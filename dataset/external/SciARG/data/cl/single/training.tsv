domain	doc_id	adu_pos	annotator	main_unit	aty	coarse_aty	second_type	coarse_second_type	parent_pos	parent_pos_rel	afu	text	text_parent
CL	D14-1002	1	pa	main	proposal	proposal	none	none	0	0	none	This paper presents a deep semantic similarity model ( DSSM ) , a special type of deep neural networks designed for text analysis , for recommending target documents to be of interest to a user based on a source document that she is reading .	
CL	D14-1002	2	pa	secondary	proposal_implementation	proposal	none	none	3	1	elaboration	We observe , identify , and detect naturally occurring signals of interestingness in click transitions on the Web between source and target documents , which we collect from commercial Web browser logs .	The DSSM is trained on millions of Web transitions , and maps source-target document pairs to feature vectors in a latent space in such a way that the distance between source documents and their corresponding interesting targets in that space is minimized .
CL	D14-1002	3	pa	secondary	proposal_implementation	proposal	none	none	1	-2	elaboration	The DSSM is trained on millions of Web transitions , and maps source-target document pairs to feature vectors in a latent space in such a way that the distance between source documents and their corresponding interesting targets in that space is minimized .	This paper presents a deep semantic similarity model ( DSSM ) , a special type of deep neural networks designed for text analysis , for recommending target documents to be of interest to a user based on a source document that she is reading .
CL	D14-1002	4	pa	secondary	means	method	none	none	5	1	by-means	The effectiveness of the DSSM is demonstrated using two interestingness tasks : automatic highlighting and contextual entity search .	The results on large-scale , real-world datasets show that the semantics of documents are important for modeling interestingness and that the DSSM leads to significant quality improvement on both tasks , outperforming not only the classic document models that do not use semantics but also state-of-the-art topic models .
CL	D14-1002	5	pa	secondary	result_means	outcomes	none	none	1	-4	support	The results on large-scale , real-world datasets show that the semantics of documents are important for modeling interestingness and that the DSSM leads to significant quality improvement on both tasks , outperforming not only the classic document models that do not use semantics but also state-of-the-art topic models .	This paper presents a deep semantic similarity model ( DSSM ) , a special type of deep neural networks designed for text analysis , for recommending target documents to be of interest to a user based on a source document that she is reading .
CL	D14-1003	1	pa	main	proposal	proposal	none	none	0	0	none	This work presents two different translation models using recurrent neural networks .	
CL	D14-1003	2	pa	secondary	proposal	proposal	none	none	1	-1	elaboration	The first one is a word-based approach using word alignments .	This work presents two different translation models using recurrent neural networks .
CL	D14-1003	3	pa	secondary	proposal	proposal	none	none	1	-2	elaboration	Second , we present phrase-based translation models that are more consistent with phrase-based decoding .	This work presents two different translation models using recurrent neural networks .
CL	D14-1003	4	pa	secondary	proposal	proposal	none	none	1	-3	elaboration	Moreover , we introduce bidirectional recurrent neural models to the problem of machine translation , allowing us to use the full source sentence in our models , which is also of theoretical interest .	This work presents two different translation models using recurrent neural networks .
CL	D14-1003	5	pa	secondary	result_means	outcomes	none	none	1	-4	support	We demonstrate that our translation models are capable of improving strong baselines already including recurrent neural language models on three tasks : IWSLT 2013 German to English , BOLT Arabic to English and Chinese to English .	This work presents two different translation models using recurrent neural networks .
CL	D14-1003	6	pa	secondary	observation	outcomes	none	none	5	-1	support	We obtain gains up to 1.6 % BLEU and 1.7 % TER by rescoring 1000-best lists .	We demonstrate that our translation models are capable of improving strong baselines already including recurrent neural language models on three tasks : IWSLT 2013 German to English , BOLT Arabic to English and Chinese to English .
CL	D14-1004	1	pa	secondary	proposal	proposal	none	none	0	0	none	This paper investigates the use of neural networks for the acquisition of selectional preferences .	
CL	D14-1004	2	pa	main	proposal	proposal	none	none	1	-1	elaboration	Inspired by recent advances of neural network models for NLP applications , we propose a neural network model that learns to discriminate between felicitous and infelicitous arguments for a particular predicate .	This paper investigates the use of neural networks for the acquisition of selectional preferences .
CL	D14-1004	3	pa	secondary	proposal_implementation	proposal	none	none	2	-1	elaboration	The model is entirely unsupervised - preferences are learned from unannotated corpus data .	Inspired by recent advances of neural network models for NLP applications , we propose a neural network model that learns to discriminate between felicitous and infelicitous arguments for a particular predicate .
CL	D14-1004	4	pa	secondary	proposal	proposal	none	none	2	-2	elaboration	We propose two neural network architectures : one that handles standard two-way selectional preferences and one that is able to deal with multi-way selectional preferences .	Inspired by recent advances of neural network models for NLP applications , we propose a neural network model that learns to discriminate between felicitous and infelicitous arguments for a particular predicate .
CL	D14-1004	5	pa	secondary	result_means	outcomes	none	none	2	-3	support	The model's performance is evaluated on a pseudo-disambiguation task , on which it is shown to achieve state of the art performance .	Inspired by recent advances of neural network models for NLP applications , we propose a neural network model that learns to discriminate between felicitous and infelicitous arguments for a particular predicate .
CL	D14-1005	1	pa	main	proposal	proposal	none	none	0	0	none	We construct multi-modal concept representations by concatenating a skip-gram linguistic representation vector with a visual concept representation vector computed using the feature extraction layers of a deep convolutional neural network ( CNN ) trained on a large labeled object recognition dataset .	
CL	D14-1005	2	pa	secondary	conclusion	outcomes	none	none	1	-1	support	This transfer learning approach brings a clear performance gain over features based on the traditional bag-of-visual-word approach .	We construct multi-modal concept representations by concatenating a skip-gram linguistic representation vector with a visual concept representation vector computed using the feature extraction layers of a deep convolutional neural network ( CNN ) trained on a large labeled object recognition dataset .
CL	D14-1005	3	pa	secondary	means	method	none	none	2	-1	by-means	Experimental results are reported on the WordSim353 and MEN semantic relatedness evaluation tasks .	This transfer learning approach brings a clear performance gain over features based on the traditional bag-of-visual-word approach .
CL	D14-1005	4	pa	secondary	proposal_implementation	proposal	none	none	1	-3	elaboration	We use visual features computed using either ImageNet or ESP Game images .	We construct multi-modal concept representations by concatenating a skip-gram linguistic representation vector with a visual concept representation vector computed using the feature extraction layers of a deep convolutional neural network ( CNN ) trained on a large labeled object recognition dataset .
CL	D14-1006	1	pa	main	proposal	proposal	none	none	0	0	none	In this paper , we present a novel approach for identifying argumentative discourse structures in persuasive essays .	
CL	D14-1006	2	pa	secondary	information_additional	other	none	none	1	-1	info-optional	The structure of argumentation consists of several components ( i.e. claims and premises ) that are connected with argumentative relations .	In this paper , we present a novel approach for identifying argumentative discourse structures in persuasive essays .
CL	D14-1006	3	pa	secondary	proposal	proposal	none	none	1	-2	elaboration	We consider this task in two consecutive steps .	In this paper , we present a novel approach for identifying argumentative discourse structures in persuasive essays .
CL	D14-1006	4	pa	secondary	proposal_implementation	proposal	none	none	3	-1	elaboration	First , we identify the components of arguments using multiclass classification .	We consider this task in two consecutive steps .
CL	D14-1006	5	pa	secondary	proposal_implementation	proposal	none	none	4	-1	sequence	Second , we classify a pair of argument components as either support or non-support for identifying the structure of argumentative discourse .	First , we identify the components of arguments using multiclass classification .
CL	D14-1006	6	pa	secondary	proposal	proposal	none	none	3	-3	elaboration	For both tasks , we evaluate several classifiers and propose novel feature sets including structural , lexical , syntactic and contextual features .	We consider this task in two consecutive steps .
CL	D14-1006	7	pa	secondary	observation	outcomes	none	none	1	-6	support	In our experiments , we obtain a macro F1-score of 0.726 for identifying argument components and 0.722 for argumentative relations .	In this paper , we present a novel approach for identifying argumentative discourse structures in persuasive essays .
CL	D14-1007	1	pa	main	proposal	proposal	none	none	0	0	none	This paper proposes a Markov Decision Process and reinforcement learning based approach for domain selection in a multi-domain Spoken Dialogue System built on a distributed architecture .	
CL	D14-1007	2	pa	secondary	proposal	proposal	none	none	1	-1	elaboration	In the proposed framework , the domain selection problem is treated as sequential planning instead of classification , such that confirmation and clarification interaction mechanisms are supported .	This paper proposes a Markov Decision Process and reinforcement learning based approach for domain selection in a multi-domain Spoken Dialogue System built on a distributed architecture .
CL	D14-1007	3	pa	secondary	result_means	outcomes	conclusion	outcomes	1	-2	support	In addition , it is shown that by using a model parameter tying trick , the extensibility of the system can be preserved , where dialogue components in new domains can be easily plugged in , without re-training the domain selection policy .	This paper proposes a Markov Decision Process and reinforcement learning based approach for domain selection in a multi-domain Spoken Dialogue System built on a distributed architecture .
CL	D14-1007	4	pa	secondary	result	outcomes	none	none	1	-3	support	The experimental results based on human subjects suggest that the proposed model marginally outperforms a non-trivial baseline .	This paper proposes a Markov Decision Process and reinforcement learning based approach for domain selection in a multi-domain Spoken Dialogue System built on a distributed architecture .
CL	D14-1008	1	pa	secondary	motivation_background	motivation	none	none	2	1	support	Discourse parsing is a challenging task and plays a critical role in discourse analysis .	In this paper , we focus on labeling full argument spans of discourse connectives in the Penn Discourse Treebank ( PDTB ) .
CL	D14-1008	2	pa	secondary	proposal	proposal	none	none	0	0	none	In this paper , we focus on labeling full argument spans of discourse connectives in the Penn Discourse Treebank ( PDTB ) .	
CL	D14-1008	3	pa	secondary	motivation_background	motivation	none	none	4	1	support	Previous studies cast this task as a linear tagging or subtree extraction problem .	In this paper , we propose a novel constituent-based approach to argument labeling , which integrates the advantages of both linear tagging and subtree extraction .
CL	D14-1008	4	pa	main	proposal	proposal	none	none	2	-2	elaboration	In this paper , we propose a novel constituent-based approach to argument labeling , which integrates the advantages of both linear tagging and subtree extraction .	In this paper , we focus on labeling full argument spans of discourse connectives in the Penn Discourse Treebank ( PDTB ) .
CL	D14-1008	5	pa	secondary	proposal	proposal	none	none	4	-1	elaboration	In particular , the proposed approach unifies intra- and inter-sentence cases by treating the immediately preceding sentence as a special constituent .	In this paper , we propose a novel constituent-based approach to argument labeling , which integrates the advantages of both linear tagging and subtree extraction .
CL	D14-1008	6	pa	secondary	proposal_implementation	proposal	none	none	5	-1	elaboration	Besides , a joint inference mechanism is introduced to incorporate global information across arguments into our constituent-based approach via integer linear programming .	In particular , the proposed approach unifies intra- and inter-sentence cases by treating the immediately preceding sentence as a special constituent .
CL	D14-1008	7	pa	secondary	result_means	outcomes	none	none	4	-3	support	Evaluation on PDTB shows significant performance improvements of our constituent-based approach over the best state-of-the-art system .	In this paper , we propose a novel constituent-based approach to argument labeling , which integrates the advantages of both linear tagging and subtree extraction .
CL	D14-1008	8	pa	secondary	result	outcomes	none	none	7	-1	elaboration	It also shows the effectiveness of our joint inference mechanism in modeling global information across arguments .	Evaluation on PDTB shows significant performance improvements of our constituent-based approach over the best state-of-the-art system .
CL	D14-1009	1	pa	main	proposal	proposal	none	none	0	0	none	We present STIR ( STrongly Incremental Repair detection ) , a system that detects speech repairs and edit terms on transcripts incrementally with minimal latency .	
CL	D14-1009	2	pa	secondary	proposal_implementation	proposal	none	none	1	-1	elaboration	STIR uses information-theoretic measures from n-gram models as its principal decision features in a pipeline of classifiers detecting the different stages of repairs .	We present STIR ( STrongly Incremental Repair detection ) , a system that detects speech repairs and edit terms on transcripts incrementally with minimal latency .
CL	D14-1009	3	pa	secondary	result_means	outcomes	none	none	1	-2	support	Results on the Switchboard disfluency tagged corpus show utterance-final accuracy on a par with state-of-the-art incremental repair detection methods , but with better incremental accuracy , faster time-to-detection and less computational overhead .	We present STIR ( STrongly Incremental Repair detection ) , a system that detects speech repairs and edit terms on transcripts incrementally with minimal latency .
CL	D14-1009	4	pa	secondary	means	method	none	none	3	-1	by-means	We evaluate its performance using incremental metrics and propose new repair processing evaluation standards .	Results on the Switchboard disfluency tagged corpus show utterance-final accuracy on a par with state-of-the-art incremental repair detection methods , but with better incremental accuracy , faster time-to-detection and less computational overhead .
CL	D14-1010	1	pa	secondary	motivation_background	motivation	none	none	3	2	support	There is rich knowledge encoded in online web data .	In this paper we adopt partial-label learning with conditional random fields to make use of this valuable knowledge for semi-supervised Chinese word segmentation .
CL	D14-1010	2	pa	secondary	motivation_background	motivation	none	none	1	-1	elaboration	For example , punctuation and entity tags in Wikipedia data define some word boundaries in a sentence .	There is rich knowledge encoded in online web data .
CL	D14-1010	3	pa	main	proposal	proposal	none	none	0	0	none	In this paper we adopt partial-label learning with conditional random fields to make use of this valuable knowledge for semi-supervised Chinese word segmentation .	
CL	D14-1010	4	pa	secondary	information_additional	other	none	none	3	-1	info-optional	The basic idea of partial-label learning is to optimize a cost function that marginalizes the probability mass in the constrained space that encodes this knowledge .	In this paper we adopt partial-label learning with conditional random fields to make use of this valuable knowledge for semi-supervised Chinese word segmentation .
CL	D14-1010	5	pa	secondary	result	outcomes	none	none	3	-2	support	By integrating some domain adaptation techniques , such as EasyAdapt , our result reaches an F-measure of 95.98 % on the CTB-6 corpus , a significant improvement from both the supervised baseline and a previous proposed approach , namely constrained decode .	In this paper we adopt partial-label learning with conditional random fields to make use of this valuable knowledge for semi-supervised Chinese word segmentation .
CL	D14-1011	1	pa	secondary	motivation_background	motivation	none	none	2	1	info-required	Microblogs have recently received widespread interest from NLP researchers .	However , current tools for Japanese word segmentation and POS tagging still perform poorly on microblog texts .
CL	D14-1011	2	pa	secondary	motivation_problem	motivation	none	none	3	1	support	However , current tools for Japanese word segmentation and POS tagging still perform poorly on microblog texts .	We developed an annotated corpus and proposed a joint model for over-coming this situation .
CL	D14-1011	3	pa	main	proposal	proposal	none	none	0	0	none	We developed an annotated corpus and proposed a joint model for over-coming this situation .	
CL	D14-1011	4	pa	secondary	conclusion	outcomes	none	none	3	-1	support	Our annotated corpus of microblog texts enables not only training of accurate statistical models but also quantitative evaluation of their performance .	We developed an annotated corpus and proposed a joint model for over-coming this situation .
CL	D14-1011	5	pa	secondary	conclusion	outcomes	none	none	3	-2	support	Our joint model with lexical normalization handles the orthographic diversity of microblog texts .	We developed an annotated corpus and proposed a joint model for over-coming this situation .
CL	D14-1011	6	pa	secondary	proposal_implementation	proposal	result	outcomes	3	-3	elaboration	We conducted an experiment to demonstrate that the corpus and model substantially contribute to boosting accuracy .	We developed an annotated corpus and proposed a joint model for over-coming this situation .
CL	D14-1012	1	pa	secondary	motivation_background	motivation	none	none	2	1	info-required	Recent work has shown success in using continuous word embeddings learned from unlabeled data as features to improve supervised NLP systems , which is regarded as a simple semi-supervised learning mechanism .	However , fundamental problems on effectively incorporating the word embedding features within the framework of linear models remain .
CL	D14-1012	2	pa	secondary	motivation_problem	motivation	none	none	3	1	support	However , fundamental problems on effectively incorporating the word embedding features within the framework of linear models remain .	In this study , we investigate and analyze three different approaches , including a new proposed distributional prototype approach , for utilizing the embedding features .
CL	D14-1012	3	pa	main	proposal	proposal	none	none	0	0	none	In this study , we investigate and analyze three different approaches , including a new proposed distributional prototype approach , for utilizing the embedding features .	
CL	D14-1012	4	pa	secondary	conclusion	outcomes	none	none	3	-1	support	The presented approaches can be integrated into most of the classical linear models in NLP .	In this study , we investigate and analyze three different approaches , including a new proposed distributional prototype approach , for utilizing the embedding features .
CL	D14-1012	5	pa	secondary	result_means	outcomes	none	none	3	-2	support	Experiments on the task of named entity recognition show that each of the proposed approaches can better utilize the word embedding features , among which the distributional prototype approach performs the best .	In this study , we investigate and analyze three different approaches , including a new proposed distributional prototype approach , for utilizing the embedding features .
CL	D14-1012	6	pa	secondary	result_means	outcomes	observation	outcomes	5	-1	elaboration	Moreover , the combination of the approaches provides additive improvements , outperforming the dense and continuous embedding features by nearly 2 points of F1 score .	Experiments on the task of named entity recognition show that each of the proposed approaches can better utilize the word embedding features , among which the distributional prototype approach performs the best .
CL	D14-1013	1	pa	secondary	motivation_background	motivation	none	none	2	1	info-required	Punctuation prediction and disfluency prediction can improve downstream natural language processing tasks such as machine translation and information extraction .	Combining the two tasks can potentially improve the efficiency of the overall pipeline system and reduce error propagation .
CL	D14-1013	2	pa	secondary	motivation_hypothesis	motivation	none	none	3	1	support	Combining the two tasks can potentially improve the efficiency of the overall pipeline system and reduce error propagation .	In this work , we compare various methods for combining punctuation prediction ( PU ) and disfluency prediction ( DF ) on the Switchboard corpus .
CL	D14-1013	3	pa	main	proposal	proposal	none	none	0	0	none	In this work , we compare various methods for combining punctuation prediction ( PU ) and disfluency prediction ( DF ) on the Switchboard corpus .	
CL	D14-1013	4	pa	secondary	proposal	proposal	none	none	3	-1	elaboration	We compare an isolated prediction approach with a cascade approach , a rescoring approach , and three joint model approaches .	In this work , we compare various methods for combining punctuation prediction ( PU ) and disfluency prediction ( DF ) on the Switchboard corpus .
CL	D14-1013	5	pa	secondary	result	outcomes	none	none	4	-1	support	For the cascade approach , we show that the soft cascade method is better than the hard cascade method .	We compare an isolated prediction approach with a cascade approach , a rescoring approach , and three joint model approaches .
CL	D14-1013	6	pa	secondary	proposal_implementation	proposal	none	none	4	-2	elaboration	We also use the cascade models to generate an n-best list , use the bi-directional cascade models to perform rescoring , and compare that with the results of the cascade models .	We compare an isolated prediction approach with a cascade approach , a rescoring approach , and three joint model approaches .
CL	D14-1013	7	pa	secondary	proposal_implementation	proposal	none	none	4	-3	elaboration	For the joint model approach , we compare mixed-label Linear-chain Conditional Random Field ( LCRF ) , cross-product LCRF and 2-layer Factorial Conditional Random Field ( FCRF ) with soft-cascade LCRF .	We compare an isolated prediction approach with a cascade approach , a rescoring approach , and three joint model approaches .
CL	D14-1013	8	pa	secondary	result	outcomes	observation	outcomes	3	-5	support	Our results show that the various methods linking the two tasks are not significantly different from one another , although they perform better than the isolated prediction method by 0.5-1.5 % in the F1 score .	In this work , we compare various methods for combining punctuation prediction ( PU ) and disfluency prediction ( DF ) on the Switchboard corpus .
CL	D14-1013	9	pa	secondary	result	outcomes	none	none	8	-1	elaboration	Moreover , the clique order of features also shows a marked difference .	Our results show that the various methods linking the two tasks are not significantly different from one another , although they perform better than the isolated prediction method by 0.5-1.5 % in the F1 score .
CL	D14-1014	1	pa	main	proposal	proposal	none	none	0	0	none	We introduce submodular optimization to the problem of training data subset selection for statistical machine translation ( SMT ) .	
CL	D14-1014	2	pa	secondary	conclusion	outcomes	proposal_implementation	proposal	1	-1	support	By explicitly formulating data selection as a submodular program , we obtain fast scalable selection algorithms with mathematical performance guarantees , resulting in a unified framework that clarifies existing approaches and also makes both new and many previous approaches easily accessible .	We introduce submodular optimization to the problem of training data subset selection for statistical machine translation ( SMT ) .
CL	D14-1014	3	pa	secondary	proposal	proposal	none	none	1	-2	elaboration	We present a new class of submodular functions designed specifically for SMT and evaluate them on two different translation tasks .	We introduce submodular optimization to the problem of training data subset selection for statistical machine translation ( SMT ) .
CL	D14-1014	4	pa	secondary	result	outcomes	none	none	2	-2	support	Our results show that our best submodular method significantly outperforms several baseline methods , including the widely-used cross-entropy based data selection method .	By explicitly formulating data selection as a submodular program , we obtain fast scalable selection algorithms with mathematical performance guarantees , resulting in a unified framework that clarifies existing approaches and also makes both new and many previous approaches easily accessible .
CL	D14-1014	5	pa	secondary	conclusion	outcomes	none	none	2	-3	elaboration	In addition , our approach easily scales to large data sets and is applicable to other data selection problems in natural language processing .	By explicitly formulating data selection as a submodular program , we obtain fast scalable selection algorithms with mathematical performance guarantees , resulting in a unified framework that clarifies existing approaches and also makes both new and many previous approaches easily accessible .
CL	D14-1015	1	pa	main	proposal	proposal	none	none	0	0	none	We investigate how to improve bilingual embedding which has been successfully used as a feature in phrase-based statistical machine translation ( SMT ) .	
CL	D14-1015	2	pa	secondary	motivation_problem	motivation	none	none	1	-1	support	Despite bilingual embedding's success , the contextual information , which is of critical importance to translation quality , was ignored in previous work .	We investigate how to improve bilingual embedding which has been successfully used as a feature in phrase-based statistical machine translation ( SMT ) .
CL	D14-1015	3	pa	secondary	proposal	proposal	none	none	1	-2	elaboration	To employ the contextual information , we propose a simple and memory-efficient model for learning bilingual embedding , taking both the source phrase and context around the phrase into account .	We investigate how to improve bilingual embedding which has been successfully used as a feature in phrase-based statistical machine translation ( SMT ) .
CL	D14-1015	4	pa	secondary	proposal_implementation	proposal	none	none	3	-1	elaboration	Bilingual translation scores generated from our proposed bilingual embedding model are used as features in our SMT system .	To employ the contextual information , we propose a simple and memory-efficient model for learning bilingual embedding , taking both the source phrase and context around the phrase into account .
CL	D14-1015	5	pa	secondary	result	outcomes	none	none	3	-2	support	Experimental results show that the proposed method achieves significant improvements on large-scale Chinese-English translation task .	To employ the contextual information , we propose a simple and memory-efficient model for learning bilingual embedding , taking both the source phrase and context around the phrase into account .
CL	D14-1016	1	pa	secondary	proposal	proposal	none	none	0	0	none	We present a novel approach to improve word alignment for statistical machine translation ( SMT ) .	
CL	D14-1016	2	pa	secondary	motivation_background	motivation	none	none	3	1	info-required	Conventional word alignment methods allow discontinuous alignment , meaning that a source ( or target ) word links to several target ( or source ) words whose positions are discontinuous .	However , we cannot extract phrase pairs from this kind of alignments as they break the alignment consistency constraint .
CL	D14-1016	3	pa	secondary	motivation_problem	motivation	none	none	4	1	support	However , we cannot extract phrase pairs from this kind of alignments as they break the alignment consistency constraint .	In this paper , we use a weighted vote method to transform discontinuous word alignment to continuous alignment , which enables SMT systems extract more phrase pairs .
CL	D14-1016	4	pa	main	proposal	proposal	none	none	1	-3	elaboration	In this paper , we use a weighted vote method to transform discontinuous word alignment to continuous alignment , which enables SMT systems extract more phrase pairs .	We present a novel approach to improve word alignment for statistical machine translation ( SMT ) .
CL	D14-1016	5	pa	secondary	means	method	none	none	6	1	by-means	We carry out experiments on large scale Chinese-to-English and German-to-English translation tasks .	Experimental results show statistically significant improvements of BLEU score in both cases over the baseline systems .
CL	D14-1016	6	pa	secondary	result	outcomes	none	none	4	-2	support	Experimental results show statistically significant improvements of BLEU score in both cases over the baseline systems .	In this paper , we use a weighted vote method to transform discontinuous word alignment to continuous alignment , which enables SMT systems extract more phrase pairs .
CL	D14-1016	7	pa	secondary	observation	outcomes	none	none	6	-1	support	Our method produces a gain of +1.68 BLEU on NIST OpenMT04 for the phrase-based system , and a gain of +1.28 BLEU on NIST OpenMT06 for the hierarchical phrase-based system .	Experimental results show statistically significant improvements of BLEU score in both cases over the baseline systems .
CL	D14-1017	1	pa	secondary	motivation_problem	motivation	none	none	2	1	info-required	Generative word alignment models , such as IBM Models , are restricted to one-to-many alignment , and cannot explicitly represent many-to-many relationships in a bilingual text .	The problem is partially solved either by introducing heuristics or by agreement constraints such that two directional word alignments agree with each other .
CL	D14-1017	2	pa	secondary	motivation_problem	motivation	none	none	3	1	support	The problem is partially solved either by introducing heuristics or by agreement constraints such that two directional word alignments agree with each other .	In this paper , we focus on the posterior regularization frame-work ( Ganchev et al. , 2010 ) that can force two directional word alignment models to agree with each other during training , and propose new constraints that can take into account the difference between function words and content words .
CL	D14-1017	3	pa	main	proposal	proposal	none	none	0	0	none	In this paper , we focus on the posterior regularization frame-work ( Ganchev et al. , 2010 ) that can force two directional word alignment models to agree with each other during training , and propose new constraints that can take into account the difference between function words and content words .	
CL	D14-1017	4	pa	secondary	result_means	outcomes	none	none	3	-1	support	Experimental results on French-to-English and Japanese-to-English alignment tasks show statistically significant gains over the previous posterior regularization baseline .	In this paper , we focus on the posterior regularization frame-work ( Ganchev et al. , 2010 ) that can force two directional word alignment models to agree with each other during training , and propose new constraints that can take into account the difference between function words and content words .
CL	D14-1017	5	pa	secondary	result_means	outcomes	conclusion	outcomes	4	-1	elaboration	We also observed gains in Japanese-to-English translation tasks , which prove the effectiveness of our methods under grammatically different language pairs .	Experimental results on French-to-English and Japanese-to-English alignment tasks show statistically significant gains over the previous posterior regularization baseline .
CL	D14-1018	1	pa	secondary	motivation_background	motivation	none	none	2	1	info-required	Distinct properties of translated text have been the subject of research in linguistics for many year ( Baker , 1993 ) .	In recent years computational methods have been developed to empirically verify the linguistic theories about translated text ( Baroni and Bernardini , 2006 ) .
CL	D14-1018	2	pa	secondary	motivation_background	motivation	none	none	3	1	info-required	In recent years computational methods have been developed to empirically verify the linguistic theories about translated text ( Baroni and Bernardini , 2006 ) .	While many characteristics of translated text are more apparent in comparison to the original text , most of the prior research has focused on monolingual features of translated and original text .
CL	D14-1018	3	pa	secondary	motivation_problem	motivation	none	none	4	1	support	While many characteristics of translated text are more apparent in comparison to the original text , most of the prior research has focused on monolingual features of translated and original text .	The contribution of this work is introducing bilingual features that are capable of explaining differences in translation direction using localized linguistic phenomena at the phrase or sentence level , rather than using monolingual statistics at the document level .
CL	D14-1018	4	pa	main	proposal	proposal	none	none	0	0	none	The contribution of this work is introducing bilingual features that are capable of explaining differences in translation direction using localized linguistic phenomena at the phrase or sentence level , rather than using monolingual statistics at the document level .	
CL	D14-1018	5	pa	secondary	conclusion	outcomes	none	none	4	-1	support	We show that these bilingual features out-perform the monolingual features used in prior work ( Kurokawa et al. , 2009 ) for the task of classifying translation direction .	The contribution of this work is introducing bilingual features that are capable of explaining differences in translation direction using localized linguistic phenomena at the phrase or sentence level , rather than using monolingual statistics at the document level .
CL	D14-1019	1	pa	secondary	motivation_background	motivation	none	none	2	1	info-required	Recently , syntactic information has helped significantly to improve statistical machine translation .	However , the use of syntactic information may have a negative impact on the speed of translation because of the large number of rules , especially when syntax labels are projected from a parser in syntax-augmented machine translation .
CL	D14-1019	2	pa	secondary	motivation_problem	motivation	none	none	3	1	support	However , the use of syntactic information may have a negative impact on the speed of translation because of the large number of rules , especially when syntax labels are projected from a parser in syntax-augmented machine translation .	In this paper , we propose a syntax-label clustering method that uses an exchange algorithm in which syntax labels are clustered together to reduce the number of rules .
CL	D14-1019	3	pa	main	proposal	proposal	none	none	0	0	none	In this paper , we propose a syntax-label clustering method that uses an exchange algorithm in which syntax labels are clustered together to reduce the number of rules .	
CL	D14-1019	4	pa	secondary	proposal_implementation	proposal	none	none	3	-1	elaboration	The proposed method achieves clustering by directly maximizing the likelihood of synchronous rules , whereas previous work considered only the similarity of probabilistic distributions of labels .	In this paper , we propose a syntax-label clustering method that uses an exchange algorithm in which syntax labels are clustered together to reduce the number of rules .
CL	D14-1019	5	pa	secondary	result_means	outcomes	none	none	3	-2	support	We tested the proposed method on Japanese-English and Chinese-English translation tasks and found order-of-magnitude higher clustering speeds for reducing labels and gains in translation quality compared with previous clustering method .	In this paper , we propose a syntax-label clustering method that uses an exchange algorithm in which syntax labels are clustered together to reduce the number of rules .
CL	D14-1020	1	pa	secondary	motivation_background	motivation	none	none	2	1	info-required	Automatic metrics are widely used in machine translation as a substitute for human assessment .	With the introduction of any new metric comes the question of just how well that metric mimics human assessment of translation quality .
CL	D14-1020	2	pa	secondary	motivation_background	motivation	none	none	4	2	info-required	With the introduction of any new metric comes the question of just how well that metric mimics human assessment of translation quality .	Significance tests are generally not used to establish whether improvements over existing methods such as BLEU are statistically significant or have occurred simply by chance , however .
CL	D14-1020	3	pa	secondary	motivation_background	motivation	none	none	2	-1	elaboration	This is often measured by correlation with human judgment .	With the introduction of any new metric comes the question of just how well that metric mimics human assessment of translation quality .
CL	D14-1020	4	pa	secondary	motivation_problem	motivation	none	none	5	1	support	Significance tests are generally not used to establish whether improvements over existing methods such as BLEU are statistically significant or have occurred simply by chance , however .	In this paper , we introduce a significance test for comparing correlations of two metrics , along with an open-source implementation of the test .
CL	D14-1020	5	pa	main	proposal	proposal	none	none	0	0	none	In this paper , we introduce a significance test for comparing correlations of two metrics , along with an open-source implementation of the test .	
CL	D14-1020	6	pa	secondary	result_means	outcomes	none	none	5	-1	support	When applied to a range of metrics across seven language pairs , tests show that for a high proportion of metrics , there is insufficient evidence to conclude significant improvement over BLEU .	In this paper , we introduce a significance test for comparing correlations of two metrics , along with an open-source implementation of the test .
CL	D14-1021	1	pa	main	proposal	proposal	none	none	0	0	none	We study a novel architecture for syntactic SMT .	
CL	D14-1021	2	pa	secondary	proposal	proposal	proposal_implementation	proposal	1	-1	elaboration	In contrast to the dominant approach in the literature , the system does not rely on translation rules , but treat translation as an unconstrained target sentence generation task , using soft features to capture lexical and syntactic correspondences between the source and target languages .	We study a novel architecture for syntactic SMT .
CL	D14-1021	3	pa	secondary	proposal_implementation	proposal	none	none	2	-1	elaboration	Target syntax features and bilingual translation features are trained consistently in a discriminative model .	In contrast to the dominant approach in the literature , the system does not rely on translation rules , but treat translation as an unconstrained target sentence generation task , using soft features to capture lexical and syntactic correspondences between the source and target languages .
CL	D14-1021	4	pa	secondary	result_means	outcomes	none	none	1	-3	support	Experiments using the IWSLT 2010 dataset show that the system achieves BLEU comparable to the state-of-the-art syntactic SMT systems .	We study a novel architecture for syntactic SMT .
CL	D14-1022	1	pa	main	proposal	proposal	none	none	0	0	none	We propose a simple and effective approach to learn translation spans for the hierarchical phrase-based translation model .	
CL	D14-1022	2	pa	secondary	proposal	proposal	none	none	1	-1	elaboration	Our model evaluates if a source span should be covered by translation rules during decoding , which is integrated into the translation system as soft constraints .	We propose a simple and effective approach to learn translation spans for the hierarchical phrase-based translation model .
CL	D14-1022	3	pa	secondary	proposal_implementation	proposal	none	none	2	-1	elaboration	Compared to syntactic constraints , our model is directly acquired from an aligned parallel corpus and does not require parsers .	Our model evaluates if a source span should be covered by translation rules during decoding , which is integrated into the translation system as soft constraints .
CL	D14-1022	4	pa	secondary	proposal_implementation	proposal	none	none	3	-1	elaboration	Rich source side contextual features and advanced machine learning methods were utilized for this learning task .	Compared to syntactic constraints , our model is directly acquired from an aligned parallel corpus and does not require parsers .
CL	D14-1022	5	pa	secondary	result_means	outcomes	none	none	1	-4	support	The proposed approach was evaluated on NTCIR-9 Chinese-English and Japanese-English translation tasks and showed significant improvement over the baseline system .	We propose a simple and effective approach to learn translation spans for the hierarchical phrase-based translation model .
CL	D14-1023	1	pa	secondary	motivation_background	motivation	none	none	2	1	info-required	Since larger n-gram Language Model ( LM ) usually performs better in Statistical Machine Translation ( SMT ) , how to construct efficient large LM is an important topic in SMT .	However , most of the existing LM growing methods need an extra monolingual corpus , where additional LM adaption technology is necessary .
CL	D14-1023	2	pa	secondary	motivation_problem	motivation	none	none	3	1	support	However , most of the existing LM growing methods need an extra monolingual corpus , where additional LM adaption technology is necessary .	In this paper , we propose a novel neural network based bilingual LM growing method , only using the bilingual parallel corpus in SMT .
CL	D14-1023	3	pa	main	proposal	proposal	none	none	0	0	none	In this paper , we propose a novel neural network based bilingual LM growing method , only using the bilingual parallel corpus in SMT .	
CL	D14-1023	4	pa	secondary	result	outcomes	none	none	3	-1	support	The results show that our method can improve both the perplexity score for LM evaluation and BLEU score for SMT , and significantly outperforms the existing LM growing methods without extra corpus .	In this paper , we propose a novel neural network based bilingual LM growing method , only using the bilingual parallel corpus in SMT .
CL	D14-1024	1	pa	main	proposal	proposal	none	none	0	0	none	This article describes a linguistically informed method for integrating phrasal verbs into statistical machine translation ( SMT ) systems .	
CL	D14-1024	2	pa	secondary	result_means	outcomes	none	none	3	1	support	In a case study involving English to Bulgarian SMT , we show that our method does not only improve translation quality but also outperforms similar methods previously applied to the same task .	We attribute this to the fact that , in contrast to previous work on the subject , we employ detailed linguistic information .
CL	D14-1024	3	pa	secondary	conclusion	outcomes	none	none	1	-2	support	We attribute this to the fact that , in contrast to previous work on the subject , we employ detailed linguistic information .	This article describes a linguistically informed method for integrating phrasal verbs into statistical machine translation ( SMT ) systems .
CL	D14-1024	4	pa	secondary	result	outcomes	none	none	2	-2	elaboration	We found out that features which describe phrasal verbs as idiomatic or compositional contribute most to the better translation quality achieved by our method .	In a case study involving English to Bulgarian SMT , we show that our method does not only improve translation quality but also outperforms similar methods previously applied to the same task .
CL	D14-1025	1	pa	secondary	motivation_background	motivation	none	none	2	1	info-required	Sentence level evaluation in MT has turned out far more difficult than corpus level evaluation .	Existing sentence level metrics employ a limited set of features , most of which are rather sparse at the sentence level , and their intricate models are rarely trained for ranking .
CL	D14-1025	2	pa	secondary	motivation_problem	motivation	none	none	3	1	support	Existing sentence level metrics employ a limited set of features , most of which are rather sparse at the sentence level , and their intricate models are rarely trained for ranking .	This paper presents a simple linear model exploiting 33 relatively dense features , some of which are novel while others are known but seldom used , and train it under the learning-to-rank framework .
CL	D14-1025	3	pa	main	proposal	proposal	none	none	0	0	none	This paper presents a simple linear model exploiting 33 relatively dense features , some of which are novel while others are known but seldom used , and train it under the learning-to-rank framework .	
CL	D14-1025	4	pa	secondary	result_means	outcomes	none	none	3	-1	support	We evaluate our metric on the standard WMT12 data showing that it outperforms the strong baseline METEOR .	This paper presents a simple linear model exploiting 33 relatively dense features , some of which are novel while others are known but seldom used , and train it under the learning-to-rank framework .
CL	D14-1025	5	pa	secondary	proposal	proposal	none	none	3	-2	elaboration	We also analyze the contribution of individual features and the choice of training data , language-pair vs. target-language data , providing new insights into this task .	This paper presents a simple linear model exploiting 33 relatively dense features , some of which are novel while others are known but seldom used , and train it under the learning-to-rank framework .
CL	D14-1026	1	pa	main	proposal	proposal	none	none	0	0	none	We present a human judgments dataset and an adapted metric for evaluation of Arabic machine translation .	
CL	D14-1026	2	pa	secondary	conclusion	outcomes	none	none	1	-1	support	Our mediumscale dataset is the first of its kind for Arabic with high annotation quality .	We present a human judgments dataset and an adapted metric for evaluation of Arabic machine translation .
CL	D14-1026	3	pa	secondary	proposal_implementation	proposal	none	none	4	1	elaboration	We use the dataset to adapt the BLEU score for Arabic .	Our score ( AL-BLEU ) provides partial credits for stem and morphological matchings of hypothesis and reference words .
CL	D14-1026	4	pa	secondary	proposal	proposal	none	none	1	-3	elaboration	Our score ( AL-BLEU ) provides partial credits for stem and morphological matchings of hypothesis and reference words .	We present a human judgments dataset and an adapted metric for evaluation of Arabic machine translation .
CL	D14-1026	5	pa	secondary	result_means	outcomes	none	none	1	-4	support	We evaluate BLEU , METEOR and AL-BLEU on our human judgments corpus and show that AL-BLEU has the highest correlation with human judgments .	We present a human judgments dataset and an adapted metric for evaluation of Arabic machine translation .
CL	D14-1026	6	pa	secondary	information_additional	other	none	none	2	-4	info-optional	We are releasing the dataset and software to the research community .	Our mediumscale dataset is the first of its kind for Arabic with high annotation quality .
CL	D14-1027	1	pa	main	proposal	proposal	none	none	0	0	none	We present a pairwise learning-to-rank approach to machine translation evaluation that learns to differentiate better from worse translations in the context of a given reference .	
CL	D14-1027	2	pa	secondary	proposal_implementation	proposal	none	none	1	-1	elaboration	We integrate several layers of linguistic information encapsulated in tree-based structures , making use of both the reference and the system output simultaneously , thus bringing our ranking closer to how humans evaluate translations .	We present a pairwise learning-to-rank approach to machine translation evaluation that learns to differentiate better from worse translations in the context of a given reference .
CL	D14-1027	3	pa	secondary	proposal_implementation	proposal	none	none	2	-1	elaboration	Most importantly , instead of deciding upfront which types of features are important , we use the learning framework of preference re-ranking kernels to learn the features automatically .	We integrate several layers of linguistic information encapsulated in tree-based structures , making use of both the reference and the system output simultaneously , thus bringing our ranking closer to how humans evaluate translations .
CL	D14-1027	4	pa	secondary	result	outcomes	none	none	1	-3	support	The evaluation results show that learning in the proposed framework yields better correlation with humans than computing the direct similarity over the same type of structures .	We present a pairwise learning-to-rank approach to machine translation evaluation that learns to differentiate better from worse translations in the context of a given reference .
CL	D14-1027	5	pa	secondary	conclusion	outcomes	none	none	1	-4	support	Also , we show our structural kernel learning ( SKL ) can be a general framework for MT evaluation , in which syntactic and semantic information can be naturally incorporated .	We present a pairwise learning-to-rank approach to machine translation evaluation that learns to differentiate better from worse translations in the context of a given reference .
CL	D14-1028	1	pa	secondary	motivation_background	motivation	none	none	2	1	info-required	Left-to-right ( LR ) decoding ( Watanabe et al. , 2006 ) is promising decoding algorithm for hierarchical phrase-based translation ( Hiero ) that visits input spans in arbitrary order producing the output translation in left to right order .	This leads to far fewer language model calls , but while LR decoding is more efficient than CKY decoding , it is unable to capture some hierarchical phrase alignments reachable using CKY decoding and suffers from lower translation quality as a result .
CL	D14-1028	2	pa	secondary	motivation_problem	motivation	none	none	3	1	support	This leads to far fewer language model calls , but while LR decoding is more efficient than CKY decoding , it is unable to capture some hierarchical phrase alignments reachable using CKY decoding and suffers from lower translation quality as a result .	This paper introduces two improvements to LR decoding that make it comparable in translation quality to CKY-based Hiero .
CL	D14-1028	3	pa	main	proposal	proposal	none	none	0	0	none	This paper introduces two improvements to LR decoding that make it comparable in translation quality to CKY-based Hiero .	
CL	D14-1029	1	pa	main	proposal	proposal	none	none	0	0	none	In this paper , we present a novel extension of a forest-to-string machine translation system with a reordering model .	
CL	D14-1029	2	pa	secondary	proposal_implementation	proposal	none	none	1	-1	elaboration	We predict reordering probabilities for every pair of source words with a model using features observed from the input parse forest .	In this paper , we present a novel extension of a forest-to-string machine translation system with a reordering model .
CL	D14-1029	3	pa	secondary	proposal	proposal	none	none	1	-2	elaboration	Our approach naturally deals with the ambiguity present in the input parse forest , but , at the same time , takes into account only the parts of the input forest used by the current translation hypothesis .	In this paper , we present a novel extension of a forest-to-string machine translation system with a reordering model .
CL	D14-1029	4	pa	secondary	observation	outcomes	none	none	1	-3	support	The method provides improvement from 0.6 up to 1.0 point measured by ( Ter − Bleu ) /2 metric .	In this paper , we present a novel extension of a forest-to-string machine translation system with a reordering model .
CL	D14-1030	1	pa	secondary	motivation_background	motivation	none	none	2	1	info-required	Many statistical models for natural language processing exist , including context-based neural networks that ( 1 ) model the previously seen context as a latent feature vector , ( 2 ) integrate successive words into the context using some learned representation ( embedding ) , and ( 3 ) compute output probabilities for incoming words given the context .	On the other hand , brain imaging studies have suggested that during reading , the brain ( a ) continuously builds a context from the successive words and every time it encounters a word it ( b ) fetches its properties from memory and ( c ) integrates it with the previous context with a degree of effort that is inversely proportional to how probable the word is .
CL	D14-1030	2	pa	secondary	motivation_background	motivation	none	none	3	1	info-required	On the other hand , brain imaging studies have suggested that during reading , the brain ( a ) continuously builds a context from the successive words and every time it encounters a word it ( b ) fetches its properties from memory and ( c ) integrates it with the previous context with a degree of effort that is inversely proportional to how probable the word is .	This hints to a parallelism between the neural networks and the brain in modeling context ( 1 and a ) , representing the incoming words ( 2 and b ) and integrating it ( 3 and c ) .
CL	D14-1030	3	pa	secondary	motivation_hypothesis	motivation	none	none	4	1	support	This hints to a parallelism between the neural networks and the brain in modeling context ( 1 and a ) , representing the incoming words ( 2 and b ) and integrating it ( 3 and c ) .	We explore this parallelism to better understand the brain processes and the neural networks representations .
CL	D14-1030	4	pa	main	proposal	proposal	none	none	0	0	none	We explore this parallelism to better understand the brain processes and the neural networks representations .	
CL	D14-1030	5	pa	secondary	proposal_implementation	proposal	none	none	4	-1	elaboration	We study the alignment between the latent vectors used by neural networks and brain activity observed via Magnetoencephalography ( MEG ) when subjects read a story .	We explore this parallelism to better understand the brain processes and the neural networks representations .
CL	D14-1030	6	pa	secondary	proposal_implementation	proposal	none	none	5	-1	elaboration	For that purpose we apply the neural network to the same text the subjects are reading , and explore the ability of these three vector representations to predict the observed word-by-word brain activity .	We study the alignment between the latent vectors used by neural networks and brain activity observed via Magnetoencephalography ( MEG ) when subjects read a story .
CL	D14-1030	7	pa	secondary	result	outcomes	none	none	4	-3	support	Our novel results show that : before a new word i is read , brain activity is well predicted by the neural network latent representation of context and the predictability decreases as the brain integrates the word and changes its own representation of context .	We explore this parallelism to better understand the brain processes and the neural networks representations .
CL	D14-1030	8	pa	secondary	result	outcomes	none	none	4	-4	support	Secondly , the neural network embedding of word i can predict the MEG activity when word i is presented to the subject , revealing that it is correlated with the brain's own representation of word i .	We explore this parallelism to better understand the brain processes and the neural networks representations .
CL	D14-1030	9	pa	secondary	result	outcomes	none	none	8	-1	elaboration	Moreover , we obtain that the activity is predicted in different regions of the brain with varying delay .	Secondly , the neural network embedding of word i can predict the MEG activity when word i is presented to the subject , revealing that it is correlated with the brain's own representation of word i .
CL	D14-1030	10	pa	secondary	result	outcomes	none	none	9	-1	elaboration	The delay is consistent with the placement of each region on the processing pathway that starts in the visual cortex and moves to higher level regions .	Moreover , we obtain that the activity is predicted in different regions of the brain with varying delay .
CL	D14-1030	11	pa	secondary	result	outcomes	none	none	4	-7	support	Finally , we show that the output probability computed by the neural networks agrees with the brain's own assessment of the probability of word i , as it can be used to predict the brain activity after the word i's properties have been fetched from memory and the brain is in the process of integrating it into the context .	We explore this parallelism to better understand the brain processes and the neural networks representations .
CL	D14-1031	1	pa	secondary	motivation_background	motivation	none	none	2	1	info-required	Child semantic development includes learning the meaning of words as well as the semantic relations among words .	A presumed outcome of semantic development is the formation of a semantic network that reflects this knowledge .
CL	D14-1031	2	pa	secondary	motivation_background	motivation	none	none	3	1	support	A presumed outcome of semantic development is the formation of a semantic network that reflects this knowledge .	We present an algorithm for simultaneously learning word meanings and gradually growing a semantic network , which adheres to the cognitive plausibility requirements of incrementality and limited computations .
CL	D14-1031	3	pa	main	proposal	proposal	none	none	0	0	none	We present an algorithm for simultaneously learning word meanings and gradually growing a semantic network , which adheres to the cognitive plausibility requirements of incrementality and limited computations .	
CL	D14-1031	4	pa	secondary	conclusion	outcomes	none	none	3	-1	support	We demonstrate that the semantic connections among words in addition to their context is necessary in forming a semantic network that resembles an adult's semantic knowledge .	We present an algorithm for simultaneously learning word meanings and gradually growing a semantic network , which adheres to the cognitive plausibility requirements of incrementality and limited computations .
CL	D14-1032	1	pa	secondary	motivation_background	motivation	none	none	2	1	info-required	Models that acquire semantic representations from both linguistic and perceptual input are of interest to researchers in NLP because of the obvious parallels with human language learning .	Performance advantages of the multi-modal approach over language-only models have been clearly established when models are required to learn concrete noun concepts .
CL	D14-1032	2	pa	secondary	motivation_background	motivation	none	none	3	1	info-required	Performance advantages of the multi-modal approach over language-only models have been clearly established when models are required to learn concrete noun concepts .	However , such concepts are comparatively rare in everyday language .
CL	D14-1032	3	pa	secondary	motivation_problem	motivation	none	none	4	1	support	However , such concepts are comparatively rare in everyday language .	In this work , we present a new means of extending the scope of multi-modal models to more commonly-occurring abstract lexical concepts via an approach that learns multi-modal embeddings .
CL	D14-1032	4	pa	main	proposal	proposal	none	none	0	0	none	In this work , we present a new means of extending the scope of multi-modal models to more commonly-occurring abstract lexical concepts via an approach that learns multi-modal embeddings .	
CL	D14-1032	5	pa	secondary	result	outcomes	conclusion	outcomes	4	-1	support	Our architecture outperforms previous approaches in combining input from distinct modalities , and propagates perceptual information on concrete concepts to abstract concepts more effectively than alternatives .	In this work , we present a new means of extending the scope of multi-modal models to more commonly-occurring abstract lexical concepts via an approach that learns multi-modal embeddings .
CL	D14-1032	6	pa	secondary	proposal	proposal	none	none	4	-2	elaboration	We discuss the implications of our results both for optimizing the performance of multi-modal models and for theories of abstract conceptual representation .	In this work , we present a new means of extending the scope of multi-modal models to more commonly-occurring abstract lexical concepts via an approach that learns multi-modal embeddings .
CL	D14-1033	1	pa	secondary	motivation_background	motivation	none	none	2	1	support	State-of-art systems for grammar error correction often correct errors based on word sequences or phrases .	In this paper , we describe a grammar error correction system which corrects grammatical errors at tree level directly .
CL	D14-1033	2	pa	main	proposal	proposal	none	none	0	0	none	In this paper , we describe a grammar error correction system which corrects grammatical errors at tree level directly .	
CL	D14-1033	3	pa	secondary	proposal_implementation	proposal	none	none	2	-1	elaboration	We cluster all error into two groups and divide our system into two modules correspondingly : the general module and the special module .	In this paper , we describe a grammar error correction system which corrects grammatical errors at tree level directly .
CL	D14-1033	4	pa	secondary	proposal_implementation	proposal	none	none	3	-1	elaboration	In the general module , we propose a TreeNode Language Model to correct errors related to verbs and nouns .	We cluster all error into two groups and divide our system into two modules correspondingly : the general module and the special module .
CL	D14-1033	5	pa	secondary	conclusion	outcomes	none	none	4	-1	support	The TreeNode Language Model is easy to train and the decoding is efficient .	In the general module , we propose a TreeNode Language Model to correct errors related to verbs and nouns .
CL	D14-1033	6	pa	secondary	proposal_implementation	proposal	none	none	3	-3	elaboration	In the special module , two extra classification models are trained to correct errors related to determiners and prepositions .	We cluster all error into two groups and divide our system into two modules correspondingly : the general module and the special module .
CL	D14-1033	7	pa	secondary	result	outcomes	observation	outcomes	2	-5	support	Experiments show that our system outperforms the state-of-art systems and improves the F1 score .	In this paper , we describe a grammar error correction system which corrects grammatical errors at tree level directly .
CL	D14-1034	1	pa	secondary	motivation_background	motivation	none	none	2	1	info-required	Most existing systems for subcategorization frame ( SCF ) acquisition rely on supervised parsing and infer SCF distributions at type , rather than instance level .	These systems suffer from poor portability across domains and their benefit for NLP tasks that involve sentence-level processing is limited .
CL	D14-1034	2	pa	secondary	motivation_problem	motivation	none	none	3	1	support	These systems suffer from poor portability across domains and their benefit for NLP tasks that involve sentence-level processing is limited .	We propose a new unsupervised , Markov Random Field-based model for SCF acquisition which is designed to address these problems .
CL	D14-1034	3	pa	main	proposal	proposal	none	none	0	0	none	We propose a new unsupervised , Markov Random Field-based model for SCF acquisition which is designed to address these problems .	
CL	D14-1034	4	pa	secondary	proposal_implementation	proposal	none	none	3	-1	elaboration	The system relies on supervised POS tagging rather than parsing , and is capable of learning SCFs at instance level .	We propose a new unsupervised , Markov Random Field-based model for SCF acquisition which is designed to address these problems .
CL	D14-1034	5	pa	secondary	result_means	outcomes	none	none	3	-2	support	We perform evaluation against gold standard data which shows that our system outperforms several supervised and type-level SCF baselines .	We propose a new unsupervised , Markov Random Field-based model for SCF acquisition which is designed to address these problems .
CL	D14-1034	6	pa	secondary	result_means	outcomes	none	none	3	-3	support	We also conduct task-based evaluation in the context of verb similarity prediction , demonstrating that a vector space model based on our SCFs substantially outperforms a lexical model and a model based on a supervised parser .	We propose a new unsupervised , Markov Random Field-based model for SCF acquisition which is designed to address these problems .
CL	D14-1035	1	pa	secondary	motivation_background	motivation	none	none	2	1	support	PCFGs with latent annotations have been shown to be a very effective model for phrase structure parsing .	We present a Bayesian model and algorithms based on a Gibbs sampler for parsing with a grammar with latent annotations .
CL	D14-1035	2	pa	main	proposal	proposal	none	none	0	0	none	We present a Bayesian model and algorithms based on a Gibbs sampler for parsing with a grammar with latent annotations .	
CL	D14-1035	3	pa	secondary	proposal_implementation	proposal	none	none	2	-1	elaboration	For PCFG-LA , we present an additional Gibbs sampler algorithm to learn annotations from training data , which are parse trees with coarse ( unannotated ) symbols .	We present a Bayesian model and algorithms based on a Gibbs sampler for parsing with a grammar with latent annotations .
CL	D14-1035	4	pa	secondary	conclusion	outcomes	proposal_implementation	proposal	2	-2	support	We show that a Gibbs sampling technique is capable of parsing sentences in a wide variety of languages and producing results that are on-par with or surpass previous approaches .	We present a Bayesian model and algorithms based on a Gibbs sampler for parsing with a grammar with latent annotations .
CL	D14-1035	5	pa	secondary	result_means	outcomes	none	none	4	-1	support	Our results for Kinyarwanda and Malagasy in particular demonstrate that low-resource language parsing can benefit substantially from a Bayesian approach .	We show that a Gibbs sampling technique is capable of parsing sentences in a wide variety of languages and producing results that are on-par with or surpass previous approaches .
CL	D14-1036	1	pa	main	proposal	proposal	none	none	0	0	none	We introduce the task of incremental semantic role labeling ( iSRL ) , in which semantic roles are assigned to incomplete input ( sentence prefixes ) .	
CL	D14-1036	2	pa	secondary	information_additional	other	none	none	1	-1	info-optional	iSRL is the semantic equivalent of incremental parsing , and is useful for language modeling , sentence completion , machine translation , and psycholinguistic modeling .	We introduce the task of incremental semantic role labeling ( iSRL ) , in which semantic roles are assigned to incomplete input ( sentence prefixes ) .
CL	D14-1036	3	pa	secondary	proposal	proposal	none	none	1	-2	elaboration	We propose an iSRL system that combines an incremental TAG parser with a semantically enriched lexicon , a role propagation algorithm , and a cascade of classifiers .	We introduce the task of incremental semantic role labeling ( iSRL ) , in which semantic roles are assigned to incomplete input ( sentence prefixes ) .
CL	D14-1036	4	pa	secondary	observation	outcomes	none	none	5	1	support	Our approach achieves an SRL F-score of 78.38 % on the standard CoNLL 2009 dataset .	It substantially outperforms a strong baseline that combines gold-standard syntactic dependencies with heuristic role assignment , as well as a baseline based on Nivre's incremental dependency parser .
CL	D14-1036	5	pa	secondary	result_means	outcomes	none	none	3	-2	support	It substantially outperforms a strong baseline that combines gold-standard syntactic dependencies with heuristic role assignment , as well as a baseline based on Nivre's incremental dependency parser .	We propose an iSRL system that combines an incremental TAG parser with a semantically enriched lexicon , a role propagation algorithm , and a cascade of classifiers .
CL	D14-1037	1	pa	secondary	motivation_problem	motivation	none	none	2	1	info-required	The informal nature of social media text renders it very difficult to be automatically processed by natural language processing tools .	Text normalization , which corresponds to restoring the non-standard words to their canonical forms , provides a solution to this challenge .
CL	D14-1037	2	pa	secondary	motivation_background	motivation	none	none	3	1	support	Text normalization , which corresponds to restoring the non-standard words to their canonical forms , provides a solution to this challenge .	We introduce an unsupervised text normalization approach that utilizes not only lexical , but also contextual and grammatical features of social text .
CL	D14-1037	3	pa	main	proposal	proposal	none	none	0	0	none	We introduce an unsupervised text normalization approach that utilizes not only lexical , but also contextual and grammatical features of social text .	
CL	D14-1037	4	pa	secondary	proposal_implementation	proposal	none	none	3	-1	elaboration	The contextual and grammatical features are extracted from a word association graph built by using a large unlabeled social media text corpus .	We introduce an unsupervised text normalization approach that utilizes not only lexical , but also contextual and grammatical features of social text .
CL	D14-1037	5	pa	secondary	proposal_implementation	proposal	none	none	4	-1	elaboration	The graph encodes the relative positions of the words with respect to each other , as well as their part-of-speech tags .	The contextual and grammatical features are extracted from a word association graph built by using a large unlabeled social media text corpus .
CL	D14-1037	6	pa	secondary	proposal_implementation	proposal	none	none	4	-2	elaboration	The lexical features are obtained by using the longest common subsequence ratio and edit distance measures to encode the surface similarity among words , and the double metaphone algorithm to represent the phonetic similarity .	The contextual and grammatical features are extracted from a word association graph built by using a large unlabeled social media text corpus .
CL	D14-1037	7	pa	secondary	proposal	proposal	none	none	3	-4	elaboration	Unlike most of the recent approaches that are based on generating normalization dictionaries , the proposed approach performs normalization by considering the context of the non-standard words in the input text .	We introduce an unsupervised text normalization approach that utilizes not only lexical , but also contextual and grammatical features of social text .
CL	D14-1037	8	pa	secondary	result	outcomes	none	none	3	-5	support	Our results show that it achieves state-of-the-art F-score performance on standard datasets .	We introduce an unsupervised text normalization approach that utilizes not only lexical , but also contextual and grammatical features of social text .
CL	D14-1037	9	pa	secondary	conclusion	outcomes	none	none	3	-6	support	In addition , the system can be tuned to achieve very high precision without sacrificing much from recall .	We introduce an unsupervised text normalization approach that utilizes not only lexical , but also contextual and grammatical features of social text .
CL	D14-1038	1	pa	secondary	motivation_background	motivation	none	none	2	1	info-required	Search engines are increasingly relying on large knowledge bases of facts to provide direct answers to users' queries .	However , the construction of these knowledge bases is largely manual and does not scale to the long and heavy tail of facts .
CL	D14-1038	2	pa	secondary	motivation_problem	motivation	none	none	3	1	info-required	However , the construction of these knowledge bases is largely manual and does not scale to the long and heavy tail of facts .	Open information extraction tries to address this challenge , but typically assumes that facts are expressed with verb phrases , and therefore has had difficulty extracting facts for noun-based relations .
CL	D14-1038	3	pa	secondary	motivation_problem	motivation	none	none	4	1	support	Open information extraction tries to address this challenge , but typically assumes that facts are expressed with verb phrases , and therefore has had difficulty extracting facts for noun-based relations .	We describe ReNoun , an open information extraction system that complements previous efforts by focusing on nominal attributes and on the long tail .
CL	D14-1038	4	pa	main	proposal	proposal	none	none	0	0	none	We describe ReNoun , an open information extraction system that complements previous efforts by focusing on nominal attributes and on the long tail .	
CL	D14-1038	5	pa	secondary	proposal	proposal	none	none	4	-1	elaboration	ReNoun's approach is based on leveraging a large ontology of noun attributes mined from a text corpus and from user queries .	We describe ReNoun , an open information extraction system that complements previous efforts by focusing on nominal attributes and on the long tail .
CL	D14-1038	6	pa	secondary	proposal_implementation	proposal	none	none	5	-1	elaboration	ReNoun creates a seed set of training data by using specialized patterns and requiring that the facts mention an attribute in the ontology .	ReNoun's approach is based on leveraging a large ontology of noun attributes mined from a text corpus and from user queries .
CL	D14-1038	7	pa	secondary	proposal_implementation	proposal	none	none	6	-1	sequence	ReNoun then generalizes from this seed set to produce a much larger set of extractions that are then scored .	ReNoun creates a seed set of training data by using specialized patterns and requiring that the facts mention an attribute in the ontology .
CL	D14-1038	8	pa	secondary	result	outcomes	none	none	4	-4	support	We describe experiments that show that we extract facts with high precision and for attributes that cannot be extracted with verb-based techniques .	We describe ReNoun , an open information extraction system that complements previous efforts by focusing on nominal attributes and on the long tail .
CL	D14-1039	1	pa	secondary	motivation_background	motivation	none	none	2	1	info-required	Text-based document geolocation is commonly rooted in language-based information retrieval techniques over geodesic grids .	These methods ignore the natural hierarchy of cells in such grids and fall afoul of independence assumptions .
CL	D14-1039	2	pa	secondary	motivation_problem	motivation	none	none	3	1	support	These methods ignore the natural hierarchy of cells in such grids and fall afoul of independence assumptions .	We demonstrate the effectiveness of using logistic regression models on a hierarchy of nodes in the grid , which improves upon the state of the art accuracy by several percent and reduces mean error distances by hundreds of kilometers on data from Twitter , Wikipedia , and Flickr .
CL	D14-1039	3	pa	main	conclusion	outcomes	result_means	outcomes	0	0	none	We demonstrate the effectiveness of using logistic regression models on a hierarchy of nodes in the grid , which improves upon the state of the art accuracy by several percent and reduces mean error distances by hundreds of kilometers on data from Twitter , Wikipedia , and Flickr .	
CL	D14-1039	4	pa	secondary	conclusion	outcomes	none	none	3	-1	support	We also show that logistic regression performs feature selection effectively , assigning high weights to geocentric terms .	We demonstrate the effectiveness of using logistic regression models on a hierarchy of nodes in the grid , which improves upon the state of the art accuracy by several percent and reduces mean error distances by hundreds of kilometers on data from Twitter , Wikipedia , and Flickr .
CL	D14-1070	1	mn	secondary	motivation_background	motivation	none	none	2	1	info-required	Text classification methods for tasks like factoid question answering typically use manually defined string matching rules or bag of words representations .	These methods are ineffective when question text contains very few individual words ( e.g. , named entities ) that are indicative of the answer .
CL	D14-1070	2	mn	secondary	motivation_problem	motivation	none	none	3	1	support	These methods are ineffective when question text contains very few individual words ( e.g. , named entities ) that are indicative of the answer .	We introduce a recursive neural network ( rnn ) model that can reason over such input by modeling textual compositionality .
CL	D14-1070	3	mn	main	proposal	proposal	none	none	0	0	none	We introduce a recursive neural network ( rnn ) model that can reason over such input by modeling textual compositionality .	
CL	D14-1070	4	mn	secondary	means	method	none	none	6	2	by-means	We apply our model , qanta , to a dataset of questions from a trivia competition called quiz bowl .	The model outperforms multiple baselines and , when combined with information retrieval methods , ri-vals the best human players .
CL	D14-1070	5	mn	secondary	conclusion	outcomes	none	none	3	-2	support	Unlike previous rnn models , qanta learns word and phrase-level representations that combine across sentences to reason about entities .	We introduce a recursive neural network ( rnn ) model that can reason over such input by modeling textual compositionality .
CL	D14-1070	6	mn	secondary	result	outcomes	none	none	5	-1	support	The model outperforms multiple baselines and , when combined with information retrieval methods , ri-vals the best human players .	Unlike previous rnn models , qanta learns word and phrase-level representations that combine across sentences to reason about entities .
CL	D14-1071	1	mn	secondary	motivation_background	motivation	none	none	2	1	support	Transforming a natural language ( NL ) question into a corresponding logical form ( LF ) is central to the knowledge-based question answering ( KB-QA ) task .	Unlike most previous methods that achieve this goal based on mappings between lexicalized phrases and logical predicates , this paper goes one step further and proposes a novel embedding-based approach that maps NL-questions into LFs for KB-QA by leveraging semantic associations between lexical representations and KB-properties in the latent space .
CL	D14-1071	2	mn	main	proposal	proposal	motivation_background	motivation	0	0	none	Unlike most previous methods that achieve this goal based on mappings between lexicalized phrases and logical predicates , this paper goes one step further and proposes a novel embedding-based approach that maps NL-questions into LFs for KB-QA by leveraging semantic associations between lexical representations and KB-properties in the latent space .	
CL	D14-1071	3	mn	secondary	result_means	outcomes	none	none	2	-1	support	Experimental results demonstrate that our proposed method outperforms three KB-QA baseline methods on two publicly released QA data sets .	Unlike most previous methods that achieve this goal based on mappings between lexicalized phrases and logical predicates , this paper goes one step further and proposes a novel embedding-based approach that maps NL-questions into LFs for KB-QA by leveraging semantic associations between lexical representations and KB-properties in the latent space .
CL	D14-1072	1	mn	secondary	motivation_problem	motivation	none	none	2	1	support	Wikipedia's link structure is a valuable resource for natural language processing tasks , but only a fraction of the concepts mentioned in each article are annotated with hyperlinks .	In this paper , we study how to augment Wikipedia with additional high-precision links .
CL	D14-1072	2	mn	main	proposal	proposal	none	none	0	0	none	In this paper , we study how to augment Wikipedia with additional high-precision links .	
CL	D14-1072	3	mn	secondary	proposal_implementation	proposal	none	none	2	-1	elaboration	We present 3W , a system that identifies concept mentions in Wikipedia text , and links each mention to its referent page .	In this paper , we study how to augment Wikipedia with additional high-precision links .
CL	D14-1072	4	mn	secondary	proposal_implementation	proposal	motivation_hypothesis	motivation	3	-1	elaboration	3W leverages rich semantic information present in Wikipedia to achieve high precision .	We present 3W , a system that identifies concept mentions in Wikipedia text , and links each mention to its referent page .
CL	D14-1072	5	mn	secondary	observation	outcomes	none	none	2	-3	support	Our experiments demonstrate that 3W can add an average of seven new links to each Wikipedia article , at a precision of 0.98 .	In this paper , we study how to augment Wikipedia with additional high-precision links .
CL	D14-1073	1	mn	main	proposal	proposal	none	none	0	0	none	In this paper we present our task-based evaluation of query biased summarization for cross-language information retrieval ( CLIR ) using relevance prediction .	
CL	D14-1073	2	mn	secondary	proposal_implementation	proposal	none	none	1	-1	elaboration	We describe our 13 summarization methods each from one of four summarization strategies .	In this paper we present our task-based evaluation of query biased summarization for cross-language information retrieval ( CLIR ) using relevance prediction .
CL	D14-1073	3	mn	secondary	means	method	proposal_implementation	proposal	5	2	by-means	We show how well our methods perform using Farsi text from the CLEF 2008 shared-task , which we translated to English automtatically .	We found that different summarization methods perform optimally for different evaluation metrics , but overall query biased word clouds are the best summarization strategy .
CL	D14-1073	4	mn	secondary	means	method	none	none	5	1	by-means	We report precision/recall/F1 , accuracy and time-on-task .	We found that different summarization methods perform optimally for different evaluation metrics , but overall query biased word clouds are the best summarization strategy .
CL	D14-1073	5	mn	secondary	result	outcomes	none	none	6	1	elaboration	We found that different summarization methods perform optimally for different evaluation metrics , but overall query biased word clouds are the best summarization strategy .	In our analysis , we demonstrate that using the ROUGE metric on our sentence-based summaries cannot make the same kinds of distinctions as our evaluation framework does .
CL	D14-1073	6	mn	secondary	result	outcomes	none	none	7	1	support	In our analysis , we demonstrate that using the ROUGE metric on our sentence-based summaries cannot make the same kinds of distinctions as our evaluation framework does .	Finally , we present our recommendations for creating muchneeded evaluation standards and datasets .
CL	D14-1073	7	mn	secondary	conclusion	outcomes	none	none	1	-6	support	Finally , we present our recommendations for creating muchneeded evaluation standards and datasets .	In this paper we present our task-based evaluation of query biased summarization for cross-language information retrieval ( CLIR ) using relevance prediction .
CL	D14-1074	1	mn	main	proposal	proposal	none	none	0	0	none	We propose a model for Chinese poem generation based on recurrent neural networks which we argue is ideally suited to capturing poetic content and form .	
CL	D14-1074	2	mn	secondary	proposal_implementation	proposal	none	none	1	-1	elaboration	Our generator jointly performs content selection ( "what to say" ) and surface realization ( "how to say" ) by learning representations of individual characters , and their combinations into one or more lines as well as how these mutually reinforce and constrain each other .	We propose a model for Chinese poem generation based on recurrent neural networks which we argue is ideally suited to capturing poetic content and form .
CL	D14-1074	3	mn	secondary	proposal_implementation	proposal	none	none	2	-1	elaboration	Poem lines are generated incrementally by taking into account the entire history of what has been generated so far rather than the limited horizon imposed by the previous line or lexical n-grams .	Our generator jointly performs content selection ( "what to say" ) and surface realization ( "how to say" ) by learning representations of individual characters , and their combinations into one or more lines as well as how these mutually reinforce and constrain each other .
CL	D14-1074	4	mn	secondary	result	outcomes	none	none	1	-3	support	Experimental results show that our model outperforms competitive Chinese poetry generation systems using both automatic and manual evaluation methods .	We propose a model for Chinese poem generation based on recurrent neural networks which we argue is ideally suited to capturing poetic content and form .
CL	D14-1075	1	mn	main	proposal	proposal	none	none	0	0	none	This paper explores alternate algorithms , reward functions and feature sets for performing multi-document summarization using reinforcement learning with a high focus on reproducibility .	
CL	D14-1075	2	mn	secondary	result	outcomes	none	none	1	-1	support	We show that ROUGE results can be improved using a unigram and bigram similarity metric when training a learner to select sentences for summarization .	This paper explores alternate algorithms , reward functions and feature sets for performing multi-document summarization using reinforcement learning with a high focus on reproducibility .
CL	D14-1075	3	mn	secondary	means	method	none	none	2	-1	by-means	Learners are trained to summarize document clusters based on various algorithms and reward functions and then evaluated using ROUGE .	We show that ROUGE results can be improved using a unigram and bigram similarity metric when training a learner to select sentences for summarization .
CL	D14-1075	4	mn	secondary	observation	outcomes	none	none	2	-2	support	Our experiments show a statistically significant improvement of 1.33 % , 1.58 % , and 2.25 % for ROUGE-1 , ROUGE-2 and ROUGE-L scores , respectively , when compared with the performance of the state of the art in automatic summarization with reinforcement learning on the DUC2004 dataset .	We show that ROUGE results can be improved using a unigram and bigram similarity metric when training a learner to select sentences for summarization .
CL	D14-1075	5	mn	secondary	observation	outcomes	none	none	2	-3	support	Furthermore query focused extensions of our approach show an improvement of 1.37 % and 2.31 % for ROUGE-2 and ROUGE-SU4 respectively over query focused extensions of the state of the art with reinforcement learning on the DUC2006 dataset .	We show that ROUGE results can be improved using a unigram and bigram similarity metric when training a learner to select sentences for summarization .
CL	D14-1076	1	mn	main	proposal	proposal	none	none	0	0	none	In this paper , we focus on the problem of using sentence compression techniques to improve multi-document summarization .	
CL	D14-1076	2	mn	secondary	proposal_implementation	proposal	none	none	1	-1	elaboration	We propose an innovative sentence compression method by considering every node in the constituent parse tree and deciding its status - remove or retain .	In this paper , we focus on the problem of using sentence compression techniques to improve multi-document summarization .
CL	D14-1076	3	mn	secondary	proposal_implementation	proposal	none	none	2	-1	elaboration	Integer liner programming with discriminative training is used to solve the problem .	We propose an innovative sentence compression method by considering every node in the constituent parse tree and deciding its status - remove or retain .
CL	D14-1076	4	mn	secondary	proposal_implementation	proposal	none	none	3	-1	elaboration	Under this model , we incorporate various constraints to improve the linguistic quality of the compressed sentences .	Integer liner programming with discriminative training is used to solve the problem .
CL	D14-1076	5	mn	secondary	proposal_implementation	proposal	none	none	4	-1	sequence	Then we utilize a pipeline summarization framework where sentences are first compressed by our proposed compression model to obtain top-n candidates and then a sentence selection module is used to generate the final summary .	Under this model , we incorporate various constraints to improve the linguistic quality of the compressed sentences .
CL	D14-1076	6	mn	secondary	result_means	outcomes	none	none	1	-5	support	Compared with state-of-the-art algorithms , our model has similar ROUGE-2 scores but better linguistic quality on TAC data .	In this paper , we focus on the problem of using sentence compression techniques to improve multi-document summarization .
CL	D14-1077	1	mn	main	proposal	proposal	none	none	0	0	none	In this study , we analyzed the effects of applying different levels of stemming approaches such as fixed-length word truncation and morphological analysis for multi-document summarization ( MDS ) on Turkish , which is an agglutinative and morphologically rich language .	
CL	D14-1077	2	mn	secondary	proposal_implementation	proposal	none	none	1	-1	elaboration	We constructed a manually annotated MDS data set , and to our best knowledge , reported the first results on Turkish MDS .	In this study , we analyzed the effects of applying different levels of stemming approaches such as fixed-length word truncation and morphological analysis for multi-document summarization ( MDS ) on Turkish , which is an agglutinative and morphologically rich language .
CL	D14-1077	3	mn	secondary	result	outcomes	none	none	1	-2	support	Our results show that a simple fixed-length word truncation approach performs slightly better than no stemming , whereas applying complex morphological analysis does not improve Turkish MDS .	In this study , we analyzed the effects of applying different levels of stemming approaches such as fixed-length word truncation and morphological analysis for multi-document summarization ( MDS ) on Turkish , which is an agglutinative and morphologically rich language .
CL	D14-1078	1	mn	secondary	motivation_background	motivation	none	none	2	1	info-required	The ability to learn from user interactions can give systems access to unprecedented amounts of knowledge .	This is evident in search engines , recommender systems , and electronic commerce , and it can be the key to solving other knowledge in-tensive tasks .
CL	D14-1078	2	mn	secondary	motivation_background	motivation	none	none	3	1	info-required	This is evident in search engines , recommender systems , and electronic commerce , and it can be the key to solving other knowledge in-tensive tasks .	However , extracting the knowledge conveyed by user interactions is less straightforward than standard machine learning , since it requires learning systems that explicitly account for human decision making , human motivation , and human abilities .
CL	D14-1078	3	mn	secondary	motivation_problem	motivation	none	none	4	1	support	However , extracting the knowledge conveyed by user interactions is less straightforward than standard machine learning , since it requires learning systems that explicitly account for human decision making , human motivation , and human abilities .	In this talk , I argue that the design space of such interactive learning systems encompasses not only the machine learning algorithm itself , but also the design of the interaction under an appropriate model of user behavior .
CL	D14-1078	4	mn	secondary	motivation_hypothesis	motivation	none	none	5	1	support	In this talk , I argue that the design space of such interactive learning systems encompasses not only the machine learning algorithm itself , but also the design of the interaction under an appropriate model of user behavior .	To this effect , the talk explores how integrating microeconomic models of human behavior into the learning process leads to new interaction models and their associated learning algorithms , leading to systems that have provable guarantees and that perform robustly in practice .
CL	D14-1078	5	mn	main	proposal	proposal	conclusion	outcomes	0	0	none	To this effect , the talk explores how integrating microeconomic models of human behavior into the learning process leads to new interaction models and their associated learning algorithms , leading to systems that have provable guarantees and that perform robustly in practice .	
CL	D14-1079	1	mn	main	proposal	proposal	none	none	0	0	none	We provide a comparative study between neural word representations and traditional vector spaces based on co-occurrence counts , in a number of compositional tasks .	
CL	D14-1079	2	mn	secondary	proposal_implementation	proposal	none	none	1	-1	elaboration	We use three different semantic spaces and implement seven tensor-based compositional models , which we then test ( together with simpler additive and multiplicative approaches ) in tasks involving verb disambiguation and sentence similarity .	We provide a comparative study between neural word representations and traditional vector spaces based on co-occurrence counts , in a number of compositional tasks .
CL	D14-1079	3	mn	secondary	proposal_implementation	proposal	means	method	2	-1	elaboration	To check their scalability , we additionally evaluate the spaces using simple compositional methods on larger-scale tasks with less constrained language : paraphrase detection and dialogue act tagging .	We use three different semantic spaces and implement seven tensor-based compositional models , which we then test ( together with simpler additive and multiplicative approaches ) in tasks involving verb disambiguation and sentence similarity .
CL	D14-1079	4	mn	secondary	result_means	outcomes	none	none	1	-3	support	In the more constrained tasks , co-occurrence vectors are competitive , although choice of compositional method is important ; on the larger-scale tasks , they are outperformed by neural word embeddings , which show robust , stable performance across the tasks .	We provide a comparative study between neural word representations and traditional vector spaces based on co-occurrence counts , in a number of compositional tasks .
CL	D14-1080	1	mn	secondary	motivation_background	motivation	none	none	2	1	info-required	Recurrent neural networks ( RNNs ) are connectionist models of sequential data that are naturally applicable to the analysis of natural language .	Recently , "depth in space" — as an orthogonal notion to "depth in time" — in RNNs has been investigated by stacking multiple layers of RNNs and shown empirically to bring a temporal hierarchy to the architecture .
CL	D14-1080	2	mn	secondary	motivation_background	motivation	none	none	3	1	support	Recently , "depth in space" — as an orthogonal notion to "depth in time" — in RNNs has been investigated by stacking multiple layers of RNNs and shown empirically to bring a temporal hierarchy to the architecture .	In this work we apply these deep RNNs to the task of opinion expression extraction formulated as a token-level sequence-labeling task .
CL	D14-1080	3	mn	main	proposal	proposal	none	none	0	0	none	In this work we apply these deep RNNs to the task of opinion expression extraction formulated as a token-level sequence-labeling task .	
CL	D14-1080	4	mn	secondary	result	outcomes	none	none	3	-1	support	Experimental results show that deep , narrow RNNs outperform traditional shallow , wide RNNs with the same number of parameters .	In this work we apply these deep RNNs to the task of opinion expression extraction formulated as a token-level sequence-labeling task .
CL	D14-1080	5	mn	secondary	result	outcomes	none	none	4	-1	elaboration	Furthermore , our approach outperforms previous CRF-based baselines , including the state-of-the-art semi-Markov CRF model , and does so without access to the powerful opinion lexicons and syntactic features relied upon by the semi-CRF , as well as without the standard layer-by-layer pre-training typically required of RNN architectures .	Experimental results show that deep , narrow RNNs outperform traditional shallow , wide RNNs with the same number of parameters .
CL	D14-1081	1	mn	main	proposal	proposal	none	none	0	0	none	We propose the first implementation of an infinite-order generative dependency model .	
CL	D14-1081	2	mn	secondary	proposal_implementation	proposal	none	none	1	-1	elaboration	The model is based on a new recursive neural network architecture , the Inside-Outside Recursive Neural Network .	We propose the first implementation of an infinite-order generative dependency model .
CL	D14-1081	3	mn	secondary	proposal_implementation	proposal	none	none	2	-1	elaboration	This architecture allows information to flow not only bottom-up , as in traditional recursive neural networks , but also top-down .	The model is based on a new recursive neural network architecture , the Inside-Outside Recursive Neural Network .
CL	D14-1081	4	mn	secondary	proposal_implementation	proposal	none	none	3	-1	elaboration	This is achieved by computing content as well as context representations for any constituent , and letting these representations interact .	This architecture allows information to flow not only bottom-up , as in traditional recursive neural networks , but also top-down .
CL	D14-1081	5	mn	secondary	result_means	outcomes	none	none	1	-4	support	Experimental results on the English section of the Universal Dependency Treebank show that the infinite-order model achieves a perplexity seven times lower than the traditional third-order model using counting , and tends to choose more accurate parses in k-best lists .	We propose the first implementation of an infinite-order generative dependency model .
CL	D14-1081	6	mn	secondary	result	outcomes	none	none	5	-1	elaboration	In addition , reranking with this model achieves state-of-the-art unlabelled attachment scores and unlabelled exact match scores .	Experimental results on the English section of the Universal Dependency Treebank show that the infinite-order model achieves a perplexity seven times lower than the traditional third-order model using counting , and tends to choose more accurate parses in k-best lists .
CL	D14-1082	1	mn	secondary	motivation_background	motivation	none	none	2	1	info-required	Almost all current dependency parsers classify based on millions of sparse indicator features .	Not only do these features generalize poorly , but the cost of feature computation restricts parsing speed significantly .
CL	D14-1082	2	mn	secondary	motivation_problem	motivation	none	none	3	1	support	Not only do these features generalize poorly , but the cost of feature computation restricts parsing speed significantly .	In this work , we propose a novel way of learning a neural network classifier for use in a greedy , transition-based dependency parser .
CL	D14-1082	3	mn	main	proposal	proposal	none	none	0	0	none	In this work , we propose a novel way of learning a neural network classifier for use in a greedy , transition-based dependency parser .	
CL	D14-1082	4	mn	secondary	result_means	outcomes	none	none	3	-1	support	Because this classifier learns and uses just a small number of dense features , it can work very fast , while achiev-ing an about 2 % improvement in unlabeled and labeled attachment scores on both English and Chinese datasets .	In this work , we propose a novel way of learning a neural network classifier for use in a greedy , transition-based dependency parser .
CL	D14-1082	5	mn	secondary	observation	outcomes	none	none	4	-1	support	Concretely , our parser is able to parse more than 1000 sentences per second at 92.2 % unlabeled attachment score on the English Penn Treebank .	Because this classifier learns and uses just a small number of dense features , it can work very fast , while achiev-ing an about 2 % improvement in unlabeled and labeled attachment scores on both English and Chinese datasets .
CL	D14-1083	1	mn	secondary	motivation_background	motivation	none	none	2	1	info-required	Recent years have seen a surge of interest in stance classification in online debates .	Oftentimes , however , it is important to determine not only the stance expressed by an author in her debate posts , but also the reasons behind her supporting or opposing the issue under debate .
CL	D14-1083	2	mn	secondary	motivation_problem	motivation	none	none	3	1	support	Oftentimes , however , it is important to determine not only the stance expressed by an author in her debate posts , but also the reasons behind her supporting or opposing the issue under debate .	We therefore examine the new task of reason classification in this paper .
CL	D14-1083	3	mn	main	proposal	proposal	none	none	0	0	none	We therefore examine the new task of reason classification in this paper .	
CL	D14-1083	4	mn	secondary	proposal_implementation	proposal	motivation_background	motivation	3	-1	elaboration	Given the close in-terplay between stance classification and reason classification , we design computational models for examining how automatically computed stance information can be profitably exploited for reason classification .	We therefore examine the new task of reason classification in this paper .
CL	D14-1083	5	mn	secondary	result_means	outcomes	none	none	3	-2	support	Experiments on our reason-annotated corpus of ideological debate posts from four domains demonstrate that sophisticated models of stances and reasons can indeed yield more accurate reason and stance classification results than their simpler counterparts .	We therefore examine the new task of reason classification in this paper .
CL	D14-1084	1	mn	secondary	motivation_problem	motivation	none	none	2	1	support	State-of-the-art Chinese zero pronoun resolution systems are supervised , thus relying on training data containing manually resolved zero pronouns .	To eliminate the reliance on annotated data , we present a generative model for unsupervised Chinese zero pronoun resolution .
CL	D14-1084	2	mn	main	proposal	proposal	none	none	0	0	none	To eliminate the reliance on annotated data , we present a generative model for unsupervised Chinese zero pronoun resolution .	
CL	D14-1084	3	mn	secondary	motivation_hypothesis	motivation	none	none	2	-1	support	At the core of our model is a novel hypothesis : a probabilistic pronoun resolver trained on overt pronouns in an unsupervised manner can be used to resolve zero pronouns .	To eliminate the reliance on annotated data , we present a generative model for unsupervised Chinese zero pronoun resolution .
CL	D14-1084	4	mn	secondary	result_means	outcomes	none	none	2	-2	support	Experiments demonstrate that our unsupervised model rivals its state-of-the-art supervised counterparts in performance when resolving the Chinese zero pronouns in the OntoNotes corpus .	To eliminate the reliance on annotated data , we present a generative model for unsupervised Chinese zero pronoun resolution .
CL	D14-1085	1	mn	main	proposal	proposal	none	none	0	0	none	We present sentence enhancement as a novel technique for text-to-text generation in abstractive summarization .	
CL	D14-1085	2	mn	secondary	motivation_hypothesis	motivation	proposal_implementation	proposal	1	-1	support	Compared to extraction or previous approaches to sentence fusion , sentence enhancement increases the range of possible summary sentences by allowing the combination of dependency subtrees from any sentence from the source text .	We present sentence enhancement as a novel technique for text-to-text generation in abstractive summarization .
CL	D14-1085	3	mn	secondary	result	outcomes	none	none	1	-2	support	Our experiments indicate that our approach yields summary sentences that are competitive with a sentence fusion baseline in terms of content quality , but better in terms of grammaticality , and that the benefit of sentence enhancement relies crucially on an event coreference resolution algorithm using distributional semantics .	We present sentence enhancement as a novel technique for text-to-text generation in abstractive summarization .
CL	D14-1085	4	mn	secondary	proposal_implementation	proposal	none	none	1	-3	elaboration	We also consider how text-to-text generation approaches to summarization can be extended beyond the source text by examining how human summary writers incorporate source-text-external elements into their summary sentences .	We present sentence enhancement as a novel technique for text-to-text generation in abstractive summarization .
CL	D14-1086	1	mn	main	proposal	proposal	none	none	0	0	none	In this paper we introduce a new game to crowd-source natural language referring expressions .	
CL	D14-1086	2	mn	secondary	proposal_implementation	proposal	none	none	1	-1	elaboration	By designing a two player game , we can both collect and verify referring expressions directly within the game .	In this paper we introduce a new game to crowd-source natural language referring expressions .
CL	D14-1086	3	mn	secondary	observation	outcomes	none	none	4	1	support	To date , the game has produced a dataset containing 130,525 expressions , referring to 96,654 distinct objects , in 19,894 photographs of natural scenes .	This dataset is larger and more varied than previous REG datasets and allows us to study referring expressions in real-world scenes .
CL	D14-1086	4	mn	secondary	result	outcomes	none	none	1	-3	support	This dataset is larger and more varied than previous REG datasets and allows us to study referring expressions in real-world scenes .	In this paper we introduce a new game to crowd-source natural language referring expressions .
CL	D14-1086	5	mn	secondary	proposal_implementation	proposal	none	none	2	-3	elaboration	We provide an in depth analysis of the resulting dataset .	By designing a two player game , we can both collect and verify referring expressions directly within the game .
CL	D14-1086	6	mn	secondary	proposal_implementation	proposal	means	method	5	-1	elaboration	Based on our findings , we design a new optimization based model for generating referring expressions and perform experimental evaluations on 3 test sets .	We provide an in depth analysis of the resulting dataset .
CL	D14-1087	1	mn	main	proposal	proposal	none	none	0	0	none	We propose an unsupervised approach to constructing templates from a large collection of semantic category names , and use the templates as the semantic representation of categories .	
CL	D14-1087	2	mn	secondary	motivation_problem	motivation	none	none	1	-1	support	The main challenge is that many terms have multiple meanings , resulting in a lot of wrong templates .	We propose an unsupervised approach to constructing templates from a large collection of semantic category names , and use the templates as the semantic representation of categories .
CL	D14-1087	3	mn	secondary	proposal_implementation	proposal	none	none	1	-2	elaboration	Statistical data and semantic knowledge are extracted from a web corpus to improve template generation .	We propose an unsupervised approach to constructing templates from a large collection of semantic category names , and use the templates as the semantic representation of categories .
CL	D14-1087	4	mn	secondary	proposal_implementation	proposal	none	none	3	-1	elaboration	A nonlinear scoring function is proposed and demonstrated to be effective .	Statistical data and semantic knowledge are extracted from a web corpus to improve template generation .
CL	D14-1087	5	mn	secondary	result	outcomes	none	none	1	-4	support	Experiments show that our approach achieves significantly better results than baseline methods .	We propose an unsupervised approach to constructing templates from a large collection of semantic category names , and use the templates as the semantic representation of categories .
CL	D14-1087	6	mn	secondary	result_means	outcomes	none	none	5	-1	elaboration	As an immediate application , we apply the extracted templates to the cleaning of a category collection and see promising results ( precision improved from 81 % to 89 % ) .	Experiments show that our approach achieves significantly better results than baseline methods .
CL	D14-1088	1	mn	secondary	motivation_background	motivation	none	none	2	1	info-required	Taxonomies are the backbone of many structured , semantic knowledge resources .	Recent works for extracting taxonomic relations from text focused on collecting lexical-syntactic patterns to extract the taxonomic relations by matching the patterns to text .
CL	D14-1088	2	mn	secondary	motivation_background	motivation	none	none	3	1	info-required	Recent works for extracting taxonomic relations from text focused on collecting lexical-syntactic patterns to extract the taxonomic relations by matching the patterns to text .	These approaches , however , often show low coverage due to the lack of contextual analysis across sentences .
CL	D14-1088	3	mn	secondary	motivation_problem	motivation	none	none	4	1	support	These approaches , however , often show low coverage due to the lack of contextual analysis across sentences .	To address this issue , we propose a novel approach that collectively utilizes contextual information of terms in syntactic structures such that if the set of contexts of a term includes most of contexts of another term , a subsumption relation between the two terms is inferred .
CL	D14-1088	4	mn	main	proposal	proposal	none	none	0	0	none	To address this issue , we propose a novel approach that collectively utilizes contextual information of terms in syntactic structures such that if the set of contexts of a term includes most of contexts of another term , a subsumption relation between the two terms is inferred .	
CL	D14-1088	5	mn	secondary	proposal_implementation	proposal	means	method	4	-1	elaboration	We apply this method to the task of taxonomy construction from scratch , where we introduce another novel graph-based algorithm for taxonomic structure induction .	To address this issue , we propose a novel approach that collectively utilizes contextual information of terms in syntactic structures such that if the set of contexts of a term includes most of contexts of another term , a subsumption relation between the two terms is inferred .
CL	D14-1088	6	mn	secondary	result	outcomes	none	none	4	-2	support	Our experiment results show that the proposed method is well complementary with previous methods of linguistic pattern matching and significantly improves recall and thus F-measure .	To address this issue , we propose a novel approach that collectively utilizes contextual information of terms in syntactic structures such that if the set of contexts of a term includes most of contexts of another term , a subsumption relation between the two terms is inferred .
CL	D14-1089	1	mn	secondary	motivation_problem	motivation	none	none	2	1	support	State-of-the-art fact extraction is heavily constrained by recall , as demonstrated by recent performance in TAC Slot Filling .	We isolate this recall loss for NE slots by systematically analysing each stage of the slot filling pipeline as a filter over correct answers .
CL	D14-1089	2	mn	main	proposal	proposal	none	none	0	0	none	We isolate this recall loss for NE slots by systematically analysing each stage of the slot filling pipeline as a filter over correct answers .	
CL	D14-1089	3	mn	secondary	information_additional	other	none	none	2	-1	info-optional	Recall is critical as candidates never generated can never be recovered , whereas precision can always be increased in downstream processing .	We isolate this recall loss for NE slots by systematically analysing each stage of the slot filling pipeline as a filter over correct answers .
CL	D14-1089	4	mn	secondary	result	outcomes	none	none	2	-2	support	We provide precise , empirical confirmation of previously hypothesised sources of recall loss in slot filling .	We isolate this recall loss for NE slots by systematically analysing each stage of the slot filling pipeline as a filter over correct answers .
CL	D14-1089	5	mn	secondary	result	outcomes	observation	outcomes	4	-1	elaboration	While NE type constraints substantially reduce the search space with only a minor recall penalty , we find that 10 % to 39 % of slot fills will be entirely ignored by most systems .	We provide precise , empirical confirmation of previously hypothesised sources of recall loss in slot filling .
CL	D14-1089	6	mn	secondary	result	outcomes	none	none	4	-2	elaboration	One in six correct answers are lost if coreference is not used , but this can be mostly retained by simple name matching rules .	We provide precise , empirical confirmation of previously hypothesised sources of recall loss in slot filling .
CL	D14-1090	1	mn	secondary	motivation_problem	motivation	motivation_background	motivation	2	1	info-required	Several state-of-the-art event extraction systems employ models based on Support Vector Machines ( SVMs ) in a pipeline architecture , which fails to exploit the joint dependencies that typically exist among events and arguments .	While there have been attempts to overcome this limitation using Markov Logic Networks ( MLNs ) , it remains challenging to perform joint inference in MLNs when the model encodes many high-dimensional sophisticated features such as those essential for event extraction .
CL	D14-1090	2	mn	secondary	motivation_problem	motivation	none	none	3	1	support	While there have been attempts to overcome this limitation using Markov Logic Networks ( MLNs ) , it remains challenging to perform joint inference in MLNs when the model encodes many high-dimensional sophisticated features such as those essential for event extraction .	In this paper , we propose a new model for event extraction that combines the power of MLNs and SVMs , dwarfing their limitations .
CL	D14-1090	3	mn	main	proposal	proposal	none	none	0	0	none	In this paper , we propose a new model for event extraction that combines the power of MLNs and SVMs , dwarfing their limitations .	
CL	D14-1090	4	mn	secondary	proposal_implementation	proposal	none	none	3	-1	elaboration	The key idea is to reliably learn and process high-dimensional features using SVMs ; encode the output of SVMs as low-dimensional , soft formulas in MLNs ; and use the superior joint inferencing power of MLNs to enforce joint consistency constraints over the soft formulas .	In this paper , we propose a new model for event extraction that combines the power of MLNs and SVMs , dwarfing their limitations .
CL	D14-1090	5	mn	secondary	means	method	none	none	6	1	by-means	We evaluate our approach for the task of extracting biomedical events on the BioNLP 2013 , 2011 and 2009 Genia shared task datasets .	Our approach yields the best F1 score to date on the BioNLP'13 ( 53.61 ) and BioNLP'11 ( 58.07 ) datasets and the second-best F1 score to date on the BioNLP'09 dataset ( 58.16 ) .
CL	D14-1090	6	mn	secondary	observation	outcomes	none	none	3	-3	support	Our approach yields the best F1 score to date on the BioNLP'13 ( 53.61 ) and BioNLP'11 ( 58.07 ) datasets and the second-best F1 score to date on the BioNLP'09 dataset ( 58.16 ) .	In this paper , we propose a new model for event extraction that combines the power of MLNs and SVMs , dwarfing their limitations .
CL	D14-1091	1	mn	secondary	motivation_background	motivation	none	none	2	1	info-required	Stress is a useful cue for English word segmentation .	A wide range of computational models have found that stress cues enable a 2-10 % improvement in segmentation accuracy , depending on the kind of model , by using input that has been annotated with stress using a pronouncing dictionary .
CL	D14-1091	2	mn	secondary	motivation_background	motivation	none	none	3	1	info-required	A wide range of computational models have found that stress cues enable a 2-10 % improvement in segmentation accuracy , depending on the kind of model , by using input that has been annotated with stress using a pronouncing dictionary .	However , stress is neither invariably produced nor unambiguously identifiable in real speech .
CL	D14-1091	3	mn	secondary	motivation_problem	motivation	none	none	5	2	support	However , stress is neither invariably produced nor unambiguously identifiable in real speech .	We devise Adaptor Grammar word segmentation models that exploit either stress , or syllable weight , or both , and evaluate the utility of syllable weight as a cue to word boundaries .
CL	D14-1091	4	mn	secondary	motivation_background	motivation	none	none	3	-1	info-required	Heavy syllables , i.e. those with long vowels or syllable codas , attract stress in English .	However , stress is neither invariably produced nor unambiguously identifiable in real speech .
CL	D14-1091	5	mn	main	proposal	proposal	none	none	0	0	none	We devise Adaptor Grammar word segmentation models that exploit either stress , or syllable weight , or both , and evaluate the utility of syllable weight as a cue to word boundaries .	
CL	D14-1091	6	mn	secondary	result	outcomes	none	none	5	-1	support	Our results suggest that syllable weight encodes largely the same information for word segmentation in English that annotated dictionary stress does .	We devise Adaptor Grammar word segmentation models that exploit either stress , or syllable weight , or both , and evaluate the utility of syllable weight as a cue to word boundaries .
CL	D14-1092	1	mn	main	proposal	proposal	none	none	0	0	none	In this paper , we propose a joint model for unsupervised Chinese word segmentation ( CWS ) .	
CL	D14-1092	2	mn	secondary	proposal_implementation	proposal	motivation_background	motivation	1	-1	elaboration	Inspired by the "products of experts" idea , our joint model firstly combines two generative models , which are word-based hierarchical Dirichlet process model and character-based hidden Markov model , by simply multiplying their probabilities together .	In this paper , we propose a joint model for unsupervised Chinese word segmentation ( CWS ) .
CL	D14-1092	3	mn	secondary	proposal_implementation	proposal	none	none	2	-1	elaboration	Gibbs sampling is used for model inference .	Inspired by the "products of experts" idea , our joint model firstly combines two generative models , which are word-based hierarchical Dirichlet process model and character-based hidden Markov model , by simply multiplying their probabilities together .
CL	D14-1092	4	mn	secondary	proposal_implementation	proposal	none	none	3	-1	elaboration	In order to further combine the strength of goodness-based model , we then integrated nVBE into our joint model by using it to initializing the Gibbs sampler .	Gibbs sampling is used for model inference .
CL	D14-1092	5	mn	secondary	means	method	none	none	6	1	by-means	We conduct our experiments on PKU and MSRA datasets provided by the second SIGHAN bakeoff .	Test results on these two datasets show that the joint model achieves much better results than all of its component models .
CL	D14-1092	6	mn	secondary	result	outcomes	none	none	1	-5	support	Test results on these two datasets show that the joint model achieves much better results than all of its component models .	In this paper , we propose a joint model for unsupervised Chinese word segmentation ( CWS ) .
CL	D14-1092	7	mn	secondary	result	outcomes	none	none	6	-1	elaboration	Statistical significance tests also show that it is significantly better than state-of-the-art systems , achieving the highest F-scores .	Test results on these two datasets show that the joint model achieves much better results than all of its component models .
CL	D14-1092	8	mn	secondary	result	outcomes	none	none	7	-1	elaboration	Finally , analysis indicates that compared with nVBE and HDP , the joint model has a stronger ability to solve both combinational and overlapping ambiguities in Chinese word segmentation .	Statistical significance tests also show that it is significantly better than state-of-the-art systems , achieving the highest F-scores .
CL	D14-1093	1	mn	secondary	motivation_background	motivation	none	none	2	1	info-required	Supervised methods have been the dominant approach for Chinese word segmentation .	The performance can drop significantly when the test domain is different from the training domain .
CL	D14-1093	2	mn	secondary	motivation_problem	motivation	none	none	3	1	support	The performance can drop significantly when the test domain is different from the training domain .	In this paper , we study the problem of obtaining partial annotation from freely available data to help Chinese word segmentation on different domains .
CL	D14-1093	3	mn	main	proposal	proposal	none	none	0	0	none	In this paper , we study the problem of obtaining partial annotation from freely available data to help Chinese word segmentation on different domains .	
CL	D14-1093	4	mn	secondary	proposal_implementation	proposal	none	none	3	-1	elaboration	Different sources of free annotations are transformed into a unified form of partial annotation and a variant CRF model is used to leverage both fully and partially annotated data consistently .	In this paper , we study the problem of obtaining partial annotation from freely available data to help Chinese word segmentation on different domains .
CL	D14-1093	5	mn	secondary	result	outcomes	none	none	3	-2	support	Experimental results show that the Chinese word segmentation model benefits from free partially annotated data .	In this paper , we study the problem of obtaining partial annotation from freely available data to help Chinese word segmentation on different domains .
CL	D14-1093	6	mn	secondary	result_means	outcomes	none	none	5	-1	elaboration	On the SIGHAN Bakeoff 2010 data , we achieve results that are competitive to the best reported in the literature .	Experimental results show that the Chinese word segmentation model benefits from free partially annotated data .
CL	D14-1094	1	mn	secondary	motivation_background	motivation	none	none	2	1	info-required	Most studies on statistical Korean word spacing do not utilize the information provided by the input sentence and assume that it was completely concatenated .	This makes the word spacer ignore the correct spaced parts of the input sentence and erroneously alter them .
CL	D14-1094	2	mn	secondary	motivation_problem	motivation	none	none	3	1	support	This makes the word spacer ignore the correct spaced parts of the input sentence and erroneously alter them .	To overcome such limit , this paper proposes a structural SVM-based Korean word spacing method that can utilize the space information of the input sentence .
CL	D14-1094	3	mn	main	proposal	proposal	none	none	0	0	none	To overcome such limit , this paper proposes a structural SVM-based Korean word spacing method that can utilize the space information of the input sentence .	
CL	D14-1094	4	mn	secondary	observation	outcomes	none	none	5	1	support	The experiment on sentences with 10 % spacing errors showed that our method achieved 96.81 % F-score , while the basic structural SVM method only achieved 92.53 % F-score .	The more the input sentence was correctly spaced , the more accurately our method performed .
CL	D14-1094	5	mn	secondary	result	outcomes	none	none	3	-2	support	The more the input sentence was correctly spaced , the more accurately our method performed .	To overcome such limit , this paper proposes a structural SVM-based Korean word spacing method that can utilize the space information of the input sentence .
CL	D14-1095	1	mn	main	proposal	proposal	none	none	0	0	none	We explore the impact of morphological segmentation on keyword spotting ( KWS ) .	
CL	D14-1095	2	mn	secondary	motivation_problem	motivation	none	none	1	-1	support	Despite potential benefits , state-of-the-art KWS systems do not use morphological information .	We explore the impact of morphological segmentation on keyword spotting ( KWS ) .
CL	D14-1095	3	mn	secondary	proposal_implementation	proposal	none	none	1	-2	elaboration	In this paper , we augment a state-of-the-art KWS system with sub-word units derived from supervised and unsupervised morphological segmentations , and compare with phonetic and syllabic segmentations .	We explore the impact of morphological segmentation on keyword spotting ( KWS ) .
CL	D14-1095	4	mn	secondary	result	outcomes	none	none	1	-3	support	Our experiments demonstrate that morphemes improve overall performance of KWS systems .	We explore the impact of morphological segmentation on keyword spotting ( KWS ) .
CL	D14-1095	5	mn	secondary	result	outcomes	none	none	4	-1	elaboration	Syllabic units , however , rival the performance of morphological units when used in KWS .	Our experiments demonstrate that morphemes improve overall performance of KWS systems .
CL	D14-1095	6	mn	secondary	result	outcomes	none	none	5	-1	elaboration	By combining morphological , phonetic and syllabic segmentations , we demonstrate substantial performance gains .	Syllabic units , however , rival the performance of morphological units when used in KWS .
CL	D14-1096	1	mn	main	proposal	proposal	none	none	0	0	none	In this paper we address the problem of multilingual part-of-speech tagging for resource-poor languages .	
CL	D14-1096	2	mn	secondary	proposal_implementation	proposal	none	none	1	-1	elaboration	We use parallel data to transfer part-of-speech information from resource-rich to resource-poor languages .	In this paper we address the problem of multilingual part-of-speech tagging for resource-poor languages .
CL	D14-1096	3	mn	secondary	proposal_implementation	proposal	observation	outcomes	2	-1	elaboration	Additionally , we use a small amount of annotated data to learn to "correct" errors from projected approach such as tagset mismatch between languages , achieving state-of-the-art performance ( 91.3 % ) across 8 languages .	We use parallel data to transfer part-of-speech information from resource-rich to resource-poor languages .
CL	D14-1096	4	mn	secondary	conclusion	outcomes	none	none	1	-3	support	Our approach is based on modest data requirements , and uses minimum divergence classification .	In this paper we address the problem of multilingual part-of-speech tagging for resource-poor languages .
CL	D14-1096	5	mn	secondary	result_means	outcomes	proposal_implementation	proposal	1	-4	support	For situations where no universal tagset mapping is available , we propose an alternate method , resulting in state-of-the-art 85.6 % accuracy on the resource-poor language Malagasy .	In this paper we address the problem of multilingual part-of-speech tagging for resource-poor languages .
CL	D14-1097	1	mn	secondary	information_additional	other	none	none	2	1	info-required	Active learning ( AL ) consists of asking human annotators to annotate automatically selected data that are assumed to bring the most benefit in the creation of a classifier .	AL allows to learn accurate systems with much less annotated data than what is required by pure supervised learning algorithms , hence limiting the tedious effort of annotating a large collection of data .
CL	D14-1097	2	mn	secondary	motivation_background	motivation	none	none	3	1	support	AL allows to learn accurate systems with much less annotated data than what is required by pure supervised learning algorithms , hence limiting the tedious effort of annotating a large collection of data .	We experimentally investigate the behavior of several AL strategies for sequence labeling tasks ( in a partially-labeled scenario ) tailored on Partially-Labeled Conditional Random Fields , on four sequence labeling tasks : phrase chunking , part-of-speech tagging , named-entity recognition , and bio-entity recognition .
CL	D14-1097	3	mn	main	proposal	proposal	none	none	0	0	none	We experimentally investigate the behavior of several AL strategies for sequence labeling tasks ( in a partially-labeled scenario ) tailored on Partially-Labeled Conditional Random Fields , on four sequence labeling tasks : phrase chunking , part-of-speech tagging , named-entity recognition , and bio-entity recognition .	
CL	D14-1098	1	mn	main	proposal	proposal	none	none	0	0	none	In this paper , we propose novel structured language modeling methods for code mixing speech recognition by incorporating a well-known syntactic constraint for switching code , namely the Functional Head Constraint ( FHC ) .	
CL	D14-1098	2	mn	secondary	information_additional	other	none	none	3	1	info-required	Code mixing data is not abundantly available for training language models .	Our proposed methods successfully alleviate this core problem for code mixing speech recognition by using bilingual data to train a structured language model with syntactic constraint .
CL	D14-1098	3	mn	secondary	proposal_implementation	proposal	none	none	1	-2	elaboration	Our proposed methods successfully alleviate this core problem for code mixing speech recognition by using bilingual data to train a structured language model with syntactic constraint .	In this paper , we propose novel structured language modeling methods for code mixing speech recognition by incorporating a well-known syntactic constraint for switching code , namely the Functional Head Constraint ( FHC ) .
CL	D14-1098	4	mn	secondary	motivation_problem	motivation	none	none	5	1	support	Linguists and bilingual speakers found that code switch do not happen between the functional head and its complements .	We propose to learn the code mixing language model from bilingual data with this constraint in a weighted finite state transducer ( WFST ) framework .
CL	D14-1098	5	mn	secondary	proposal_implementation	proposal	none	none	3	-2	elaboration	We propose to learn the code mixing language model from bilingual data with this constraint in a weighted finite state transducer ( WFST ) framework .	Our proposed methods successfully alleviate this core problem for code mixing speech recognition by using bilingual data to train a structured language model with syntactic constraint .
CL	D14-1098	6	mn	secondary	proposal_implementation	proposal	none	none	5	-1	elaboration	The constrained code switch language model is obtained by first expanding the search network with a translation model , and then using parsing to restrict paths to those permissible under the constraint .	We propose to learn the code mixing language model from bilingual data with this constraint in a weighted finite state transducer ( WFST ) framework .
CL	D14-1098	7	mn	secondary	proposal_implementation	proposal	none	none	6	-1	elaboration	We implement and compare two approaches - lattice parsing enables a sequential coupling whereas partial parsing enables a tight coupling between parsing and filtering .	The constrained code switch language model is obtained by first expanding the search network with a translation model , and then using parsing to restrict paths to those permissible under the constraint .
CL	D14-1098	8	mn	secondary	means	method	none	none	11	3	by-means	We tested our system on a lecture speech dataset with 16 % embedded second language , and on a lunch conversation dataset with 20 % embedded language .	Our proposed approach avoids making early decisions on code-switch boundaries and is therefore more robust .
CL	D14-1098	9	mn	secondary	observation	outcomes	none	none	11	2	support	Our language models with lattice parsing and partial parsing reduce word error rates from a baseline mixed language model by 3.8 % and 3.9 % in terms of word error rate relatively on the average on the first and second tasks respectively .	Our proposed approach avoids making early decisions on code-switch boundaries and is therefore more robust .
CL	D14-1098	10	mn	secondary	observation	outcomes	none	none	11	1	support	It outperforms the interpolated language model by 3.7 % and 5.6 % in terms of word error rate relatively , and outperforms the adapted language model by 2.6 % and 4.6 % relatively .	Our proposed approach avoids making early decisions on code-switch boundaries and is therefore more robust .
CL	D14-1098	11	mn	secondary	result	outcomes	none	none	1	-10	support	Our proposed approach avoids making early decisions on code-switch boundaries and is therefore more robust .	In this paper , we propose novel structured language modeling methods for code mixing speech recognition by incorporating a well-known syntactic constraint for switching code , namely the Functional Head Constraint ( FHC ) .
CL	D14-1098	12	mn	secondary	conclusion	outcomes	none	none	1	-11	support	We address the code switch data scarcity challenge by using bilingual data with syntactic structure .	In this paper , we propose novel structured language modeling methods for code mixing speech recognition by incorporating a well-known syntactic constraint for switching code , namely the Functional Head Constraint ( FHC ) .
CL	D14-1099	1	mn	secondary	motivation_background	motivation	none	none	2	1	info-required	The introduction of dynamic oracles has considerably improved the accuracy of greedy transition-based dependency parsers , without sacrificing parsing efficiency .	However , this enhancement is limited to projective parsing , and dynamic oracles have not yet been implemented for parsers supporting non-projectivity .
CL	D14-1099	2	mn	secondary	motivation_problem	motivation	none	none	3	1	support	However , this enhancement is limited to projective parsing , and dynamic oracles have not yet been implemented for parsers supporting non-projectivity .	In this paper we introduce the first such oracle , for a non-projective parser based on Attardi's parser .
CL	D14-1099	3	mn	main	proposal	proposal	none	none	0	0	none	In this paper we introduce the first such oracle , for a non-projective parser based on Attardi's parser .	
CL	D14-1099	4	mn	secondary	conclusion	outcomes	none	none	3	-1	support	We show that training with this oracle improves parsing accuracy over a conventional ( static ) oracle on a wide range of datasets .	In this paper we introduce the first such oracle , for a non-projective parser based on Attardi's parser .
CL	D14-1100	1	mn	secondary	motivation_problem	motivation	none	none	2	1	support	The syntactic ambiguity of a transitive verb ( Vt ) followed by a noun ( N ) has long been a problem in Chinese parsing .	In this paper , we propose a classifier to resolve the ambiguity of Vt-N structures .
CL	D14-1100	2	mn	main	proposal	proposal	none	none	0	0	none	In this paper , we propose a classifier to resolve the ambiguity of Vt-N structures .	
CL	D14-1100	3	mn	secondary	proposal_implementation	proposal	none	none	2	-1	elaboration	The design of the classifier is based on three important guidelines , namely , adopting linguistically motivated features , using all available resources , and easy integration into a parsing model .	In this paper , we propose a classifier to resolve the ambiguity of Vt-N structures .
CL	D14-1100	4	mn	secondary	proposal_implementation	proposal	none	none	3	-1	elaboration	The linguistically motivated features include semantic relations , context , and morphological structures ; and the available resources are treebank , thesaurus , affix database , and large corpora .	The design of the classifier is based on three important guidelines , namely , adopting linguistically motivated features , using all available resources , and easy integration into a parsing model .
CL	D14-1100	5	mn	secondary	proposal_implementation	proposal	none	none	4	-1	elaboration	We also propose two learning approaches that resolve the problem of data sparseness by auto-parsing and extracting relative knowledge from large-scale unlabeled data .	The linguistically motivated features include semantic relations , context , and morphological structures ; and the available resources are treebank , thesaurus , affix database , and large corpora .
CL	D14-1100	6	mn	secondary	result	outcomes	none	none	2	-4	support	Our experiment results show that the Vt-N classifier outperforms the current PCFG parser .	In this paper , we propose a classifier to resolve the ambiguity of Vt-N structures .
CL	D14-1100	7	mn	secondary	result	outcomes	none	none	6	-1	elaboration	Furthermore , it can be easily and effectively integrated into the PCFG parser and general statistical parsing models .	Our experiment results show that the Vt-N classifier outperforms the current PCFG parser .
CL	D14-1100	8	mn	secondary	result	outcomes	none	none	6	-2	support	Evaluation of the learning approaches indicates that world knowledge facilitates Vt-N disambiguation through data selection and error correction .	Our experiment results show that the Vt-N classifier outperforms the current PCFG parser .
CL	D14-1101	1	mn	main	proposal	proposal	none	none	0	0	none	We propose a neural network approach to benefit from the non-linearity of corpus-wide statistics for part-of-speech ( POS ) tagging .	
CL	D14-1101	2	mn	secondary	proposal_implementation	proposal	none	none	1	-1	elaboration	We investigated several types of corpus-wide information for the words , such as word embeddings and POS tag distributions .	We propose a neural network approach to benefit from the non-linearity of corpus-wide statistics for part-of-speech ( POS ) tagging .
CL	D14-1101	3	mn	secondary	proposal_implementation	proposal	none	none	2	-1	elaboration	Since these statistics are encoded as dense continuous features , it is not trivial to combine these features comparing with sparse discrete features .	We investigated several types of corpus-wide information for the words , such as word embeddings and POS tag distributions .
CL	D14-1101	4	mn	secondary	proposal_implementation	proposal	none	none	3	-1	elaboration	Our tagger is designed as a combination of a linear model for discrete features and a feed-forward neural network that captures the non-linear interactions among the continuous features .	Since these statistics are encoded as dense continuous features , it is not trivial to combine these features comparing with sparse discrete features .
CL	D14-1101	5	mn	secondary	proposal_implementation	proposal	result	outcomes	4	-1	elaboration	By using several recent advances in the activation functions for neural networks , the proposed method marks new state-of-the-art accuracies for English POS tagging tasks .	Our tagger is designed as a combination of a linear model for discrete features and a feed-forward neural network that captures the non-linear interactions among the continuous features .
CL	D14-1102	1	mn	secondary	motivation_background	motivation	none	none	2	1	info-required	Different approaches to high-quality grammatical error correction have been proposed recently , many of which have their own strengths and weaknesses .	Most of these approaches are based on classification or statistical machine translation ( SMT ) .
CL	D14-1102	2	mn	secondary	motivation_background	motivation	none	none	3	1	support	Most of these approaches are based on classification or statistical machine translation ( SMT ) .	In this paper , we propose to combine the output from a classification-based system and an SMT-based system to improve the correction quality .
CL	D14-1102	3	mn	main	proposal	proposal	none	none	0	0	none	In this paper , we propose to combine the output from a classification-based system and an SMT-based system to improve the correction quality .	
CL	D14-1102	4	mn	secondary	proposal_implementation	proposal	none	none	3	-1	elaboration	We adopt the system combination technique of Heafield and Lavie ( 2010 ) .	In this paper , we propose to combine the output from a classification-based system and an SMT-based system to improve the correction quality .
CL	D14-1102	5	mn	secondary	result_means	outcomes	none	none	3	-2	support	We achieve an F0.5 score of 39.39 % on the test set of the CoNLL-2014 shared task , outperforming the best system in the shared task .	In this paper , we propose to combine the output from a classification-based system and an SMT-based system to improve the correction quality .
CL	D14-1103	1	mn	main	proposal	proposal	none	none	0	0	none	In this paper we propose a method to increase dependency parser performance without using additional labeled or unlabeled data by refining the layer of predicted part-of-speech ( POS ) tags .	
CL	D14-1103	2	mn	secondary	result_means	outcomes	none	none	1	-1	support	We perform experiments on English and German and show significant improvements for both languages .	In this paper we propose a method to increase dependency parser performance without using additional labeled or unlabeled data by refining the layer of predicted part-of-speech ( POS ) tags .
CL	D14-1103	3	mn	secondary	proposal_implementation	proposal	none	none	1	-2	elaboration	The refinement is based on generative split-merge training for Hidden Markov models ( HMMs ) .	In this paper we propose a method to increase dependency parser performance without using additional labeled or unlabeled data by refining the layer of predicted part-of-speech ( POS ) tags .
CL	D14-1104	1	mn	secondary	motivation_background	motivation	none	none	2	1	info-required	Importance weighting is a generalization of various statistical bias correction techniques .	While our labeled data in NLP is heavily biased , importance weighting has seen only few applications in NLP , most of them relying on a small amount of labeled target data .
CL	D14-1104	2	mn	secondary	motivation_background	motivation	none	none	3	1	info-required	While our labeled data in NLP is heavily biased , importance weighting has seen only few applications in NLP , most of them relying on a small amount of labeled target data .	The publication bias toward reporting positive results makes it hard to say whether researchers have tried .
CL	D14-1104	3	mn	secondary	motivation_problem	motivation	none	none	4	1	support	The publication bias toward reporting positive results makes it hard to say whether researchers have tried .	This paper presents a negative result on unsupervised domain adaptation for POS tagging .
CL	D14-1104	4	mn	main	proposal	proposal	none	none	0	0	none	This paper presents a negative result on unsupervised domain adaptation for POS tagging .	
CL	D14-1104	5	mn	secondary	proposal_implementation	proposal	none	none	4	-1	elaboration	In this setup , we only have unlabeled data and thus only indirect access to the bias in emission and transition probabilities .	This paper presents a negative result on unsupervised domain adaptation for POS tagging .
CL	D14-1104	6	mn	secondary	information_additional	other	none	none	7	1	info-required	Moreover , most errors in POS tagging are due to unseen words , and there , importance weighting cannot help .	We present experiments with a wide variety of weight functions , quantilizations , as well as with randomly generated weights , to support these claims .
CL	D14-1104	7	mn	secondary	proposal_implementation	proposal	none	none	5	-2	elaboration	We present experiments with a wide variety of weight functions , quantilizations , as well as with randomly generated weights , to support these claims .	In this setup , we only have unlabeled data and thus only indirect access to the bias in emission and transition probabilities .
CL	D14-1105	1	mn	secondary	motivation_background	motivation	none	none	2	1	info-required	Code-mixing is frequently observed in user generated content on social media , especially from multilingual users .	The linguistic complexity of such content is compounded by presence of spelling variations , transliteration and non-adherance to formal grammar .
CL	D14-1105	2	mn	secondary	motivation_problem	motivation	none	none	3	1	support	The linguistic complexity of such content is compounded by presence of spelling variations , transliteration and non-adherance to formal grammar .	We describe our initial efforts to create a multi-level annotated corpus of Hindi-English code-mixed text collated from Facebook forums , and explore language identification , back-transliteration , normalization and POS tagging of this data .
CL	D14-1105	3	mn	main	proposal	proposal	none	none	0	0	none	We describe our initial efforts to create a multi-level annotated corpus of Hindi-English code-mixed text collated from Facebook forums , and explore language identification , back-transliteration , normalization and POS tagging of this data .	
CL	D14-1105	4	mn	secondary	conclusion	outcomes	none	none	3	-1	support	Our results show that language identification and transliteration for Hindi are two major challenges that impact POS tagging accuracy .	We describe our initial efforts to create a multi-level annotated corpus of Hindi-English code-mixed text collated from Facebook forums , and explore language identification , back-transliteration , normalization and POS tagging of this data .
CL	D14-1106	1	mn	main	proposal	proposal	none	none	0	0	none	We investigate grammatical error detection in spoken language , and present a data-driven method to train a dependency parser to automatically identify and label grammatical errors .	
CL	D14-1106	2	mn	secondary	information_additional	other	none	none	1	-1	info-optional	This method is agnostic to the label set used , and the only manual annotations needed for training are grammatical error labels .	We investigate grammatical error detection in spoken language , and present a data-driven method to train a dependency parser to automatically identify and label grammatical errors .
CL	D14-1106	3	mn	secondary	result	outcomes	none	none	1	-2	support	We find that the proposed system is robust to disfluencies , so that a separate stage to elide disfluencies is not required .	We investigate grammatical error detection in spoken language , and present a data-driven method to train a dependency parser to automatically identify and label grammatical errors .
CL	D14-1106	4	mn	secondary	result_means	outcomes	none	none	3	-1	elaboration	The proposed system outperforms two baseline systems on two different corpora that use different sets of error tags .	We find that the proposed system is robust to disfluencies , so that a separate stage to elide disfluencies is not required .
CL	D14-1106	5	mn	secondary	observation	outcomes	none	none	3	-2	support	It is able to identify utterances with grammatical errors with an F1-score as high as 0.623 , as compared to a baseline F1 of 0.350 on the same data .	We find that the proposed system is robust to disfluencies , so that a separate stage to elide disfluencies is not required .
CL	D14-1107	1	mn	main	proposal	proposal	none	none	0	0	none	We introduce a new CCG parsing model which is factored on lexical category assignments .	
CL	D14-1107	2	mn	secondary	proposal_implementation	proposal	none	none	1	-1	elaboration	Parsing is then simply a deterministic search for the most probable category sequence that supports a CCG derivation .	We introduce a new CCG parsing model which is factored on lexical category assignments .
CL	D14-1107	3	mn	secondary	proposal_implementation	proposal	none	none	2	-1	elaboration	The parser is extremely simple , with a tiny feature set , no POS tagger , and no statistical model of the derivation or dependencies .	Parsing is then simply a deterministic search for the most probable category sequence that supports a CCG derivation .
CL	D14-1107	4	mn	secondary	information_additional	other	none	none	3	-1	info-optional	Formulating the model in this way allows a highly effective heuristic for A∗parsing , which makes parsing extremely fast .	The parser is extremely simple , with a tiny feature set , no POS tagger , and no statistical model of the derivation or dependencies .
CL	D14-1107	5	mn	secondary	result	outcomes	none	none	1	-4	support	Compared to the standard C&C CCG parser , our model is more accurate out-of-domain , is four times faster , has higher coverage , and is greatly simplified .	We introduce a new CCG parsing model which is factored on lexical category assignments .
CL	D14-1107	6	mn	secondary	result_means	outcomes	none	none	5	-1	elaboration	We also show that using our parser improves the performance of a state-of-the-art question answering system .	Compared to the standard C&C CCG parser , our model is more accurate out-of-domain , is four times faster , has higher coverage , and is greatly simplified .
CL	D14-1108	1	mn	main	proposal	proposal	none	none	0	0	none	We describe a new dependency parser for English tweets , TWEEBOPARSER .	
CL	D14-1108	2	mn	secondary	proposal_implementation	proposal	none	none	1	-1	elaboration	The parser builds on several contributions : new syntactic annotations for a corpus of tweets ( TWEEBANK ) , with conventions informed by the domain ; adaptations to a statistical parsing algorithm ; and a new approach to exploiting out-of-domain Penn Treebank data .	We describe a new dependency parser for English tweets , TWEEBOPARSER .
CL	D14-1108	3	mn	secondary	result_means	outcomes	none	none	1	-2	support	Our experiments show that the parser achieves over 80 % unlabeled attachment accuracy on our new , high-quality test set and measure the benefit of our contributions .	We describe a new dependency parser for English tweets , TWEEBOPARSER .
CL	D14-1108	4	mn	secondary	information_additional	other	none	none	3	-1	info-optional	Our dataset and parser can be found at http : //www.ark.cs.cmu.edu/TweetNLP .	Our experiments show that the parser achieves over 80 % unlabeled attachment accuracy on our new , high-quality test set and measure the benefit of our contributions .
CL	D14-1109	1	mn	secondary	motivation_problem	motivation	none	none	2	1	info-required	Dependency parsing with high-order features results in a provably hard decoding problem .	A lot of work has gone into developing powerful optimization methods for solving these combinatorial problems .
CL	D14-1109	2	mn	secondary	motivation_background	motivation	none	none	3	1	support	A lot of work has gone into developing powerful optimization methods for solving these combinatorial problems .	In contrast , we explore , analyze , and demonstrate that a substantially simpler randomized greedy inference algorithm already suffices for near optimal parsing : a) we analytically quantify the number of local optima that the greedy method has to overcome in the context of first-order parsing ; b) we show that , as a decoding algorithm , the greedy method surpasses dual decomposition in second-order parsing ; c) we empirically demonstrate that our approach with up to third-order and global features outperforms the state-of-the-art dual decomposition and MCMC sampling methods when evaluated on 14 languages of non-projective CoNLL datasets .
CL	D14-1109	3	mn	main	proposal	proposal	result_means	outcomes	0	0	none	In contrast , we explore , analyze , and demonstrate that a substantially simpler randomized greedy inference algorithm already suffices for near optimal parsing : a) we analytically quantify the number of local optima that the greedy method has to overcome in the context of first-order parsing ; b) we show that , as a decoding algorithm , the greedy method surpasses dual decomposition in second-order parsing ; c) we empirically demonstrate that our approach with up to third-order and global features outperforms the state-of-the-art dual decomposition and MCMC sampling methods when evaluated on 14 languages of non-projective CoNLL datasets .	
CL	D14-1110	1	mn	secondary	motivation_background	motivation	none	none	2	1	info-required	Most word representation methods assume that each word owns a single semantic vector .	This is usually problematic because lexical ambiguity is ubiquitous , which is also the problem to be resolved by word sense disambiguation .
CL	D14-1110	2	mn	secondary	motivation_problem	motivation	none	none	3	1	support	This is usually problematic because lexical ambiguity is ubiquitous , which is also the problem to be resolved by word sense disambiguation .	In this paper , we present a unified model for joint word sense representation and disambiguation , which will assign distinct representations for each word sense .
CL	D14-1110	3	mn	main	proposal	proposal	none	none	0	0	none	In this paper , we present a unified model for joint word sense representation and disambiguation , which will assign distinct representations for each word sense .	
CL	D14-1110	4	mn	secondary	proposal_implementation	proposal	none	none	3	-1	elaboration	The basic idea is that both word sense representation ( WSR ) and word sense disambiguation ( WSD ) will benefit from each other : ( 1 ) high-quality WSR will capture rich information about words and senses , which should be helpful for WSD , and ( 2 ) high-quality WSD will provide reliable disambiguated corpora for learning better sense representations .	In this paper , we present a unified model for joint word sense representation and disambiguation , which will assign distinct representations for each word sense .
CL	D14-1110	5	mn	secondary	result	outcomes	none	none	3	-2	support	Experimental results show that , our model improves the performance of contextual word similarity compared to existing WSR methods , outperforms state-of-the-art supervised methods on domain-specific WSD , and achieves competitive performance on coarse-grained all-words WSD .	In this paper , we present a unified model for joint word sense representation and disambiguation , which will assign distinct representations for each word sense .
CL	D14-1111	1	mn	secondary	motivation_background	motivation	none	none	2	1	support	Compositional distributional semantics is a subfield of Computational Linguistics which investigates methods for representing the meanings of phrases and sentences .	In this paper , we explore implementations of a framework based on Combinatory Categorial Grammar ( CCG ) , in which words with certain grammatical types have meanings represented by multi-linear maps ( i.e. multi-dimensional arrays , or tensors ) .
CL	D14-1111	2	mn	main	proposal	proposal	none	none	0	0	none	In this paper , we explore implementations of a framework based on Combinatory Categorial Grammar ( CCG ) , in which words with certain grammatical types have meanings represented by multi-linear maps ( i.e. multi-dimensional arrays , or tensors ) .	
CL	D14-1111	3	mn	secondary	motivation_problem	motivation	none	none	4	1	support	An obstacle to full implemen-tation of the framework is the size of these tensors .	We examine the performance of lower dimensional approximations of transitive verb tensors on a sentence plausibility/selectional preference task .
CL	D14-1111	4	mn	secondary	proposal_implementation	proposal	none	none	2	-2	elaboration	We examine the performance of lower dimensional approximations of transitive verb tensors on a sentence plausibility/selectional preference task .	In this paper , we explore implementations of a framework based on Combinatory Categorial Grammar ( CCG ) , in which words with certain grammatical types have meanings represented by multi-linear maps ( i.e. multi-dimensional arrays , or tensors ) .
CL	D14-1111	5	mn	secondary	result	outcomes	none	none	2	-3	support	We find that the matrices perform as well as , and sometimes even better than , full tensors , allowing a reduction in the number of parameters needed to model the framework .	In this paper , we explore implementations of a framework based on Combinatory Categorial Grammar ( CCG ) , in which words with certain grammatical types have meanings represented by multi-linear maps ( i.e. multi-dimensional arrays , or tensors ) .
CL	D14-1112	1	mn	main	proposal	proposal	none	none	0	0	none	In this paper we propose a computational method for determining the orthographic similarity between Romanian and related languages .	
CL	D14-1112	2	mn	secondary	proposal_implementation	proposal	none	none	1	-1	elaboration	We account for etymons and cognates and we investigate not only the number of related words , but also their forms , quantifying orthographic similarities .	In this paper we propose a computational method for determining the orthographic similarity between Romanian and related languages .
CL	D14-1112	3	mn	secondary	conclusion	outcomes	none	none	1	-2	support	The method we propose is adaptable to any language , as far as resources are available .	In this paper we propose a computational method for determining the orthographic similarity between Romanian and related languages .
CL	D14-1113	1	mn	secondary	motivation_background	motivation	none	none	2	1	info-required	There is rising interest in vector-space word embeddings and their use in NLP , especially given recent methods for their fast estimation at very large scale .	Nearly all this work , however , assumes a single vector per word type—ignoring polysemy and thus jeopardizing their useful-ness for downstream tasks .
CL	D14-1113	2	mn	secondary	motivation_problem	motivation	none	none	3	1	support	Nearly all this work , however , assumes a single vector per word type—ignoring polysemy and thus jeopardizing their useful-ness for downstream tasks .	We present an extension to the Skip-gram model that efficiently learns multiple embeddings per word type .
CL	D14-1113	3	mn	main	proposal	proposal	none	none	0	0	none	We present an extension to the Skip-gram model that efficiently learns multiple embeddings per word type .	
CL	D14-1113	4	mn	secondary	proposal_implementation	proposal	none	none	3	-1	elaboration	It differs from recent related work by jointly performing word sense discrimination and embedding learning , by non-parametrically estimating the number of senses per word type , and by its efficiency and scalability .	We present an extension to the Skip-gram model that efficiently learns multiple embeddings per word type .
CL	D14-1113	5	mn	secondary	result_means	outcomes	none	none	3	-2	support	We present new state-of-the-art results in the word similarity in context task and demonstrate its scalability by training with one machine on a corpus of nearly 1 billion tokens in less than 6 hours .	We present an extension to the Skip-gram model that efficiently learns multiple embeddings per word type .
CL	D14-1114	1	mn	secondary	motivation_background	motivation	none	none	2	1	info-required	Knowledge graphs are recently used for enriching query representations in an entity-aware way for the rich facts organized around entities in it .	However , few of the methods pay attention to non-entity words and clicked websites in queries , which also help conveying user intent .
CL	D14-1114	2	mn	secondary	motivation_problem	motivation	none	none	3	1	support	However , few of the methods pay attention to non-entity words and clicked websites in queries , which also help conveying user intent .	In this paper , we tackle the problem of intent understanding with innovatively representing entity words , refiners and clicked urls as intent topics in a unified knowledge graph based framework , in a way to exploit and expand knowledge graph which we call "tailor" .
CL	D14-1114	3	mn	main	proposal	proposal	none	none	0	0	none	In this paper , we tackle the problem of intent understanding with innovatively representing entity words , refiners and clicked urls as intent topics in a unified knowledge graph based framework , in a way to exploit and expand knowledge graph which we call "tailor" .	
CL	D14-1114	4	mn	secondary	proposal_implementation	proposal	none	none	3	-1	elaboration	We collaboratively exploit global knowledge in knowledge graphs and local contexts in query log to initialize intent representation , then propagate the enriched features in a graph consisting of intent topics using an unsupervised algorithm .	In this paper , we tackle the problem of intent understanding with innovatively representing entity words , refiners and clicked urls as intent topics in a unified knowledge graph based framework , in a way to exploit and expand knowledge graph which we call "tailor" .
CL	D14-1114	5	mn	secondary	conclusion	outcomes	none	none	3	-2	support	The experiments prove intent topics with knowledge graph enriched features significantly enhance intent understanding .	In this paper , we tackle the problem of intent understanding with innovatively representing entity words , refiners and clicked urls as intent topics in a unified knowledge graph based framework , in a way to exploit and expand knowledge graph which we call "tailor" .
CL	D14-1115	1	mn	secondary	motivation_background	motivation	none	none	2	1	support	The role of Web search queries has been demonstrated in the extraction of attributes of instances and classes , or of sets of related instances and their class labels .	This paper explores the acquisition of open-domain commonsense knowledge , usually available as factual knowledge , from Web search queries .
CL	D14-1115	2	mn	main	proposal	proposal	none	none	0	0	none	This paper explores the acquisition of open-domain commonsense knowledge , usually available as factual knowledge , from Web search queries .	
CL	D14-1115	3	mn	secondary	proposal_implementation	proposal	motivation_background	motivation	2	-1	elaboration	Similarly to previous work in open-domain information extraction , knowledge extracted from text - in this case , from queries - takes the form of lexicalized assertions associated with open-domain classes .	This paper explores the acquisition of open-domain commonsense knowledge , usually available as factual knowledge , from Web search queries .
CL	D14-1115	4	mn	secondary	result	outcomes	none	none	2	-2	support	Experimental results indicate that facts extracted from queries complement , and have competitive accuracy levels relative to , facts extracted from Web documents by previous methods .	This paper explores the acquisition of open-domain commonsense knowledge , usually available as factual knowledge , from Web search queries .
CL	D14-1116	1	mn	secondary	motivation_background	motivation	none	none	2	1	info-required	Question Answering over Linked Data ( QALD ) aims to evaluate a question answering system over structured data , the key objective of which is to translate questions posed using natural language into structured queries .	This technique can help common users to directly access open-structured knowledge on the Web and , accordingly , has attracted much attention .
CL	D14-1116	2	mn	secondary	motivation_background	motivation	none	none	3	1	support	This technique can help common users to directly access open-structured knowledge on the Web and , accordingly , has attracted much attention .	To this end , we propose a novel method using first-order logic .
CL	D14-1116	3	mn	secondary	proposal	proposal	none	none	4	1	elaboration	To this end , we propose a novel method using first-order logic .	We formulate the knowledge for resolving the ambiguities in the main three steps of QALD ( phrase detection , phrase-to-semantic-item mapping and semantic item grouping ) as first-order logic clauses in a Markov Logic Network .
CL	D14-1116	4	mn	main	proposal	proposal	none	none	0	0	none	We formulate the knowledge for resolving the ambiguities in the main three steps of QALD ( phrase detection , phrase-to-semantic-item mapping and semantic item grouping ) as first-order logic clauses in a Markov Logic Network .	
CL	D14-1116	5	mn	secondary	proposal_implementation	proposal	none	none	4	-1	elaboration	All clauses can then produce interacted effects in a unified framework and can jointly resolve all ambiguities .	We formulate the knowledge for resolving the ambiguities in the main three steps of QALD ( phrase detection , phrase-to-semantic-item mapping and semantic item grouping ) as first-order logic clauses in a Markov Logic Network .
CL	D14-1116	6	mn	secondary	proposal_implementation	proposal	none	none	5	-1	elaboration	Moreover , our method adopts a pattern-learning strategy for semantic item grouping .	All clauses can then produce interacted effects in a unified framework and can jointly resolve all ambiguities .
CL	D14-1116	7	mn	secondary	conclusion	outcomes	none	none	4	-3	support	In this way , our method can cover more text expressions and answer more questions than previous methods using manually designed patterns .	We formulate the knowledge for resolving the ambiguities in the main three steps of QALD ( phrase detection , phrase-to-semantic-item mapping and semantic item grouping ) as first-order logic clauses in a Markov Logic Network .
CL	D14-1116	8	mn	secondary	result	outcomes	none	none	7	-1	support	The experimental results using open benchmarks demonstrate the effectiveness of the proposed method .	In this way , our method can cover more text expressions and answer more questions than previous methods using manually designed patterns .
CL	D14-1117	1	mn	secondary	motivation_background	motivation	none	none	2	1	support	Much recent work focuses on formal interpretation of natural question utterances , with the goal of executing the resulting structured queries on knowledge graphs ( KGs ) such as Freebase .	Here we address two limitations of this approach when applied to open-domain , entity-oriented Web queries .
CL	D14-1117	2	mn	secondary	proposal	proposal	none	none	6	4	elaboration	Here we address two limitations of this approach when applied to open-domain , entity-oriented Web queries .	We propose a novel technique to segment a telegraphic query and assign a coarse-grained purpose to each segment : a base entity e1 , a relation type r , a target entity type t2 , and contextual words s .
CL	D14-1117	3	mn	secondary	motivation_problem	motivation	none	none	2	-1	support	First , Web queries are rarely well-formed questions .	Here we address two limitations of this approach when applied to open-domain , entity-oriented Web queries .
CL	D14-1117	4	mn	secondary	motivation_problem	motivation	none	none	3	-1	info-required	They are "telegraphic" , with missing verbs , prepositions , clauses , case and phrase clues .	First , Web queries are rarely well-formed questions .
CL	D14-1117	5	mn	secondary	motivation_problem	motivation	none	none	3	-2	elaboration	Second , the KG is always incomplete , unable to directly answer many queries .	First , Web queries are rarely well-formed questions .
CL	D14-1117	6	mn	main	proposal	proposal	none	none	0	0	none	We propose a novel technique to segment a telegraphic query and assign a coarse-grained purpose to each segment : a base entity e1 , a relation type r , a target entity type t2 , and contextual words s .	
CL	D14-1117	7	mn	secondary	proposal_implementation	proposal	none	none	6	-1	elaboration	The query seeks entity e2 ∈ t2 where r ( e1 , e2 ) holds , further evidenced by schema-agnostic words s .	We propose a novel technique to segment a telegraphic query and assign a coarse-grained purpose to each segment : a base entity e1 , a relation type r , a target entity type t2 , and contextual words s .
CL	D14-1117	8	mn	secondary	proposal_implementation	proposal	none	none	7	-1	elaboration	Query segmentation is integrated with the KG and an unstructured corpus where mentions of entities have been linked to the KG .	The query seeks entity e2 ∈ t2 where r ( e1 , e2 ) holds , further evidenced by schema-agnostic words s .
CL	D14-1117	9	mn	secondary	proposal_implementation	proposal	none	none	8	-1	info-optional	We do not trust the best or any specific query segmentation .	Query segmentation is integrated with the KG and an unstructured corpus where mentions of entities have been linked to the KG .
CL	D14-1117	10	mn	secondary	proposal_implementation	proposal	none	none	9	-1	elaboration	Instead , evidence in favor of candidate e2s are aggregated across several segmentations .	We do not trust the best or any specific query segmentation .
CL	D14-1117	11	mn	secondary	result_means	outcomes	none	none	6	-5	support	Extensive experiments on the ClueWeb corpus and parts of Freebase as our KG , using over a thousand telegraphic queries adapted from TREC , INEX , and WebQuestions , show the efficacy of our approach .	We propose a novel technique to segment a telegraphic query and assign a coarse-grained purpose to each segment : a base entity e1 , a relation type r , a target entity type t2 , and contextual words s .
CL	D14-1117	12	mn	secondary	observation	outcomes	none	none	11	-1	support	For one benchmark , MAP improves from 0.2-0.29 ( competitive baselines ) to 0.42 ( our system ) .	Extensive experiments on the ClueWeb corpus and parts of Freebase as our KG , using over a thousand telegraphic queries adapted from TREC , INEX , and WebQuestions , show the efficacy of our approach .
CL	D14-1117	13	mn	secondary	observation	outcomes	none	none	12	-1	elaboration	NDCG @ 10 improves from 0.29-0.36 to 0.54 .	For one benchmark , MAP improves from 0.2-0.29 ( competitive baselines ) to 0.42 ( our system ) .
CL	D14-1118	1	mn	secondary	motivation_background	motivation	none	none	2	1	info-required	Estimating questions' difficulty levels is an important task in community question answering ( CQA ) services .	Previous studies propose to solve this problem based on the question-user comparisons extracted from the question answering threads .
CL	D14-1118	2	mn	secondary	motivation_background	motivation	none	none	3	1	info-required	Previous studies propose to solve this problem based on the question-user comparisons extracted from the question answering threads .	However , they suffer from data sparseness problem as each question only gets a limited number of comparisons .
CL	D14-1118	3	mn	secondary	motivation_problem	motivation	none	none	5	2	support	However , they suffer from data sparseness problem as each question only gets a limited number of comparisons .	In this paper , we propose a novel question difficulty estimation approach called Regularized Competition Model ( RCM ) , which naturally combines question-user comparisons and questions' textual descriptions into a unified framework .
CL	D14-1118	4	mn	secondary	motivation_problem	motivation	none	none	3	-1	elaboration	Moreover , they cannot handle newly posted questions which get no comparisons .	However , they suffer from data sparseness problem as each question only gets a limited number of comparisons .
CL	D14-1118	5	mn	main	proposal	proposal	none	none	0	0	none	In this paper , we propose a novel question difficulty estimation approach called Regularized Competition Model ( RCM ) , which naturally combines question-user comparisons and questions' textual descriptions into a unified framework .	
CL	D14-1118	6	mn	secondary	motivation_hypothesis	motivation	none	none	5	-1	support	By incorporating textual information , RCM can effectively deal with data sparseness problem .	In this paper , we propose a novel question difficulty estimation approach called Regularized Competition Model ( RCM ) , which naturally combines question-user comparisons and questions' textual descriptions into a unified framework .
CL	D14-1118	7	mn	secondary	proposal_implementation	proposal	none	none	5	-2	elaboration	We further employ a K-Nearest Neighbor approach to estimate difficulty levels of newly posted questions , again by leveraging textual similarities .	In this paper , we propose a novel question difficulty estimation approach called Regularized Competition Model ( RCM ) , which naturally combines question-user comparisons and questions' textual descriptions into a unified framework .
CL	D14-1118	8	mn	secondary	result_means	outcomes	none	none	9	1	support	Experiments on two publicly available data sets show that for both well-resolved and newly-posted questions , RCM performs the estimation task significantly better than existing methods , demonstrating the advantage of incorporating textual information .	More interestingly , we observe that RCM might provide an automatic way to quantitatively measure the knowledge levels of words .
CL	D14-1118	9	mn	secondary	conclusion	outcomes	none	none	5	-4	support	More interestingly , we observe that RCM might provide an automatic way to quantitatively measure the knowledge levels of words .	In this paper , we propose a novel question difficulty estimation approach called Regularized Competition Model ( RCM ) , which naturally combines question-user comparisons and questions' textual descriptions into a unified framework .
CL	D14-1119	1	mn	secondary	information_additional	other	none	none	2	1	info-optional	A poll consists of a question and a set of predefined answers from which voters can select .	We present the new problem of vote prediction on comments , which involves determining which of these answers a voter selected given a comment she wrote after voting .
CL	D14-1119	2	mn	main	proposal	proposal	none	none	0	0	none	We present the new problem of vote prediction on comments , which involves determining which of these answers a voter selected given a comment she wrote after voting .	
CL	D14-1119	3	mn	secondary	proposal_implementation	proposal	none	none	2	-1	elaboration	To address this task , we exploit not only the information extracted from the comments but also extra-textual information such as user demographic information and inter-comment constraints .	We present the new problem of vote prediction on comments , which involves determining which of these answers a voter selected given a comment she wrote after voting .
CL	D14-1119	4	mn	secondary	result_means	outcomes	none	none	2	-2	support	In an evaluation involving nearly one million comments collected from the popular SodaHead social polling website , we show that a vote prediction system that exploits only textual information can be improved significantly when extended with extra-textual information .	We present the new problem of vote prediction on comments , which involves determining which of these answers a voter selected given a comment she wrote after voting .
CL	D14-1120	1	mn	main	proposal	proposal	none	none	0	0	none	In this paper we first exploit cash-tags ( " $ " followed by stocks' ticker symbols ) in Twitter to build a stock network , where nodes are stocks connected by edges when two stocks co-occur frequently in tweets .	
CL	D14-1120	2	mn	secondary	proposal_implementation	proposal	none	none	1	-1	elaboration	We then employ a labeled topic model to jointly model both the tweets and the network structure to assign each node and each edge a topic respectively .	In this paper we first exploit cash-tags ( " $ " followed by stocks' ticker symbols ) in Twitter to build a stock network , where nodes are stocks connected by edges when two stocks co-occur frequently in tweets .
CL	D14-1120	3	mn	secondary	conclusion	outcomes	none	none	1	-2	support	This Semantic Stock Network ( SSN ) summarizes discussion topics about stocks and stock relations .	In this paper we first exploit cash-tags ( " $ " followed by stocks' ticker symbols ) in Twitter to build a stock network , where nodes are stocks connected by edges when two stocks co-occur frequently in tweets .
CL	D14-1120	4	mn	secondary	conclusion	outcomes	none	none	3	-1	support	We further show that social sentiment about stock ( node ) topics and stock relationship ( edge ) topics are predictive of each stock's market .	This Semantic Stock Network ( SSN ) summarizes discussion topics about stocks and stock relations .
CL	D14-1120	5	mn	secondary	proposal_implementation	proposal	none	none	2	-3	elaboration	For prediction , we propose to regress the topic-sentiment time-series and the stock's price time series .	We then employ a labeled topic model to jointly model both the tweets and the network structure to assign each node and each edge a topic respectively .
CL	D14-1120	6	mn	secondary	result	outcomes	none	none	1	-5	support	Experimental results demonstrate that topic sentiments from close neighbors are able to help improve the prediction of a stock markedly .	In this paper we first exploit cash-tags ( " $ " followed by stocks' ticker symbols ) in Twitter to build a stock network , where nodes are stocks connected by edges when two stocks co-occur frequently in tweets .
CL	D14-1121	1	mn	secondary	motivation_background	motivation	none	none	2	1	support	Demographic lexica have potential for widespread use in social science , economic , and business applications .	We derive predictive lexica ( words and weights ) for age and gender using regression and classification models from word usage in Facebook , blog , and Twitter data with associated demographic labels .
CL	D14-1121	2	mn	main	proposal	proposal	none	none	0	0	none	We derive predictive lexica ( words and weights ) for age and gender using regression and classification models from word usage in Facebook , blog , and Twitter data with associated demographic labels .	
CL	D14-1121	3	mn	secondary	result_means	outcomes	none	none	2	-1	support	The lexica , made publicly available, achieved state-of-the-art accuracy in language based age and gender prediction over Facebook and Twitter , and were evaluated for generalization across social media genres as well as in limited message situations .	We derive predictive lexica ( words and weights ) for age and gender using regression and classification models from word usage in Facebook , blog , and Twitter data with associated demographic labels .
CL	D14-1122	1	mn	secondary	motivation_background	motivation	none	none	2	1	info-required	Dependency parsing is a core task in NLP , and it is widely used by many applications such as information extraction , ques-tion answering , and machine translation .	In the era of social media , a big challenge is that parsers trained on traditional newswire corpora typically suffer from the domain mismatch issue , and thus perform poorly on social media data .
CL	D14-1122	2	mn	secondary	motivation_problem	motivation	none	none	3	1	support	In the era of social media , a big challenge is that parsers trained on traditional newswire corpora typically suffer from the domain mismatch issue , and thus perform poorly on social media data .	We present a new GFL/FUDG-annotated Chinese treebank with more than 18K tokens from Sina Weibo ( the Chinese equivalent of Twitter ) .
CL	D14-1122	3	mn	main	proposal	proposal	none	none	0	0	none	We present a new GFL/FUDG-annotated Chinese treebank with more than 18K tokens from Sina Weibo ( the Chinese equivalent of Twitter ) .	
CL	D14-1122	4	mn	secondary	proposal_implementation	proposal	none	none	3	-1	elaboration	We formulate the dependency parsing problem as many small and parallelizable arc prediction tasks : for each task , we use a programmable probabilistic first-order logic to infer the dependency arc of a token in the sentence .	We present a new GFL/FUDG-annotated Chinese treebank with more than 18K tokens from Sina Weibo ( the Chinese equivalent of Twitter ) .
CL	D14-1122	5	mn	secondary	result	outcomes	none	none	3	-2	support	In experiments , we show that the proposed model outperforms an off-the-shelf Stanford Chinese parser , as well as a strong MaltParser baseline that is trained on the same in-domain data .	We present a new GFL/FUDG-annotated Chinese treebank with more than 18K tokens from Sina Weibo ( the Chinese equivalent of Twitter ) .
CL	D14-1123	1	mn	secondary	motivation_background	motivation	none	none	2	1	info-optional	Microblog has become a major platform for information about real-world events .	Automatically discovering real-world events from microblog has attracted the attention of many researchers .
CL	D14-1123	2	mn	secondary	motivation_background	motivation	none	none	3	1	info-required	Automatically discovering real-world events from microblog has attracted the attention of many researchers .	However , most of existing work ignore the importance of emotion information for event detection .
CL	D14-1123	3	mn	secondary	motivation_problem	motivation	none	none	4	1	support	However , most of existing work ignore the importance of emotion information for event detection .	We argue that people's emotional reactions immediately reflect the occurring of real-world events and should be important for event detection .
CL	D14-1123	4	mn	secondary	motivation_hypothesis	motivation	none	none	5	1	support	We argue that people's emotional reactions immediately reflect the occurring of real-world events and should be important for event detection .	In this study , we focus on the problem of community-related event detection by community emotions .
CL	D14-1123	5	mn	main	proposal	proposal	none	none	0	0	none	In this study , we focus on the problem of community-related event detection by community emotions .	
CL	D14-1123	6	mn	secondary	proposal_implementation	proposal	none	none	5	-1	elaboration	To address the problem , we propose a novel framework which include the following three key components : microblog emotion classification , community emotion aggregation and community emotion burst detection .	In this study , we focus on the problem of community-related event detection by community emotions .
CL	D14-1123	7	mn	secondary	means	method	none	none	8	1	by-means	We evaluate our approach on real microblog data sets .	Experimental results demonstrate the effectiveness of the proposed framework .
CL	D14-1123	8	mn	secondary	conclusion	outcomes	none	none	5	-3	support	Experimental results demonstrate the effectiveness of the proposed framework .	In this study , we focus on the problem of community-related event detection by community emotions .
CL	D14-1124	1	mn	secondary	motivation_background	motivation	none	none	2	1	info-required	Casual online forums such as Reddit , Slashdot and Digg , are continuing to increase in popularity as a means of communication .	Detecting disagreement in this domain is a considerable challenge .
CL	D14-1124	2	mn	secondary	motivation_problem	motivation	none	none	3	1	support	Detecting disagreement in this domain is a considerable challenge .	Many topics are unique to the conversation on the forum , and the appearance of disagreement may be much more subtle than on political blogs or social media sites such as twitter .
CL	D14-1124	3	mn	secondary	motivation_problem	motivation	none	none	4	1	support	Many topics are unique to the conversation on the forum , and the appearance of disagreement may be much more subtle than on political blogs or social media sites such as twitter .	In this analysis we present a crowd-sourced annotated corpus for topic level disagreement detection in Slashdot , showing that disagreement detection in this domain is difficult even for humans .
CL	D14-1124	4	mn	secondary	proposal	proposal	conclusion	outcomes	0	0	none	In this analysis we present a crowd-sourced annotated corpus for topic level disagreement detection in Slashdot , showing that disagreement detection in this domain is difficult even for humans .	
CL	D14-1124	5	mn	secondary	result	outcomes	none	none	4	-1	support	We then proceed to show that a new set of features determined from the rhetorical structure of the conversation significantly improves the performance on disagreement detection over a baseline consisting of unigram/bigram features , discourse markers , structural features and meta-post features .	In this analysis we present a crowd-sourced annotated corpus for topic level disagreement detection in Slashdot , showing that disagreement detection in this domain is difficult even for humans .
CL	D14-1125	1	mn	secondary	motivation_background	motivation	none	none	2	1	support	Recently , work in NLP was initiated on a type of opinion inference that arises when opinions are expressed toward events which have positive or negative effects on entities ( +/-effect events ) .	This paper addresses methods for creating a lexicon of such events , to support such work on opinion inference .
CL	D14-1125	2	mn	main	proposal	proposal	none	none	0	0	none	This paper addresses methods for creating a lexicon of such events , to support such work on opinion inference .	
CL	D14-1125	3	mn	secondary	proposal_implementation	proposal	none	none	2	-1	elaboration	Due to significant sense ambiguity , our goal is to develop a sense-level rather than word-level lexicon .	This paper addresses methods for creating a lexicon of such events , to support such work on opinion inference .
CL	D14-1125	4	mn	secondary	proposal_implementation	proposal	none	none	3	-1	elaboration	To maximize the effectiveness of different types of information , we combine a graph-based method using WordNet1 relations and a standard classifier using gloss information .	Due to significant sense ambiguity , our goal is to develop a sense-level rather than word-level lexicon .
CL	D14-1125	5	mn	secondary	proposal_implementation	proposal	result	outcomes	4	-1	elaboration	A hybrid between the two gives the best results .	To maximize the effectiveness of different types of information , we combine a graph-based method using WordNet1 relations and a standard classifier using gloss information .
CL	D14-1125	6	mn	secondary	result	outcomes	none	none	5	-1	support	Further , we provide evidence that the model is an effective way to guide manual annotation to find +/-effect senses that are not in the seed set .	A hybrid between the two gives the best results .
CL	D14-1126	1	mn	secondary	motivation_background	motivation	none	none	2	1	support	Aspect-based opinion mining has attracted lots of attention today .	In this paper , we address the problem of product aspect rating prediction , where we would like to extract the product aspects , and predict aspect ratings simultaneously .
CL	D14-1126	2	mn	main	proposal	proposal	none	none	0	0	none	In this paper , we address the problem of product aspect rating prediction , where we would like to extract the product aspects , and predict aspect ratings simultaneously .	
CL	D14-1126	3	mn	secondary	motivation_problem	motivation	none	none	5	2	info-required	Topic models have been widely adapted to jointly model aspects and sentiments , but existing models may not do the prediction task well due to their weakness in sentiment extraction .	To tackle this problem , we propose a sentiment-aligned topic model ( SATM ) , where we incorporate two types of external knowledge : product-level overall rating distribution and word-level sentiment lexicon .
CL	D14-1126	4	mn	secondary	motivation_problem	motivation	none	none	3	-1	support	The sentiment topics usually do not have clear correspondence to commonly used ratings , and the model may fail to extract certain kinds of sentiments due to skewed data .	Topic models have been widely adapted to jointly model aspects and sentiments , but existing models may not do the prediction task well due to their weakness in sentiment extraction .
CL	D14-1126	5	mn	secondary	proposal_implementation	proposal	none	none	2	-3	elaboration	To tackle this problem , we propose a sentiment-aligned topic model ( SATM ) , where we incorporate two types of external knowledge : product-level overall rating distribution and word-level sentiment lexicon .	In this paper , we address the problem of product aspect rating prediction , where we would like to extract the product aspects , and predict aspect ratings simultaneously .
CL	D14-1126	6	mn	secondary	result	outcomes	none	none	2	-4	support	Experiments on real dataset demonstrate that SATM is effective on product aspect rating prediction , and it achieves better performance compared to the existing approaches .	In this paper , we address the problem of product aspect rating prediction , where we would like to extract the product aspects , and predict aspect ratings simultaneously .
CL	D14-1127	1	mn	main	proposal	proposal	none	none	0	0	none	We present a weakly supervised approach for learning hashtags , hashtag patterns , and phrases associated with five emotions : AFFECTION , ANGER/RAGE , FEAR/ANXIETY , JOY , and SADNESS/DISAPPOINTMENT .	
CL	D14-1127	2	mn	secondary	proposal_implementation	proposal	none	none	1	-1	elaboration	Starting with seed hashtags to label an initial set of tweets , we train emotion classifiers and use them to learn new emotion hashtags and hashtag patterns .	We present a weakly supervised approach for learning hashtags , hashtag patterns , and phrases associated with five emotions : AFFECTION , ANGER/RAGE , FEAR/ANXIETY , JOY , and SADNESS/DISAPPOINTMENT .
CL	D14-1127	3	mn	secondary	proposal_implementation	proposal	none	none	2	-1	elaboration	This process then repeats in a bootstrapping framework .	Starting with seed hashtags to label an initial set of tweets , we train emotion classifiers and use them to learn new emotion hashtags and hashtag patterns .
CL	D14-1127	4	mn	secondary	proposal_implementation	proposal	none	none	2	-2	elaboration	Emotion phrases are also extracted from the learned hashtags and used to create phrase-based emotion classifiers .	Starting with seed hashtags to label an initial set of tweets , we train emotion classifiers and use them to learn new emotion hashtags and hashtag patterns .
CL	D14-1127	5	mn	secondary	observation	outcomes	none	none	1	-4	support	We show that the learned set of emotion indicators yields a substantial improve-ment in F-scores , ranging from + % 5 to + % 18 over baseline classifiers .	We present a weakly supervised approach for learning hashtags , hashtag patterns , and phrases associated with five emotions : AFFECTION , ANGER/RAGE , FEAR/ANXIETY , JOY , and SADNESS/DISAPPOINTMENT .
CL	D14-1128	1	mn	secondary	motivation_hypothesis	motivation	none	none	2	1	support	We put forward the hypothesis that high-accuracy sentiment analysis is only possible if word senses with different polarity are accurately recognized .	We provide evidence for this hypothesis in a case study for the adjective "hard" and propose contextually enhanced sentiment lexicons that contain the information necessary for sentiment-relevant sense disambiguation .
CL	D14-1128	2	mn	main	proposal	proposal	none	none	0	0	none	We provide evidence for this hypothesis in a case study for the adjective "hard" and propose contextually enhanced sentiment lexicons that contain the information necessary for sentiment-relevant sense disambiguation .	
CL	D14-1128	3	mn	secondary	result	outcomes	proposal_implementation	proposal	2	-1	support	An experimental evaluation demonstrates that senses with different polarity can be distinguished well using a combination of standard and novel features .	We provide evidence for this hypothesis in a case study for the adjective "hard" and propose contextually enhanced sentiment lexicons that contain the information necessary for sentiment-relevant sense disambiguation .
CL	D14-1129	1	mn	secondary	motivation_background	motivation	none	none	2	1	support	Identifying parallel web pages from bilingual web sites is a crucial step of bilingual resource construction for cross-lingual information processing .	In this paper , we propose a link-based approach to distinguish parallel web pages from bilingual web sites .
CL	D14-1129	2	mn	main	proposal	proposal	none	none	0	0	none	In this paper , we propose a link-based approach to distinguish parallel web pages from bilingual web sites .	
CL	D14-1129	3	mn	secondary	motivation_hypothesis	motivation	motivation_problem	motivation	2	-1	support	Compared with the existing methods , which only employ the internal translation similarity ( such as content-based similarity and page structural similarity ) , we hypothesize that the external translation similarity is an effective feature to identify parallel web pages .	In this paper , we propose a link-based approach to distinguish parallel web pages from bilingual web sites .
CL	D14-1129	4	mn	secondary	information_additional	other	none	none	5	1	info-optional	Within a bilingual web site , web pages are interconnected by hyperlinks .	The basic idea of our method is that the translation similarity of two pages can be inferred from their neighbor pages , which can be adopted as an important source of external similarity .
CL	D14-1129	5	mn	secondary	proposal_implementation	proposal	none	none	2	-3	elaboration	The basic idea of our method is that the translation similarity of two pages can be inferred from their neighbor pages , which can be adopted as an important source of external similarity .	In this paper , we propose a link-based approach to distinguish parallel web pages from bilingual web sites .
CL	D14-1129	6	mn	secondary	proposal_implementation	proposal	none	none	5	-1	elaboration	Thus , the translation similarity of page pairs will influence each other .	The basic idea of our method is that the translation similarity of two pages can be inferred from their neighbor pages , which can be adopted as an important source of external similarity .
CL	D14-1129	7	mn	secondary	proposal_implementation	proposal	none	none	2	-5	elaboration	An iterative algorithm is developed to estimate the external translation similarity and the final translation similarity .	In this paper , we propose a link-based approach to distinguish parallel web pages from bilingual web sites .
CL	D14-1129	8	mn	secondary	proposal_implementation	proposal	none	none	7	-1	elaboration	Both internal and external similarity measures are combined in the iterative algorithm .	An iterative algorithm is developed to estimate the external translation similarity and the final translation similarity .
CL	D14-1129	9	mn	secondary	result_means	outcomes	none	none	2	-7	support	Experiments on six bilingual websites demonstrate that our method is effective and obtains significant improvement ( 6.2 % F-Score ) over the baseline which only utilizes internal translation similarity .	In this paper , we propose a link-based approach to distinguish parallel web pages from bilingual web sites .
CL	D14-1130	1	mn	secondary	motivation_background	motivation	none	none	2	1	info-required	Analyses of computer aided translation typically focus on either frontend interfaces and human effort , or backend translation and machine learnability of corrections .	However , this distinction is artificial in practice since the frontend and backend must work in concert .
CL	D14-1130	2	mn	secondary	motivation_problem	motivation	none	none	3	1	support	However , this distinction is artificial in practice since the frontend and backend must work in concert .	We present the first holistic , quantitative evaluation of these issues by contrasting two assistive modes : post-editing and interactive machine translation ( MT ) .
CL	D14-1130	3	mn	main	proposal	proposal	none	none	0	0	none	We present the first holistic , quantitative evaluation of these issues by contrasting two assistive modes : post-editing and interactive machine translation ( MT ) .	
CL	D14-1130	4	mn	secondary	proposal_implementation	proposal	none	none	3	-1	elaboration	We describe a new translator interface , extensive modifications to a phrase-based MT system , and a novel objective function for re-tuning to human corrections .	We present the first holistic , quantitative evaluation of these issues by contrasting two assistive modes : post-editing and interactive machine translation ( MT ) .
CL	D14-1130	5	mn	secondary	result_means	outcomes	none	none	3	-2	support	Evaluation with professional bilingual translators shows that post-edit is faster than interactive at the cost of translation quality for French-English and English-German .	We present the first holistic , quantitative evaluation of these issues by contrasting two assistive modes : post-editing and interactive machine translation ( MT ) .
CL	D14-1130	6	mn	secondary	result	outcomes	proposal_implementation	proposal	5	-1	elaboration	However , re-tuning the MT system to interactive output leads to larger , statistically significant reductions in HTER versus re-tuning to post-edit .	Evaluation with professional bilingual translators shows that post-edit is faster than interactive at the cost of translation quality for French-English and English-German .
CL	D14-1130	7	mn	secondary	result	outcomes	none	none	6	-1	elaboration	Analysis shows that tuning directly to HTER results in fine-grained corrections to subsequent machine output .	However , re-tuning the MT system to interactive output leads to larger , statistically significant reductions in HTER versus re-tuning to post-edit .
CL	D14-1131	1	mn	secondary	motivation_background	motivation	none	none	2	1	support	The combinatorial space of translation derivations in phrase-based statistical machine translation is given by the intersection between a translation lattice and a target language model .	We replace this in-tractable intersection by a tractable relaxation which incorporates a low-order upperbound on the language model .
CL	D14-1131	2	mn	main	proposal	proposal	none	none	0	0	none	We replace this in-tractable intersection by a tractable relaxation which incorporates a low-order upperbound on the language model .	
CL	D14-1131	3	mn	secondary	proposal_implementation	proposal	none	none	2	-1	elaboration	Exact optimisation is achieved through a coarse-to-fine strategy with connections to adaptive rejection sampling .	We replace this in-tractable intersection by a tractable relaxation which incorporates a low-order upperbound on the language model .
CL	D14-1131	4	mn	secondary	proposal_implementation	proposal	means	method	3	-1	elaboration	We perform exact optimisation with unpruned language models of order 3 to 5 and show search-error curves for beam search and cube pruning on standard test sets .	Exact optimisation is achieved through a coarse-to-fine strategy with connections to adaptive rejection sampling .
CL	D14-1131	5	mn	secondary	conclusion	outcomes	none	none	2	-3	support	This is the first work to tractably tackle exact optimisation with language models of orders higher than 3 .	We replace this in-tractable intersection by a tractable relaxation which incorporates a low-order upperbound on the language model .
CL	D14-1132	1	mn	secondary	motivation_background	motivation	none	none	2	1	info-required	Recent work by Cherry ( 2013 ) has shown that directly optimizing phrase-based reordering models towards BLEU can lead to significant gains .	Their approach is limited to small training sets of a few thousand sentences and a similar number of sparse features .
CL	D14-1132	2	mn	secondary	motivation_problem	motivation	none	none	3	1	support	Their approach is limited to small training sets of a few thousand sentences and a similar number of sparse features .	We show how the expected BLEU objective allows us to train a simple linear discriminative reordering model with millions of sparse features on hundreds of thousands of sentences resulting in significant improvements .
CL	D14-1132	3	mn	main	proposal	proposal	result	outcomes	0	0	none	We show how the expected BLEU objective allows us to train a simple linear discriminative reordering model with millions of sparse features on hundreds of thousands of sentences resulting in significant improvements .	
CL	D14-1132	4	mn	secondary	result	outcomes	none	none	3	-1	support	A comparison to likelihood training demonstrates that expected BLEU is vastly more effective .	We show how the expected BLEU objective allows us to train a simple linear discriminative reordering model with millions of sparse features on hundreds of thousands of sentences resulting in significant improvements .
CL	D14-1132	5	mn	secondary	observation	outcomes	means	method	3	-2	support	Our best results improve a hierarchical lexicalized reordering baseline by up to 2.0 BLEU in a single-reference setting on a French-English WMT 2012 setup .	We show how the expected BLEU objective allows us to train a simple linear discriminative reordering model with millions of sparse features on hundreds of thousands of sentences resulting in significant improvements .
CL	D14-1133	1	mn	secondary	motivation_background	motivation	motivation_problem	motivation	2	1	support	Numerous works in Statistical Machine Translation ( SMT ) have attempted to identify better translation hypotheses obtained by an initial decoding using an improved , but more costly scoring function .	In this work , we introduce an approach that takes the hypotheses produced by a state-of-the-art , reranked phrase-based SMT system , and explores new parts of the search space by applying rewriting rules selected on the basis of posterior phrase-level confidence .
CL	D14-1133	2	mn	main	proposal	proposal	none	none	0	0	none	In this work , we introduce an approach that takes the hypotheses produced by a state-of-the-art , reranked phrase-based SMT system , and explores new parts of the search space by applying rewriting rules selected on the basis of posterior phrase-level confidence .	
CL	D14-1133	3	mn	secondary	result_means	outcomes	none	none	2	-1	support	In the medical domain , we obtain a 1.9 BLEU improvement over a reranked baseline exploiting the same scoring function , corresponding to a 5.4 BLEU improvement over the original Moses baseline .	In this work , we introduce an approach that takes the hypotheses produced by a state-of-the-art , reranked phrase-based SMT system , and explores new parts of the search space by applying rewriting rules selected on the basis of posterior phrase-level confidence .
CL	D14-1133	4	mn	secondary	result	outcomes	none	none	3	-1	elaboration	We show that if an indication of which phrases require rewriting is provided , our automatic rewriting procedure yields an additional improvement of 1.5 BLEU .	In the medical domain , we obtain a 1.9 BLEU improvement over a reranked baseline exploiting the same scoring function , corresponding to a 5.4 BLEU improvement over the original Moses baseline .
CL	D14-1133	5	mn	secondary	result	outcomes	none	none	4	-1	elaboration	Various analyses , including a manual error analysis , further illustrate the good performance and potential for improvement of our approach in spite of its simplicity .	We show that if an indication of which phrases require rewriting is provided , our automatic rewriting procedure yields an additional improvement of 1.5 BLEU .
CL	D14-1134	1	mn	main	proposal	proposal	none	none	0	0	none	We present methods to control the lexicon size when learning a Combinatory Categorial Grammar semantic parser .	
CL	D14-1134	2	mn	secondary	motivation_background	motivation	none	none	3	1	support	Existing methods incrementally expand the lexicon by greedily adding entries , considering a single training datapoint at a time .	We propose using corpus-level statistics for lexicon learning decisions .
CL	D14-1134	3	mn	secondary	proposal	proposal	none	none	1	-2	elaboration	We propose using corpus-level statistics for lexicon learning decisions .	We present methods to control the lexicon size when learning a Combinatory Categorial Grammar semantic parser .
CL	D14-1134	4	mn	secondary	proposal_implementation	proposal	none	none	3	-1	elaboration	We introduce voting to globally consider adding entries to the lexicon , and pruning to remove entries no longer required to explain the training data .	We propose using corpus-level statistics for lexicon learning decisions .
CL	D14-1134	5	mn	secondary	result_means	outcomes	none	none	1	-4	support	Our methods result in state-of-the-art performance on the task of executing sequences of natural language instructions , achieving up to 25 % error reduction , with lexicons that are up to 70 % smaller and are qualitatively less noisy .	We present methods to control the lexicon size when learning a Combinatory Categorial Grammar semantic parser .
CL	D14-1135	1	mn	main	proposal	proposal	none	none	0	0	none	In this paper , we demonstrate that significant performance gains can be achieved in CCG semantic parsing by introducing a linguistically motivated grammar induction scheme .	
CL	D14-1135	2	mn	secondary	proposal_implementation	proposal	none	none	1	-1	elaboration	We present a new morpho-syntactic factored lexicon that models systematic variations in morphology , syntax , and semantics across word classes .	In this paper , we demonstrate that significant performance gains can be achieved in CCG semantic parsing by introducing a linguistically motivated grammar induction scheme .
CL	D14-1135	3	mn	secondary	proposal_implementation	proposal	none	none	2	-1	elaboration	The grammar uses domain-independent facts about the English language to restrict the number of incorrect parses that must be considered , thereby enabling effective learning from less data .	We present a new morpho-syntactic factored lexicon that models systematic variations in morphology , syntax , and semantics across word classes .
CL	D14-1135	4	mn	secondary	result_means	outcomes	none	none	1	-3	support	Experiments in benchmark domains match previous models with one quarter of the data and provide new state-of-the-art results with all available data , including up to 45 % relative test-error reduction .	In this paper , we demonstrate that significant performance gains can be achieved in CCG semantic parsing by introducing a linguistically motivated grammar induction scheme .
CL	D14-1136	1	mn	main	proposal	proposal	none	none	0	0	none	We present a model for the automatic semantic analysis of requirements elicitation documents .	
CL	D14-1136	2	mn	secondary	proposal_implementation	proposal	none	none	1	-1	elaboration	Our target semantic representation employs live sequence charts , a multi-modal visual language for scenario-based programming , which can be directly translated into executable code .	We present a model for the automatic semantic analysis of requirements elicitation documents .
CL	D14-1136	3	mn	secondary	proposal_implementation	proposal	none	none	2	-1	elaboration	The architecture we propose integrates sentence-level and discourse-level processing in a generative probabilistic framework for the analysis and disambiguation of individual sentences in context .	Our target semantic representation employs live sequence charts , a multi-modal visual language for scenario-based programming , which can be directly translated into executable code .
CL	D14-1136	4	mn	secondary	result	outcomes	none	none	1	-3	support	We show empirically that the discourse-based model consistently outperforms the sentence-based model when constructing a system that reflects all the static ( entities , properties ) and dynamic ( behavioral scenarios ) requirements in the document .	We present a model for the automatic semantic analysis of requirements elicitation documents .
CL	D14-1137	1	mn	main	proposal	proposal	none	none	0	0	none	We propose a novel model for parsing natural language sentences into their formal semantic representations .	
CL	D14-1137	2	mn	secondary	proposal_implementation	proposal	none	none	1	-1	elaboration	The model is able to perform integrated lexicon acquisition and semantic parsing , mapping each atomic element in a complete semantic representation to a contiguous word sequence in the input sentence in a recursive manner , where certain overlappings amongst such word sequences are allowed .	We propose a novel model for parsing natural language sentences into their formal semantic representations .
CL	D14-1137	3	mn	secondary	proposal_implementation	proposal	none	none	2	-1	elaboration	It defines distributions over the novel relaxed hybrid tree structures which jointly represent both sentences and semantics .	The model is able to perform integrated lexicon acquisition and semantic parsing , mapping each atomic element in a complete semantic representation to a contiguous word sequence in the input sentence in a recursive manner , where certain overlappings amongst such word sequences are allowed .
CL	D14-1137	4	mn	secondary	proposal_implementation	proposal	none	none	3	-1	elaboration	Such structures allow tractable dynamic programming algorithms to be developed for efficient learning and decoding .	It defines distributions over the novel relaxed hybrid tree structures which jointly represent both sentences and semantics .
CL	D14-1137	5	mn	secondary	proposal_implementation	proposal	none	none	2	-3	elaboration	Trained under a discriminative setting , our model is able to incorporate a rich set of features where certain unbounded long-distance dependencies can be captured in a principled manner .	The model is able to perform integrated lexicon acquisition and semantic parsing , mapping each atomic element in a complete semantic representation to a contiguous word sequence in the input sentence in a recursive manner , where certain overlappings amongst such word sequences are allowed .
CL	D14-1137	6	mn	secondary	result_means	outcomes	none	none	1	-5	support	We demonstrate through experiments that by exploiting a large collection of simple features , our model is shown to be competitive to previous works and achieves state-of-the-art performance on standard benchmark data across four different languages .	We propose a novel model for parsing natural language sentences into their formal semantic representations .
CL	D14-1137	7	mn	secondary	information_additional	other	none	none	1	-6	info-optional	The system and code can be downloaded from http ://statnlp.org/research/sp/ .	We propose a novel model for parsing natural language sentences into their formal semantic representations .
CL	D14-1138	1	mn	secondary	motivation_background	motivation	none	none	2	1	info-required	The anchor words algorithm performs provably efficient topic model inference by finding an approximate convex hull in a high-dimensional word co-occurrence space .	However , the existing greedy algorithm often selects poor anchor words , reducing topic quality and interpretability .
CL	D14-1138	2	mn	secondary	motivation_problem	motivation	none	none	3	1	support	However , the existing greedy algorithm often selects poor anchor words , reducing topic quality and interpretability .	Rather than finding an approximate convex hull in a high-dimensional space , we propose to find an exact convex hull in a visualizable 2- or 3-dimensional space .
CL	D14-1138	3	mn	main	proposal	proposal	motivation_problem	motivation	0	0	none	Rather than finding an approximate convex hull in a high-dimensional space , we propose to find an exact convex hull in a visualizable 2- or 3-dimensional space .	
CL	D14-1138	4	mn	secondary	result	outcomes	none	none	3	-1	support	Such low-dimensional embeddings both improve topics and clearly show users why the algorithm selects certain words .	Rather than finding an approximate convex hull in a high-dimensional space , we propose to find an exact convex hull in a visualizable 2- or 3-dimensional space .
CL	D14-1139	1	mn	main	proposal	proposal	none	none	0	0	none	We generalize contrastive estimation in two ways that permit adding more knowledge to unsupervised learning .	
CL	D14-1139	2	mn	secondary	proposal_implementation	proposal	none	none	1	-1	elaboration	The first allows the modeler to specify not only the set of corrupted inputs for each observation , but also how bad each one is .	We generalize contrastive estimation in two ways that permit adding more knowledge to unsupervised learning .
CL	D14-1139	3	mn	secondary	proposal_implementation	proposal	none	none	2	-1	elaboration	The second allows specifying structural preferences on the latent variable used to explain the observations .	The first allows the modeler to specify not only the set of corrupted inputs for each observation , but also how bad each one is .
CL	D14-1139	4	mn	secondary	proposal_implementation	proposal	none	none	3	-1	elaboration	They require setting additional hyperparameters , which can be problematic in unsupervised learning , so we investigate new methods for unsupervised model selection and system combination .	The second allows specifying structural preferences on the latent variable used to explain the observations .
CL	D14-1139	5	mn	secondary	result_means	outcomes	none	none	1	-4	support	We instantiate these ideas for part-of-speech induction without tag dictionaries , improving over contrastive estimation as well as strong benchmarks from the PASCAL 2012 shared task .	We generalize contrastive estimation in two ways that permit adding more knowledge to unsupervised learning .
CL	D14-1140	1	mn	main	proposal	proposal	none	none	0	0	none	We introduce a reinforcement learning-based approach to simultaneous machine translation—producing a translation while receiving input words— between languages with drastically different word orders : from verb-final languages ( e.g. , German ) to verb-medial languages ( English ) .	
CL	D14-1140	2	mn	secondary	motivation_problem	motivation	none	none	3	1	support	In traditional machine translation , a translator must "wait" for source material to appear before translation begins .	We remove this bottleneck by predicting the final verb in advance .
CL	D14-1140	3	mn	secondary	proposal	proposal	none	none	1	-2	elaboration	We remove this bottleneck by predicting the final verb in advance .	We introduce a reinforcement learning-based approach to simultaneous machine translation—producing a translation while receiving input words— between languages with drastically different word orders : from verb-final languages ( e.g. , German ) to verb-medial languages ( English ) .
CL	D14-1140	4	mn	secondary	proposal_implementation	proposal	none	none	1	-3	elaboration	We use reinforcement learning to learn when to trust predictions about unseen , future portions of the sentence .	We introduce a reinforcement learning-based approach to simultaneous machine translation—producing a translation while receiving input words— between languages with drastically different word orders : from verb-final languages ( e.g. , German ) to verb-medial languages ( English ) .
CL	D14-1140	5	mn	secondary	means	method	none	none	6	1	by-means	We also introduce an evaluation metric to measure expeditiousness and quality .	We show that our new translation model outperforms batch and monotone translation strategies .
CL	D14-1140	6	mn	secondary	result	outcomes	none	none	1	-5	support	We show that our new translation model outperforms batch and monotone translation strategies .	We introduce a reinforcement learning-based approach to simultaneous machine translation—producing a translation while receiving input words— between languages with drastically different word orders : from verb-final languages ( e.g. , German ) to verb-medial languages ( English ) .
CL	D14-1141	1	mn	secondary	motivation_background	motivation	none	none	2	1	info-required	The task of unsupervised induction of probabilistic context-free grammars ( PCFGs ) has attracted a lot of attention in the field of computational linguistics .	Although it is a difficult task , work in this area is still very much in demand since it can contribute to the advancement of language parsing and modelling .
CL	D14-1141	2	mn	secondary	motivation_background	motivation	none	none	3	1	support	Although it is a difficult task , work in this area is still very much in demand since it can contribute to the advancement of language parsing and modelling .	In this work , we describe a new algorithm for PCFG induction based on a principled approach and capable of inducing accurate yet compact artificial natural language grammars and typical context-free grammars .
CL	D14-1141	3	mn	main	proposal	proposal	none	none	0	0	none	In this work , we describe a new algorithm for PCFG induction based on a principled approach and capable of inducing accurate yet compact artificial natural language grammars and typical context-free grammars .	
CL	D14-1141	4	mn	secondary	proposal_implementation	proposal	none	none	3	-1	elaboration	Moreover , this algorithm can work on large grammars and datasets and infers correctly even from small samples .	In this work , we describe a new algorithm for PCFG induction based on a principled approach and capable of inducing accurate yet compact artificial natural language grammars and typical context-free grammars .
CL	D14-1141	5	mn	secondary	result	outcomes	none	none	3	-2	support	Our analysis shows that the type of grammars induced by our algorithm are , in theory , capable of modelling natural language .	In this work , we describe a new algorithm for PCFG induction based on a principled approach and capable of inducing accurate yet compact artificial natural language grammars and typical context-free grammars .
CL	D14-1141	6	mn	secondary	result_means	outcomes	none	none	5	-1	elaboration	One of our experiments shows that our algorithm can potentially outperform the state-of-the-art in unsupervised parsing on the WSJ10 corpus .	Our analysis shows that the type of grammars induced by our algorithm are , in theory , capable of modelling natural language .
CL	D14-1142	1	mn	secondary	motivation_background	motivation	none	none	2	1	support	A common approach in text mining tasks such as text categorization , authorship identification or plagiarism detection is to rely on features like words , part-of-speech tags , stems , or some other high-level linguistic features .	In this work , an approach that uses character n-grams as features is proposed for the task of native language identification .
CL	D14-1142	2	mn	main	proposal	proposal	none	none	0	0	none	In this work , an approach that uses character n-grams as features is proposed for the task of native language identification .	
CL	D14-1142	3	mn	secondary	proposal_implementation	proposal	motivation_problem	motivation	2	-1	elaboration	Instead of doing standard feature selection , the proposed approach combines several string kernels using multiple kernel learning .	In this work , an approach that uses character n-grams as features is proposed for the task of native language identification .
CL	D14-1142	4	mn	secondary	proposal_implementation	proposal	none	none	3	-1	elaboration	Kernel Ridge Regression and Kernel Discriminant Analysis are independently used in the learning stage .	Instead of doing standard feature selection , the proposed approach combines several string kernels using multiple kernel learning .
CL	D14-1142	5	mn	secondary	result_means	outcomes	none	none	6	1	support	The empirical results obtained in all the experiments conducted in this work indicate that the proposed approach achieves state of the art performance in native language identification , reaching an accuracy that is 1.7 % above the top scoring system of the 2013 NLI Shared Task .	Furthermore , the proposed approach has an important advantage in that it is language independent and linguistic theory neutral.
CL	D14-1142	6	mn	secondary	conclusion	outcomes	none	none	2	-4	support	Furthermore , the proposed approach has an important advantage in that it is language independent and linguistic theory neutral.	In this work , an approach that uses character n-grams as features is proposed for the task of native language identification .
CL	D14-1142	7	mn	secondary	result_means	outcomes	none	none	6	-1	support	In the cross-corpus experiment , the proposed approach shows that it can also be topic independent , improving the state of the art system by 32.3 % .	Furthermore , the proposed approach has an important advantage in that it is language independent and linguistic theory neutral.
CL	D14-1143	1	mn	secondary	motivation_background	motivation	motivation_problem	motivation	2	1	info-required	Predicting vocabulary of second language learners is essential to support their language learning ; however , because of the large size of language vocabularies , we cannot collect information on the entire vocabulary .	For practical measurements , we need to sample a small portion of words from the entire vocabulary and predict the rest of the words .
CL	D14-1143	2	mn	secondary	motivation_hypothesis	motivation	none	none	3	1	support	For practical measurements , we need to sample a small portion of words from the entire vocabulary and predict the rest of the words .	In this study , we propose a novel framework for this sampling method .
CL	D14-1143	3	mn	secondary	proposal	proposal	none	none	5	2	elaboration	In this study , we propose a novel framework for this sampling method .	We formalize these heuristic techniques as a graph-based non-interactive active learning method as applied to a special graph .
CL	D14-1143	4	mn	secondary	motivation_problem	motivation	none	none	5	1	support	Current methods rely on simple heuristic techniques involving inflexible manual tuning by educational experts .	We formalize these heuristic techniques as a graph-based non-interactive active learning method as applied to a special graph .
CL	D14-1143	5	mn	main	proposal	proposal	none	none	0	0	none	We formalize these heuristic techniques as a graph-based non-interactive active learning method as applied to a special graph .	
CL	D14-1143	6	mn	secondary	result	outcomes	proposal_implementation	proposal	5	-1	support	We show that by extending the graph , we can support additional functionality such as incorporating domain specificity and sampling from multiple corpora .	We formalize these heuristic techniques as a graph-based non-interactive active learning method as applied to a special graph .
CL	D14-1143	7	mn	secondary	result	outcomes	none	none	6	-1	elaboration	In our experiments , we show that our extended methods outperform other methods in terms of vocabulary prediction accuracy when the number of samples is small .	We show that by extending the graph , we can support additional functionality such as incorporating domain specificity and sampling from multiple corpora .
CL	D14-1144	1	mn	secondary	motivation_background	motivation	none	none	2	1	support	Language transfer , the characteristic second language usage patterns caused by native language interference , is investigated by Second Language Acquisition ( SLA ) researchers seeking to find overused and underused linguistic features .	In this paper we develop and present a methodology for deriving ranked lists of such features .
CL	D14-1144	2	mn	main	proposal	proposal	none	none	0	0	none	In this paper we develop and present a methodology for deriving ranked lists of such features .	
CL	D14-1144	3	mn	secondary	proposal_implementation	proposal	result	outcomes	2	-1	elaboration	Using very large learner data , we show our method's ability to find relevant candidates using sophisticated linguistic features .	In this paper we develop and present a methodology for deriving ranked lists of such features .
CL	D14-1144	4	mn	secondary	proposal_implementation	proposal	none	none	3	-1	elaboration	To illustrate its applicability to SLA research , we formulate plausible language transfer hypotheses supported by current evidence .	Using very large learner data , we show our method's ability to find relevant candidates using sophisticated linguistic features .
CL	D14-1144	5	mn	secondary	conclusion	outcomes	none	none	2	-3	support	This is the first work to extend Native Language Identification to a broader linguistic interpretation of learner data and address the automatic extraction of underused features on a pernative language basis .	In this paper we develop and present a methodology for deriving ranked lists of such features .
CL	D14-1145	1	mn	secondary	motivation_background	motivation	none	none	2	1	info-required	Languages spoken by immigrants change due to contact with the local languages .	Capturing these changes is problematic for current language technologies , which are typically developed for speakers of the standard dialect only .
CL	D14-1145	2	mn	secondary	motivation_problem	motivation	none	none	3	1	support	Capturing these changes is problematic for current language technologies , which are typically developed for speakers of the standard dialect only .	Even when dialectal variants are available for such technologies , we still need to predict which dialect is being used .
CL	D14-1145	3	mn	secondary	motivation_problem	motivation	none	none	4	1	support	Even when dialectal variants are available for such technologies , we still need to predict which dialect is being used .	In this study , we distinguish between the immigrant and the standard dialect of Turkish by focusing on Light Verb Constructions .
CL	D14-1145	4	mn	main	proposal	proposal	none	none	0	0	none	In this study , we distinguish between the immigrant and the standard dialect of Turkish by focusing on Light Verb Constructions .	
CL	D14-1145	5	mn	secondary	observation	outcomes	proposal_implementation	proposal	4	-1	support	We experiment with a number of grammatical and contextual features , achieving over 84 % accuracy ( 56 % baseline ) .	In this study , we distinguish between the immigrant and the standard dialect of Turkish by focusing on Light Verb Constructions .
CL	D14-1146	1	mn	secondary	motivation_background	motivation	none	none	2	1	info-required	Readability is used to provide users with high-quality service in text recommendation or text visualization .	With the increasing use of hand-held devices , reading device is regarded as an important factor for readability .
CL	D14-1146	2	mn	secondary	motivation_background	motivation	none	none	3	1	support	With the increasing use of hand-held devices , reading device is regarded as an important factor for readability .	Therefore , this paper investigates the relationship between readability and reading devices such as a smart phone , a tablet , and paper .
CL	D14-1146	3	mn	main	proposal	proposal	none	none	0	0	none	Therefore , this paper investigates the relationship between readability and reading devices such as a smart phone , a tablet , and paper .	
CL	D14-1146	4	mn	secondary	proposal_implementation	proposal	motivation_hypothesis	motivation	3	-1	elaboration	We suggest readability factors that are strongly related with the readability of a specific device by showing the correlations between various factors in each device and human-rated readability .	Therefore , this paper investigates the relationship between readability and reading devices such as a smart phone , a tablet , and paper .
CL	D14-1146	5	mn	secondary	result	outcomes	none	none	3	-2	support	Our experimental results show that each device has its own readability characteristics , and thus different weights should be imposed on readability factors according to the device type .	Therefore , this paper investigates the relationship between readability and reading devices such as a smart phone , a tablet , and paper .
CL	D14-1146	6	mn	secondary	means	method	none	none	5	-1	elaboration	In order to prove the usefulness of the results , we apply the device-dependent readability to news article recommendation .	Our experimental results show that each device has its own readability characteristics , and thus different weights should be imposed on readability factors according to the device type .
CL	D14-1147	1	mn	main	proposal	proposal	none	none	0	0	none	We propose a new Chinese abbreviation prediction method which can incorporate rich local information while generating the abbreviation globally .	
CL	D14-1147	2	mn	secondary	proposal_implementation	proposal	motivation_background	motivation	1	-1	elaboration	Different to previous character tagging methods , we introduce the minimum semantic unit , which is more fine-grained than character but more coarse-grained than word , to capture word level information in the sequence labeling framework .	We propose a new Chinese abbreviation prediction method which can incorporate rich local information while generating the abbreviation globally .
CL	D14-1147	3	mn	secondary	proposal_implementation	proposal	none	none	2	-1	elaboration	To solve the "character duplication" problem in Chinese abbreviation prediction , we also use a substring tagging strategy to generate local substring tagging candidates .	Different to previous character tagging methods , we introduce the minimum semantic unit , which is more fine-grained than character but more coarse-grained than word , to capture word level information in the sequence labeling framework .
CL	D14-1147	4	mn	secondary	proposal_implementation	proposal	none	none	3	-1	elaboration	We use an integer linear programming ( ILP ) formulation with various constraints to globally decode the final abbreviation from the generated candidates .	To solve the "character duplication" problem in Chinese abbreviation prediction , we also use a substring tagging strategy to generate local substring tagging candidates .
CL	D14-1147	5	mn	secondary	conclusion	outcomes	none	none	1	-4	support	Experiments show that our method outperforms the state-of-the-art systems , without using any extra resource .	We propose a new Chinese abbreviation prediction method which can incorporate rich local information while generating the abbreviation globally .
CL	D14-1148	1	mn	secondary	motivation_background	motivation	none	none	2	1	info-required	It has been shown that news events influence the trends of stock price movements .	However , previous work on news-driven stock market prediction rely on shallow features ( such as bags-of-words , named entities and noun phrases ) , which do not capture structured entity-relation information , and hence cannot represent complete and exact events .
CL	D14-1148	2	mn	secondary	motivation_problem	motivation	none	none	3	1	support	However , previous work on news-driven stock market prediction rely on shallow features ( such as bags-of-words , named entities and noun phrases ) , which do not capture structured entity-relation information , and hence cannot represent complete and exact events .	Recent advances in Open Information Extraction ( Open IE ) techniques enable the extraction of structured events from web-scale data .
CL	D14-1148	3	mn	secondary	motivation_background	motivation	none	none	4	1	support	Recent advances in Open Information Extraction ( Open IE ) techniques enable the extraction of structured events from web-scale data .	We propose to adapt Open IE technology for event-based stock price movement prediction , extracting structured events from large-scale public news without manual efforts .
CL	D14-1148	4	mn	main	proposal	proposal	none	none	0	0	none	We propose to adapt Open IE technology for event-based stock price movement prediction , extracting structured events from large-scale public news without manual efforts .	
CL	D14-1148	5	mn	secondary	proposal_implementation	proposal	none	none	4	-1	elaboration	Both linear and nonlinear models are employed to empirically investigate the hidden and complex relationships between events and the stock market .	We propose to adapt Open IE technology for event-based stock price movement prediction , extracting structured events from large-scale public news without manual efforts .
CL	D14-1148	6	mn	secondary	observation	outcomes	none	none	7	1	support	Largescale experiments show that the accuracy of S&P 500 index prediction is 60 % , and that of individual stock prediction can be over 70 % .	Our event-based system outperforms bags-of-words-based baselines , and previously reported systems trained on S&P 500 stock historical data .
CL	D14-1148	7	mn	secondary	result_means	outcomes	none	none	4	-3	support	Our event-based system outperforms bags-of-words-based baselines , and previously reported systems trained on S&P 500 stock historical data .	We propose to adapt Open IE technology for event-based stock price movement prediction , extracting structured events from large-scale public news without manual efforts .
CL	D14-1149	1	mn	secondary	motivation_problem	motivation	none	none	2	1	support	Automatically identifying related specialist terms is a difficult and important task required to understand the lexical structure of language .	This paper develops a corpus-based method of extracting coherent clusters of satellite terminology— terms on the edge of the lexicon — using co-occurrence networks of unstructured text .
CL	D14-1149	2	mn	main	proposal	proposal	none	none	0	0	none	This paper develops a corpus-based method of extracting coherent clusters of satellite terminology— terms on the edge of the lexicon — using co-occurrence networks of unstructured text .	
CL	D14-1149	3	mn	secondary	proposal_implementation	proposal	none	none	2	-1	elaboration	Term clusters are identified by extracting communities in the co-occurrence graph , after which the largest is discarded and the remaining words are ranked by centrality within a community .	This paper develops a corpus-based method of extracting coherent clusters of satellite terminology— terms on the edge of the lexicon — using co-occurrence networks of unstructured text .
CL	D14-1149	4	mn	secondary	information_additional	other	none	none	3	-1	info-optional	The method is tractable on large corpora , requires no document structure and minimal normalization .	Term clusters are identified by extracting communities in the co-occurrence graph , after which the largest is discarded and the remaining words are ranked by centrality within a community .
CL	D14-1149	5	mn	secondary	result	outcomes	none	none	2	-3	support	The results suggest that the model is able to extract coherent groups of satellite terms in corpora with varying size , content and structure .	This paper develops a corpus-based method of extracting coherent clusters of satellite terminology— terms on the edge of the lexicon — using co-occurrence networks of unstructured text .
CL	D14-1149	6	mn	secondary	result	outcomes	none	none	5	-1	elaboration	The findings also confirm that language consists of a densely connected core ( observed in dictionaries ) and systematic , semantically coherent groups of terms at the edges of the lexicon .	The results suggest that the model is able to extract coherent groups of satellite terms in corpora with varying size , content and structure .
CL	D14-1150	1	ab	secondary	motivation_background	motivation	none	none	2	1	support	Given the large amounts of online textual documents available these days , e.g. , news articles , weblogs , and scientific papers , effective methods for extracting keyphrases , which provide a high-level topic description of a document , are greatly needed .	In this paper , we propose a supervised model for keyphrase extraction from research papers , which are embedded in citation networks .
CL	D14-1150	2	ab	main	proposal	proposal	none	none	0	0	none	In this paper , we propose a supervised model for keyphrase extraction from research papers , which are embedded in citation networks .	
CL	D14-1150	3	ab	secondary	proposal_implementation	proposal	result	outcomes	2	-1	elaboration	To this end , we design novel features based on citation network information and use them in conjunction with traditional features for keyphrase extraction to obtain remarkable improvements in performance over strong baselines .	In this paper , we propose a supervised model for keyphrase extraction from research papers , which are embedded in citation networks .
CL	D14-1151	1	ab	main	proposal	proposal	none	none	0	0	none	We propose to use coreference chains extracted from a large corpus as a resource for semantic tasks .	
CL	D14-1151	2	ab	secondary	proposal_implementation	proposal	none	none	1	-1	elaboration	We extract three million coreference chains and train word embeddings on them .	We propose to use coreference chains extracted from a large corpus as a resource for semantic tasks .
CL	D14-1151	3	ab	secondary	proposal_implementation	proposal	observation	outcomes	2	-1	sequence	Then , we compare these embeddings to word vectors derived from raw text data and show that coreference-based word embeddings improve F1 on the task of antonym classification by up to .09 .	We extract three million coreference chains and train word embeddings on them .
CL	D14-1152	1	ab	main	proposal	proposal	none	none	0	0	none	This paper proposes to apply the continuous vector representations of words for discovering keywords from a financial sentiment lexicon .	
CL	D14-1152	2	ab	secondary	proposal_implementation	proposal	none	none	1	-1	elaboration	In order to capture more keywords , we also incorporate syntactic information into the Continuous Bag-of-Words ( CBOW ) model .	This paper proposes to apply the continuous vector representations of words for discovering keywords from a financial sentiment lexicon .
CL	D14-1152	3	ab	secondary	conclusion	outcomes	none	none	1	-2	support	Experimental results on a task of financial risk prediction using the discovered keywords demonstrate that the proposed approach is good at predicting financial risk .	This paper proposes to apply the continuous vector representations of words for discovering keywords from a financial sentiment lexicon .
CL	D14-1153	1	ab	secondary	motivation_background	motivation	none	none	2	1	support	When it is not possible to compare the suspicious document to the source document ( s ) plagiarism has been committed from , the evidence of plagiarism has to be looked for intrinsically in the document itself .	In this paper , we introduce a novel languageindependent intrinsic plagiarism detection method which is based on a new text representation that we called n-gram classes .
CL	D14-1153	2	ab	main	proposal	proposal	none	none	0	0	none	In this paper , we introduce a novel languageindependent intrinsic plagiarism detection method which is based on a new text representation that we called n-gram classes .	
CL	D14-1153	3	ab	secondary	means	method	none	none	4	1	by-means	The proposed method was evaluated on three publicly available standard corpora .	The obtained results are comparable to the ones obtained by the best state-of-the-art methods .
CL	D14-1153	4	ab	secondary	result	outcomes	none	none	2	-2	support	The obtained results are comparable to the ones obtained by the best state-of-the-art methods .	In this paper , we introduce a novel languageindependent intrinsic plagiarism detection method which is based on a new text representation that we called n-gram classes .
CL	D14-1154	1	ab	secondary	motivation_background	motivation	none	none	2	1	info-required	Several recent papers on Arabic dialect identification have hinted that using a word unigram model is sufficient and effective for the task .	However , most previous work was done on a standard fairly homogeneous dataset of dialectal user comments .
CL	D14-1154	2	ab	secondary	motivation_problem	motivation	none	none	3	1	support	However , most previous work was done on a standard fairly homogeneous dataset of dialectal user comments .	In this paper , we show that training on the standard dataset does not generalize , because a unigram model may be tuned to topics in the comments and does not capture the distinguishing features of dialects .
CL	D14-1154	3	ab	main	proposal	proposal	none	none	0	0	none	In this paper , we show that training on the standard dataset does not generalize , because a unigram model may be tuned to topics in the comments and does not capture the distinguishing features of dialects .	
CL	D14-1154	4	ab	secondary	proposal	proposal	none	none	3	-1	elaboration	We show that effective dialect identification requires that we account for the distinguishing lexical , morphological , and phonological phenomena of dialects .	In this paper , we show that training on the standard dataset does not generalize , because a unigram model may be tuned to topics in the comments and does not capture the distinguishing features of dialects .
CL	D14-1154	5	ab	secondary	observation	outcomes	none	none	4	-1	support	We show that accounting for such can improve dialect detection accuracy by nearly 10 % absolute .	We show that effective dialect identification requires that we account for the distinguishing lexical , morphological , and phonological phenomena of dialects .
CL	D14-1155	1	ab	main	proposal	proposal	none	none	0	0	none	In this paper , we explore the use of keyboard strokes as a means to access the real-time writing process of online authors , analogously to prosody in speech analysis , in the context of deception detection .	
CL	D14-1155	2	ab	secondary	proposal	proposal	none	none	1	-1	elaboration	We show that differences in keystroke patterns like editing maneuvers and duration of pauses can help distinguish between truthful and deceptive writing .	In this paper , we explore the use of keyboard strokes as a means to access the real-time writing process of online authors , analogously to prosody in speech analysis , in the context of deception detection .
CL	D14-1155	3	ab	secondary	result	outcomes	none	none	1	-2	support	Empirical results show that incorporating keystroke-based features lead to improved performance in deception detection in two different domains : online reviews and essays .	In this paper , we explore the use of keyboard strokes as a means to access the real-time writing process of online authors , analogously to prosody in speech analysis , in the context of deception detection .
CL	D14-1156	1	ab	secondary	motivation_background	motivation	none	none	2	1	info-required	Statistical language modeling ( LM ) that purports to quantify the acceptability of a given piece of text has long been an interesting yet challenging research area .	In particular , language modeling for information retrieval ( IR ) has enjoyed remarkable empirical success ; one emerging stream of the LM approach for IR is to employ the pseudo-relevance feedback process to enhance the representation of an input query so as to improve retrieval effectiveness .
CL	D14-1156	2	ab	secondary	motivation_background	motivation	motivation_hypothesis	motivation	3	1	support	In particular , language modeling for information retrieval ( IR ) has enjoyed remarkable empirical success ; one emerging stream of the LM approach for IR is to employ the pseudo-relevance feedback process to enhance the representation of an input query so as to improve retrieval effectiveness .	This paper presents a continuation of such a general line of research and the main contribution is threefold .
CL	D14-1156	3	ab	main	proposal	proposal	none	none	0	0	none	This paper presents a continuation of such a general line of research and the main contribution is threefold .	
CL	D14-1156	4	ab	secondary	proposal	proposal	none	none	3	-1	elaboration	First , we propose a principled framework which can unify the relationships among several widely-used query modeling formulations .	This paper presents a continuation of such a general line of research and the main contribution is threefold .
CL	D14-1156	5	ab	secondary	proposal	proposal	none	none	4	-1	sequence	Second , on top of the successfully developed framework , we propose an extended query modeling formulation by incorporating critical query-specific information cues to guide the model estimation .	First , we propose a principled framework which can unify the relationships among several widely-used query modeling formulations .
CL	D14-1156	6	ab	secondary	proposal	proposal	none	none	5	-1	sequence	Third , we further adopt and formalize such a framework to the speech recognition and summarization tasks .	Second , on top of the successfully developed framework , we propose an extended query modeling formulation by incorporating critical query-specific information cues to guide the model estimation .
CL	D14-1156	7	ab	secondary	result	outcomes	none	none	3	-4	support	A series of empirical experiments reveal the feasibility of such an LM framework and the performance merits of the deduced models on these two tasks .	This paper presents a continuation of such a general line of research and the main contribution is threefold .
CL	D14-1157	1	ab	main	proposal_implementation	proposal	none	none	0	0	none	We study the topic dynamics of interactions in political debates using the 2012 Republican presidential primary debates as data .	
CL	D14-1157	2	ab	secondary	result	outcomes	none	none	1	-1	support	We show that the tendency of candidates to shift topics changes over the course of the election campaign , and that it is correlated with their relative power .	We study the topic dynamics of interactions in political debates using the 2012 Republican presidential primary debates as data .
CL	D14-1157	3	ab	secondary	result	outcomes	none	none	2	-1	elaboration	We also show that our topic shift features help predict candidates' relative rankings .	We show that the tendency of candidates to shift topics changes over the course of the election campaign , and that it is correlated with their relative power .
CL	D14-1158	1	ab	main	proposal_implementation	proposal	none	none	0	0	none	We present power low rank ensembles ( PLRE ) , a flexible framework for n-gram language modeling where ensembles of low rank matrices and tensors are used to obtain smoothed probability estimates of words in context .	
CL	D14-1158	2	ab	secondary	proposal_implementation	proposal	none	none	1	-1	elaboration	Our method can be understood as a generalization of n-gram modeling to non-integer n , and includes standard techniques such as absolute discounting and Kneser-Ney smoothing as special cases .	We present power low rank ensembles ( PLRE ) , a flexible framework for n-gram language modeling where ensembles of low rank matrices and tensors are used to obtain smoothed probability estimates of words in context .
CL	D14-1158	3	ab	secondary	result	outcomes	none	none	1	-2	support	PLRE training is efficient and our approach outperforms state-of-the-art modified Kneser Ney baselines in terms of perplexity on large corpora as well as on BLEU score in a downstream machine translation task .	We present power low rank ensembles ( PLRE ) , a flexible framework for n-gram language modeling where ensembles of low rank matrices and tensors are used to obtain smoothed probability estimates of words in context .
CL	D14-1159	1	ab	secondary	motivation_background	motivation	none	none	2	1	support	Machine reading calls for programs that read and understand text , but most current work only attempts to extract facts from redundant web-scale corpora .	In this paper , we focus on a new reading comprehension task that requires complex reasoning over a single document .
CL	D14-1159	2	ab	main	proposal	proposal	none	none	0	0	none	In this paper , we focus on a new reading comprehension task that requires complex reasoning over a single document .	
CL	D14-1159	3	ab	secondary	proposal_implementation	proposal	none	none	2	-1	elaboration	The input is a paragraph describing a biological process , and the goal is to answer questions that require an understanding of the relations between entities and events in the process .	In this paper , we focus on a new reading comprehension task that requires complex reasoning over a single document .
CL	D14-1159	4	ab	secondary	proposal_implementation	proposal	none	none	3	-1	elaboration	To answer the questions , we first predict a rich structure representing the process in the paragraph .	The input is a paragraph describing a biological process , and the goal is to answer questions that require an understanding of the relations between entities and events in the process .
CL	D14-1159	5	ab	secondary	proposal_implementation	proposal	none	none	4	-1	sequence	Then , we map the question to a formal query , which is executed against the predicted structure .	To answer the questions , we first predict a rich structure representing the process in the paragraph .
CL	D14-1159	6	ab	secondary	result	outcomes	none	none	2	-4	support	We demonstrate that answering questions via predicted structures substantially improves accuracy over baselines that use shallower representations .	In this paper , we focus on a new reading comprehension task that requires complex reasoning over a single document .
CL	D14-1160	1	ab	secondary	motivation_background	motivation	none	none	2	1	info-required	Connecting words with senses , namely , sight , hearing , taste , smell and touch , to comprehend the sensorial information in language is a straightforward task for humans by using commonsense knowledge .	With this in mind , a lexicon associating words with senses would be crucial for the computational tasks aiming at interpretation of language .
CL	D14-1160	2	ab	secondary	motivation_hypothesis	motivation	none	none	3	1	info-required	With this in mind , a lexicon associating words with senses would be crucial for the computational tasks aiming at interpretation of language .	However , to the best of our knowledge , there is no systematic attempt in the literature to build such a resource .
CL	D14-1160	3	ab	secondary	motivation_problem	motivation	none	none	4	1	support	However , to the best of our knowledge , there is no systematic attempt in the literature to build such a resource .	In this paper , we present a sensorial lexicon that associates English words with senses .
CL	D14-1160	4	ab	main	proposal	proposal	none	none	0	0	none	In this paper , we present a sensorial lexicon that associates English words with senses .	
CL	D14-1160	5	ab	secondary	proposal_implementation	proposal	none	none	4	-1	elaboration	To obtain this resource , we apply a computational method based on bootstrapping and corpus statistics .	In this paper , we present a sensorial lexicon that associates English words with senses .
CL	D14-1160	6	ab	secondary	means	method	none	none	7	1	by-means	The quality of the resulting lexicon is evaluated with a gold standard created via crowdsourcing .	The results show that a simple classifier relying on the lexicon outperforms two baselines on a sensory classification task , both at word and sentence level , and confirm the soundness of the proposed approach for the construction of the lexicon and the usefulness of the resource for computational applications .
CL	D14-1160	7	ab	secondary	result	outcomes	none	none	4	-3	support	The results show that a simple classifier relying on the lexicon outperforms two baselines on a sensory classification task , both at word and sentence level , and confirm the soundness of the proposed approach for the construction of the lexicon and the usefulness of the resource for computational applications .	In this paper , we present a sensorial lexicon that associates English words with senses .
CL	D14-1161	1	ab	secondary	motivation_background	motivation	none	none	2	1	support	Many forms of word relatedness have been developed , providing different perspectives on word similarity .	We introduce a Bayesian probabilistic tensor factorization model for synthesizing a single word vector representation and per-perspective linear transformations from any number of word similarity matrices .
CL	D14-1161	2	ab	main	proposal	proposal	none	none	0	0	none	We introduce a Bayesian probabilistic tensor factorization model for synthesizing a single word vector representation and per-perspective linear transformations from any number of word similarity matrices .	
CL	D14-1161	3	ab	secondary	proposal	proposal	none	none	2	-1	elaboration	The resulting word vectors , when combined with the per-perspective linear transformation , approximately recreate while also regularizing and generalizing , each word similarity perspective .	We introduce a Bayesian probabilistic tensor factorization model for synthesizing a single word vector representation and per-perspective linear transformations from any number of word similarity matrices .
CL	D14-1161	4	ab	secondary	conclusion	outcomes	none	none	2	-2	support	Our method can combine manually created semantic resources with neural word embeddings to separate synonyms and antonyms , and is capable of generalizing to words outside the vocabulary of any particular perspective .	We introduce a Bayesian probabilistic tensor factorization model for synthesizing a single word vector representation and per-perspective linear transformations from any number of word similarity matrices .
CL	D14-1161	5	ab	secondary	result_means	outcomes	none	none	4	-1	support	We evaluated the word embeddings with GRE antonym questions , the result achieves the state-of-the-art performance .	Our method can combine manually created semantic resources with neural word embeddings to separate synonyms and antonyms , and is capable of generalizing to words outside the vocabulary of any particular perspective .
CL	D14-1162	1	ab	secondary	motivation_background	motivation	motivation_problem	motivation	2	1	support	Recent methods for learning vector space representations of words have succeeded in capturing fine-grained semantic and syntactic regularities using vector arithmetic , but the origin of these regularities has remained opaque .	We analyze and make explicit the model properties needed for such regularities to emerge in word vectors .
CL	D14-1162	2	ab	main	proposal	proposal	none	none	0	0	none	We analyze and make explicit the model properties needed for such regularities to emerge in word vectors .	
CL	D14-1162	3	ab	secondary	proposal_implementation	proposal	none	none	2	-1	elaboration	The result is a new global log-bilinear regression model that combines the advantages of the two major model families in the literature : global matrix factorization and local context window methods .	We analyze and make explicit the model properties needed for such regularities to emerge in word vectors .
CL	D14-1162	4	ab	secondary	proposal_implementation	proposal	none	none	3	-1	elaboration	Our model efficiently leverages statistical information by training only on the nonzero elements in a word-word co-occurrence matrix , rather than on the entire sparse matrix or on individual context windows in a large corpus .	The result is a new global log-bilinear regression model that combines the advantages of the two major model families in the literature : global matrix factorization and local context window methods .
CL	D14-1162	5	ab	secondary	observation	outcomes	observation	outcomes	3	-2	support	The model produces a vector space with meaningful sub-structure , as evidenced by its performance of 75 % on a recent word analogy task .	The result is a new global log-bilinear regression model that combines the advantages of the two major model families in the literature : global matrix factorization and local context window methods .
CL	D14-1162	6	ab	secondary	result	outcomes	none	none	5	-1	elaboration	It also outperforms related models on similarity tasks and named entity recognition .	The model produces a vector space with meaningful sub-structure , as evidenced by its performance of 75 % on a recent word analogy task .
CL	D14-1163	1	ab	main	proposal	proposal	none	none	0	0	none	We introduce a novel compositional language model that works on Predicate-Argument Structures ( PASs ) .	
CL	D14-1163	2	ab	secondary	proposal_implementation	proposal	none	none	4	2	elaboration	Our model jointly learns word representations and their composition functions using bag-of-words and dependency-based contexts .	This enables our model to capture longrange dependencies between words and to better handle constructs such as verb-object and subject-verb-object relations .
CL	D14-1163	3	ab	secondary	proposal_implementation	proposal	none	none	2	-1	elaboration	Unlike previous word-sequence-based models , our PAS-based model composes arguments into predicates by using the category information from the PAS .	Our model jointly learns word representations and their composition functions using bag-of-words and dependency-based contexts .
CL	D14-1163	4	ab	secondary	proposal	proposal	none	none	1	-3	elaboration	This enables our model to capture longrange dependencies between words and to better handle constructs such as verb-object and subject-verb-object relations .	We introduce a novel compositional language model that works on Predicate-Argument Structures ( PASs ) .
CL	D14-1163	5	ab	secondary	result_means	outcomes	none	none	1	-4	support	We verify this experimentally using two phrase similarity datasets and achieve results comparable to or higher than the previous best results .	We introduce a novel compositional language model that works on Predicate-Argument Structures ( PASs ) .
CL	D14-1163	6	ab	secondary	result_means	outcomes	observation	outcomes	5	-1	elaboration	Our system achieves these results without the need for pre-trained word vectors and using a much smaller training corpus ; despite this , for the subject-verb-object dataset our model improves upon the state of the art by as much as ∼10 % in relative performance .	We verify this experimentally using two phrase similarity datasets and achieve results comparable to or higher than the previous best results .
CL	D14-1164	1	ab	secondary	motivation_problem	motivation	none	none	2	1	support	Broad-coverage relation extraction either requires expensive supervised training data , or suffers from drawbacks inherent to distant supervision .	We present an approach for providing partial supervision to a distantly supervised relation extractor using a small number of carefully selected examples .
CL	D14-1164	2	ab	main	proposal_implementation	proposal	none	none	0	0	none	We present an approach for providing partial supervision to a distantly supervised relation extractor using a small number of carefully selected examples .	
CL	D14-1164	3	ab	secondary	proposal	proposal	none	none	2	-1	elaboration	We compare against established active learning criteria and propose a novel criterion to sample examples which are both uncertain and representative .	We present an approach for providing partial supervision to a distantly supervised relation extractor using a small number of carefully selected examples .
CL	D14-1164	4	ab	secondary	proposal	proposal	none	none	3	-1	elaboration	In this way , we combine the benefits of fine-grained supervision for difficult examples with the coverage of a large distantly supervised corpus .	We compare against established active learning criteria and propose a novel criterion to sample examples which are both uncertain and representative .
CL	D14-1164	5	ab	secondary	observation	outcomes	none	none	2	-3	support	Our approach gives a substantial increase of 3.9 % end-to-end F1 on the 2013 KBP Slot Filling evaluation , yielding a net F1 of 37.7 % .	We present an approach for providing partial supervision to a distantly supervised relation extractor using a small number of carefully selected examples .
CL	D14-1165	1	ab	secondary	motivation_background	motivation	none	none	2	1	support	While relation extraction has traditionally been viewed as a task relying solely on textual data , recent work has shown that by taking as input existing facts in the form of entity-relation triples from both knowledge bases and textual data , the performance of relation extraction can be improved significantly .	Following this new paradigm , we propose a tensor decomposition approach for knowledge base embedding that is highly scalable , and is especially suitable for relation extraction .
CL	D14-1165	2	ab	main	proposal	proposal	none	none	0	0	none	Following this new paradigm , we propose a tensor decomposition approach for knowledge base embedding that is highly scalable , and is especially suitable for relation extraction .	
CL	D14-1165	3	ab	secondary	result_means	outcomes	none	none	2	-1	support	By leveraging relational domain knowledge about entity type information , our learning algorithm is significantly faster than previous approaches and is better able to discover new relations missing from the database .	Following this new paradigm , we propose a tensor decomposition approach for knowledge base embedding that is highly scalable , and is especially suitable for relation extraction .
CL	D14-1165	4	ab	secondary	result	outcomes	none	none	3	-1	elaboration	In addition , when applied to a relation extraction task , our approach alone is comparable to several existing systems , and improves the weighted mean average precision of a state-of-the-art method by 10 points when used as a subcomponent .	By leveraging relational domain knowledge about entity type information , our learning algorithm is significantly faster than previous approaches and is better able to discover new relations missing from the database .
CL	D14-1166	1	ab	secondary	motivation_background	motivation	none	none	3	2	info-required	A promising approach to relation extraction , called weak or distant supervision , exploits an existing database of facts as training data , by aligning it to an unlabeled collection of text documents .	However , distant supervision leads to a challenging multiple instance , multiple label learning problem .
CL	D14-1166	2	ab	secondary	motivation_background	motivation	none	none	1	-1	info-optional	Using this approach , the task of relation extraction can easily be scaled to hundreds of different relationships .	A promising approach to relation extraction , called weak or distant supervision , exploits an existing database of facts as training data , by aligning it to an unlabeled collection of text documents .
CL	D14-1166	3	ab	secondary	motivation_problem	motivation	none	none	4	1	info-required	However , distant supervision leads to a challenging multiple instance , multiple label learning problem .	Most of the proposed solutions to this problem are based on non-convex formulations , and are thus prone to local min-ima .
CL	D14-1166	4	ab	secondary	motivation_problem	motivation	none	none	5	1	support	Most of the proposed solutions to this problem are based on non-convex formulations , and are thus prone to local min-ima .	In this article , we propose a new approach to the problem of weakly supervised relation extraction , based on discriminative clustering and leading to a convex formulation .
CL	D14-1166	5	ab	main	proposal	proposal	none	none	0	0	none	In this article , we propose a new approach to the problem of weakly supervised relation extraction , based on discriminative clustering and leading to a convex formulation .	
CL	D14-1166	6	ab	secondary	result	outcomes	none	none	5	-1	support	We demonstrate that our approach outperforms state-of-the-art methods on the challenging dataset introduced by Riedel et al. ( 2010 ) .	In this article , we propose a new approach to the problem of weakly supervised relation extraction , based on discriminative clustering and leading to a convex formulation .
CL	D14-1167	1	ab	secondary	proposal	proposal	none	none	0	0	none	We examine the embedding approach to reason new relational facts from a large-scale knowledge graph and a text corpus .	
CL	D14-1167	2	ab	main	proposal	proposal	none	none	1	-1	elaboration	We propose a novel method of jointly embedding entities and words into the same continuous vector space .	We examine the embedding approach to reason new relational facts from a large-scale knowledge graph and a text corpus .
CL	D14-1167	3	ab	secondary	proposal	proposal	none	none	2	-1	elaboration	The embedding process attempts to preserve the relations between entities in the knowledge graph and the concurrences of words in the text corpus .	We propose a novel method of jointly embedding entities and words into the same continuous vector space .
CL	D14-1167	4	ab	secondary	means	method	none	none	3	-1	by-means	Entity names and Wikipedia anchors are utilized to align the embeddings of entities and words in the same space .	The embedding process attempts to preserve the relations between entities in the knowledge graph and the concurrences of words in the text corpus .
CL	D14-1167	5	ab	secondary	result_means	outcomes	none	none	2	-3	support	Large scale experiments on Freebase and a Wikipedia/NY Times corpus show that jointly embedding brings promising improvement in the accuracy of predicting facts , compared to separately embedding knowledge graphs and text .	We propose a novel method of jointly embedding entities and words into the same continuous vector space .
CL	D14-1167	6	ab	secondary	result	outcomes	none	none	5	-1	elaboration	Particularly , jointly embedding enables the prediction of facts containing entities out of the knowledge graph , which cannot be handled by previous embedding methods .	Large scale experiments on Freebase and a Wikipedia/NY Times corpus show that jointly embedding brings promising improvement in the accuracy of predicting facts , compared to separately embedding knowledge graphs and text .
CL	D14-1167	7	ab	secondary	result	outcomes	none	none	2	-5	support	At the same time , concerning the quality of the word embeddings , experiments on the analogical reasoning task show that jointly embedding is comparable to or slightly better than word2vec ( Skip-Gram ) .	We propose a novel method of jointly embedding entities and words into the same continuous vector space .
CL	D14-1168	1	ab	main	proposal	proposal	none	none	0	0	none	We propose a novel abstractive summarization system for product reviews by taking advantage of their discourse structure .	
CL	D14-1168	2	ab	secondary	proposal_implementation	proposal	none	none	1	-1	elaboration	First , we apply a discourse parser to each review and obtain a discourse tree representation for every review .	We propose a novel abstractive summarization system for product reviews by taking advantage of their discourse structure .
CL	D14-1168	3	ab	secondary	proposal_implementation	proposal	none	none	2	-1	sequence	We then modify the discourse trees such that every leaf node only contains the aspect words .	First , we apply a discourse parser to each review and obtain a discourse tree representation for every review .
CL	D14-1168	4	ab	secondary	proposal_implementation	proposal	none	none	3	-1	sequence	Second , we aggregate the aspect discourse trees and generate a graph .	We then modify the discourse trees such that every leaf node only contains the aspect words .
CL	D14-1168	5	ab	secondary	proposal_implementation	proposal	none	none	4	-1	sequence	We then select a subgraph representing the most important aspects and the rhetorical relations between them using a PageRank algorithm , and transform the selected subgraph into an aspect tree .	Second , we aggregate the aspect discourse trees and generate a graph .
CL	D14-1168	6	ab	secondary	proposal_implementation	proposal	none	none	5	-1	sequence	Finally , we generate a natural language summary by applying a template-based NLG framework .	We then select a subgraph representing the most important aspects and the rhetorical relations between them using a PageRank algorithm , and transform the selected subgraph into an aspect tree .
CL	D14-1168	7	ab	secondary	result	outcomes	none	none	1	-6	support	Quantitative and qualitative analysis of the results , based on two user studies , show that our approach significantly outperforms extractive and abstractive baselines .	We propose a novel abstractive summarization system for product reviews by taking advantage of their discourse structure .
CL	D14-1169	1	ab	secondary	motivation_background	motivation	none	none	2	1	info-required	Clustering aspect-related phrases in terms of product's property is a precursor process to aspect-level sentiment analysis which is a central task in sentiment analysis .	Most of existing methods for addressing this problem are context-based models which assume that domain synonymous phrases share similar co-occurrence contexts .
CL	D14-1169	2	ab	secondary	motivation_background	motivation	none	none	3	1	support	Most of existing methods for addressing this problem are context-based models which assume that domain synonymous phrases share similar co-occurrence contexts .	In this paper , we explore a novel idea , sentiment distribution consistency , which states that different phrases ( e.g. "price" , "money" , "worth" , and "cost" ) of the same aspect tend to have consistent sentiment distribution .
CL	D14-1169	3	ab	main	proposal	proposal	none	none	0	0	none	In this paper , we explore a novel idea , sentiment distribution consistency , which states that different phrases ( e.g. "price" , "money" , "worth" , and "cost" ) of the same aspect tend to have consistent sentiment distribution .	
CL	D14-1169	4	ab	secondary	proposal_implementation	proposal	none	none	3	-1	elaboration	Through formalizing sentiment distribution consistency as soft constraint , we propose a novel unsupervised model in the framework of Posterior Regularization ( PR ) to cluster aspect-related phrases .	In this paper , we explore a novel idea , sentiment distribution consistency , which states that different phrases ( e.g. "price" , "money" , "worth" , and "cost" ) of the same aspect tend to have consistent sentiment distribution .
CL	D14-1169	5	ab	secondary	result	outcomes	none	none	3	-2	support	Experiments demonstrate that our approach outperforms baselines remarkably .	In this paper , we explore a novel idea , sentiment distribution consistency , which states that different phrases ( e.g. "price" , "money" , "worth" , and "cost" ) of the same aspect tend to have consistent sentiment distribution .
CL	D14-1170	1	ab	secondary	proposal	proposal	none	none	4	3	elaboration	In this paper , we investigate a challenging task of automatic related work generation .	We propose our Automatic Related Work Generation system called ARWG to address this task .
CL	D14-1170	2	ab	secondary	proposal	proposal	none	none	1	-1	elaboration	Given multiple reference papers as input , the task aims to generate a related work section for a target paper .	In this paper , we investigate a challenging task of automatic related work generation .
CL	D14-1170	3	ab	secondary	information_additional	other	none	none	6	3	info-optional	The generated related work section can be used as a draft for the author to complete his or her final related work section .	At last it employs an optimization framework to generate the related work section .
CL	D14-1170	4	ab	main	proposal	proposal	none	none	0	0	none	We propose our Automatic Related Work Generation system called ARWG to address this task .	
CL	D14-1170	5	ab	secondary	proposal_implementation	proposal	none	none	2	-3	elaboration	It first exploits a PLSA model to split the sentence set of the given papers into different topic-biased parts , and then applies regression models to learn the importance of the sentences .	Given multiple reference papers as input , the task aims to generate a related work section for a target paper .
CL	D14-1170	6	ab	secondary	proposal_implementation	proposal	none	none	5	-1	sequence	At last it employs an optimization framework to generate the related work section .	It first exploits a PLSA model to split the sentence set of the given papers into different topic-biased parts , and then applies regression models to learn the importance of the sentences .
CL	D14-1170	7	ab	secondary	result_means	outcomes	none	none	4	-3	support	Our evaluation results on a test set of 150 target papers along with their reference papers show that our proposed ARWG system can generate related work sections with better quality .	We propose our Automatic Related Work Generation system called ARWG to address this task .
CL	D14-1170	8	ab	secondary	result	outcomes	none	none	7	-1	elaboration	A user study is also performed to show ARWG can achieve an improvement over generic multi-document summarization baselines .	Our evaluation results on a test set of 150 target papers along with their reference papers show that our proposed ARWG system can generate related work sections with better quality .
CL	D14-1171	1	ab	secondary	motivation_background	motivation	none	none	2	1	info-required	There are several NLP systems whose accuracy depends crucially on finding misspellings fast .	However , the classical approach is based on a quadratic time algorithm with 80 % coverage .
CL	D14-1171	2	ab	secondary	motivation_problem	motivation	none	none	3	1	support	However , the classical approach is based on a quadratic time algorithm with 80 % coverage .	We present a novel algorithm for misspelling detection , which runs in constant time and improves the coverage to more than 96 % .
CL	D14-1171	3	ab	main	proposal	proposal	none	none	0	0	none	We present a novel algorithm for misspelling detection , which runs in constant time and improves the coverage to more than 96 % .	
CL	D14-1171	4	ab	secondary	proposal_implementation	proposal	none	none	3	-1	sequence	We use this algorithm together with a cross document coreference system in order to find proper name misspellings .	We present a novel algorithm for misspelling detection , which runs in constant time and improves the coverage to more than 96 % .
CL	D14-1171	5	ab	secondary	result	outcomes	none	none	3	-2	support	The experiments confirmed significant improvement over the state of the art .	We present a novel algorithm for misspelling detection , which runs in constant time and improves the coverage to more than 96 % .
CL	D14-1172	1	ab	secondary	motivation_background	motivation	none	none	2	1	support	Learning from errors is a crucial aspect of improving expertise .	Based on this notion , we discuss a robust statistical framework for analysing the impact of different error types on machine translation ( MT ) output quality .
CL	D14-1172	2	ab	main	proposal	proposal	none	none	0	0	none	Based on this notion , we discuss a robust statistical framework for analysing the impact of different error types on machine translation ( MT ) output quality .	
CL	D14-1172	3	ab	secondary	proposal_implementation	proposal	none	none	2	-1	elaboration	Our approach is based on linear mixed-effects models , which allow the analysis of error-annotated MT output taking into account the variability inherent to the specific experimental setting from which the empirical observations are drawn .	Based on this notion , we discuss a robust statistical framework for analysing the impact of different error types on machine translation ( MT ) output quality .
CL	D14-1172	4	ab	secondary	means	method	none	none	5	1	by-means	Our experiments are carried out on different language pairs involving Chinese , Arabic and Russian as target languages .	Interesting findings are reported , concerning the impact of different error types both at the level of human perception of quality and with respect to performance results measured with automatic metrics .
CL	D14-1172	5	ab	secondary	result	outcomes	none	none	2	-3	support	Interesting findings are reported , concerning the impact of different error types both at the level of human perception of quality and with respect to performance results measured with automatic metrics .	Based on this notion , we discuss a robust statistical framework for analysing the impact of different error types on machine translation ( MT ) output quality .
CL	D14-1173	1	ab	secondary	motivation_background	motivation	none	none	2	1	info-required	Languages that have no explicit word delimiters often have to be segmented for statistical machine translation ( SMT ) .	This is commonly performed by automated segmenters trained on manually annotated corpora .
CL	D14-1173	2	ab	secondary	motivation_background	motivation	none	none	3	1	info-required	This is commonly performed by automated segmenters trained on manually annotated corpora .	However , the word segmentation ( WS ) schemes of these annotated corpora are handcrafted for general usage , and may not be suitable for SMT .
CL	D14-1173	3	ab	secondary	motivation_problem	motivation	none	none	6	3	support	However , the word segmentation ( WS ) schemes of these annotated corpora are handcrafted for general usage , and may not be suitable for SMT .	We formulated an approach based on word splitting with reference to the annotated WA to alleviate these conflicts .
CL	D14-1173	4	ab	secondary	proposal_implementation	proposal	none	none	6	2	elaboration	An analysis was performed to test this hypothesis using a manually annotated word alignment ( WA ) corpus for Chinese-English SMT .	We formulated an approach based on word splitting with reference to the annotated WA to alleviate these conflicts .
CL	D14-1173	5	ab	secondary	result_means	outcomes	none	none	4	-1	by-means	An analysis revealed that 74.60 % of the sentences in the WA corpus if segmented using an automated segmenter trained on the Penn Chinese Treebank ( CTB ) will contain conflicts with the gold WA annotations .	An analysis was performed to test this hypothesis using a manually annotated word alignment ( WA ) corpus for Chinese-English SMT .
CL	D14-1173	6	ab	main	proposal	proposal	none	none	0	0	none	We formulated an approach based on word splitting with reference to the annotated WA to alleviate these conflicts .	
CL	D14-1173	7	ab	secondary	result_means	outcomes	none	none	6	-1	support	Experimental results show that the refined WS reduced word alignment error rate by 6.82 % and achieved the highest BLEU improvement ( 0.63 on average ) on the Chinese-English open machine translation ( OpenMT ) corpora compared to related work .	We formulated an approach based on word splitting with reference to the annotated WA to alleviate these conflicts .
CL	D14-1174	1	ab	secondary	motivation_background	motivation	none	none	2	1	info-required	To overcome the scarceness of bilingual corpora for some language pairs in machine translation , pivot-based SMT uses pivot language as a `` bridge '' to generate source-target translation from source-pivot and pivot-target translation .	One of the key issues is to estimate the probabilities for the generated phrase pairs .
CL	D14-1174	2	ab	secondary	motivation_hypothesis	motivation	none	none	3	1	support	One of the key issues is to estimate the probabilities for the generated phrase pairs .	In this paper , we present a novel approach to calculate the translation probability by pivoting the co-occurrence count of source-pivot and pivot-target phrase pairs .
CL	D14-1174	3	ab	main	proposal_implementation	proposal	none	none	0	0	none	In this paper , we present a novel approach to calculate the translation probability by pivoting the co-occurrence count of source-pivot and pivot-target phrase pairs .	
CL	D14-1174	4	ab	secondary	result_means	outcomes	none	none	3	-1	support	Experimental results on Europarl data and web data show that our method leads to significant improvements over the baseline systems .	In this paper , we present a novel approach to calculate the translation probability by pivoting the co-occurrence count of source-pivot and pivot-target phrase pairs .
CL	D14-1175	1	ab	secondary	motivation_problem	motivation	none	none	2	1	support	Translating into morphologically rich languages is a particularly difficult problem in machine translation due to the high degree of inflectional ambiguity in the target language , often only poorly captured by existing word translation models .	We present a general approach that exploits source-side contexts of foreign words to improve translation prediction accuracy .
CL	D14-1175	2	ab	main	proposal	proposal	none	none	0	0	none	We present a general approach that exploits source-side contexts of foreign words to improve translation prediction accuracy .	
CL	D14-1175	3	ab	secondary	proposal_implementation	proposal	none	none	2	-1	elaboration	Our approach is based on a probabilistic neural network which does not require linguistic annotation nor manual feature engineering .	We present a general approach that exploits source-side contexts of foreign words to improve translation prediction accuracy .
CL	D14-1175	4	ab	secondary	result	outcomes	none	none	2	-2	support	We report significant improvements in word translation prediction accuracy for three morphologically rich target languages .	We present a general approach that exploits source-side contexts of foreign words to improve translation prediction accuracy .
CL	D14-1175	5	ab	secondary	result	outcomes	none	none	4	-1	elaboration	In addition , preliminary results for integrating our approach into a large-scale English-Russian statistical machine translation system show small but statistically significant improvements in translation quality .	We report significant improvements in word translation prediction accuracy for three morphologically rich target languages .
CL	D14-1176	1	ab	main	proposal_implementation	proposal	none	none	0	0	none	This paper presents a novel approach to improve reordering in phrase-based machine translation by using richer , syntactic representations of units of bilingual language models ( BiLMs ) .	
CL	D14-1176	2	ab	secondary	proposal_implementation	proposal	none	none	1	-1	elaboration	Our method to include syntactic information is simple in implementation and requires minimal changes in the decoding algorithm .	This paper presents a novel approach to improve reordering in phrase-based machine translation by using richer , syntactic representations of units of bilingual language models ( BiLMs ) .
CL	D14-1176	3	ab	secondary	means	method	none	none	4	1	by-means	The approach is evaluated in a series of Arabic-English and Chinese-English translation experiments .	The best models demonstrate significant improvements in BLEU and TER over the phrase-based baseline , as well as over the lexicalized BiLM by Niehues et al. ( 2011 ) .
CL	D14-1176	4	ab	secondary	result	outcomes	none	none	1	-3	support	The best models demonstrate significant improvements in BLEU and TER over the phrase-based baseline , as well as over the lexicalized BiLM by Niehues et al. ( 2011 ) .	This paper presents a novel approach to improve reordering in phrase-based machine translation by using richer , syntactic representations of units of bilingual language models ( BiLMs ) .
CL	D14-1176	5	ab	secondary	observation	outcomes	none	none	4	-1	elaboration	Further improvements of up to 0.45 BLEU for Arabic-English and up to 0.59 BLEU for Chinese-English are obtained by combining our dependency BiLM with a lexicalized BiLM .	The best models demonstrate significant improvements in BLEU and TER over the phrase-based baseline , as well as over the lexicalized BiLM by Niehues et al. ( 2011 ) .
CL	D14-1176	6	ab	secondary	observation	outcomes	none	none	5	-1	elaboration	An improvement of 0.98 BLEU is obtained for Chinese-English in the setting of an increased distortion limit .	Further improvements of up to 0.45 BLEU for Arabic-English and up to 0.59 BLEU for Chinese-English are obtained by combining our dependency BiLM with a lexicalized BiLM .
CL	D14-1177	1	ab	secondary	motivation_problem	motivation	none	none	2	1	support	Automatically compiling bilingual dictionaries of technical terms from comparable corpora is a challenging problem , yet with many potential applications .	In this paper , we exploit two independent observations about term translations : ( a ) terms are often formed by corresponding sub-lexical units across languages and ( b ) a term and its translation tend to appear in similar lexical context .
CL	D14-1177	2	ab	main	proposal	proposal	none	none	0	0	none	In this paper , we exploit two independent observations about term translations : ( a ) terms are often formed by corresponding sub-lexical units across languages and ( b ) a term and its translation tend to appear in similar lexical context .	
CL	D14-1177	3	ab	secondary	proposal_implementation	proposal	none	none	2	-1	elaboration	Based on the first observation , we develop a new character n-gram compositional method , a logistic regression classifier , for learning a string similarity measure of term translations .	In this paper , we exploit two independent observations about term translations : ( a ) terms are often formed by corresponding sub-lexical units across languages and ( b ) a term and its translation tend to appear in similar lexical context .
CL	D14-1177	4	ab	secondary	proposal_implementation	proposal	none	none	3	-1	sequence	According to the second observation , we use an existing context-based approach .	Based on the first observation , we develop a new character n-gram compositional method , a logistic regression classifier , for learning a string similarity measure of term translations .
CL	D14-1177	5	ab	secondary	means	method	none	none	6	1	by-means	For evaluation , we investigate the performance of compositional and context-based methods on : ( a ) similar and unrelated languages , ( b ) corpora of different degree of comparability and ( c ) the translation of frequent and rare terms .	Finally , we combine the two translation clues , namely string and contextual similarity , in a linear model and we show substantial improvements over the two translation signals .
CL	D14-1177	6	ab	secondary	result	outcomes	none	none	2	-4	support	Finally , we combine the two translation clues , namely string and contextual similarity , in a linear model and we show substantial improvements over the two translation signals .	In this paper , we exploit two independent observations about term translations : ( a ) terms are often formed by corresponding sub-lexical units across languages and ( b ) a term and its translation tend to appear in similar lexical context .
CL	D14-1178	1	ab	secondary	motivation_background	motivation	none	none	2	1	info-required	Vector space models ( VSMs ) are mathematically well-defined frameworks that have been widely used in the distributional approaches to semantics .	In VSMs , high-dimensional vectors represent linguistic entities .
CL	D14-1178	2	ab	secondary	motivation_background	motivation	none	none	3	1	info-required	In VSMs , high-dimensional vectors represent linguistic entities .	In an application , the similarity of vectors—and thus the entities that they represent— is computed by a distance formula .
CL	D14-1178	3	ab	secondary	motivation_background	motivation	none	none	4	1	info-required	In an application , the similarity of vectors—and thus the entities that they represent— is computed by a distance formula .	The high dimensionality of vectors , however , is a barrier to the performance of methods that employ VSMs .
CL	D14-1178	4	ab	secondary	motivation_problem	motivation	none	none	5	1	info-required	The high dimensionality of vectors , however , is a barrier to the performance of methods that employ VSMs .	Consequently , a dimensionality reduction technique is employed to alleviate this problem .
CL	D14-1178	5	ab	secondary	motivation_background	motivation	none	none	6	1	support	Consequently , a dimensionality reduction technique is employed to alleviate this problem .	This paper introduces a novel technique called Random Manhattan Indexing ( RMI ) for the construction of l1 normed VSMs at reduced dimensionality .
CL	D14-1178	6	ab	main	proposal	proposal	none	none	0	0	none	This paper introduces a novel technique called Random Manhattan Indexing ( RMI ) for the construction of l1 normed VSMs at reduced dimensionality .	
CL	D14-1178	7	ab	secondary	proposal_implementation	proposal	none	none	9	2	elaboration	RMI combines the construction of a VSM and dimension reduction into an incremental and thus scalable two-step procedure .	We further introduce Random Manhattan Integer Indexing ( RMII ) : a computationally enhanced version of RMI .
CL	D14-1178	8	ab	secondary	proposal_implementation	proposal	none	none	7	-1	by-means	In order to attain its goal , RMI employs the sparse Cauchy random projections .	RMI combines the construction of a VSM and dimension reduction into an incremental and thus scalable two-step procedure .
CL	D14-1178	9	ab	secondary	proposal	proposal	none	none	6	-3	elaboration	We further introduce Random Manhattan Integer Indexing ( RMII ) : a computationally enhanced version of RMI .	This paper introduces a novel technique called Random Manhattan Indexing ( RMI ) for the construction of l1 normed VSMs at reduced dimensionality .
CL	D14-1178	10	ab	secondary	conclusion	outcomes	none	none	6	-4	support	As shown in the reported experiments , RMI and RMII can be used reliably to estimate the l1 distances between vectors in a vector space of low dimensionality .	This paper introduces a novel technique called Random Manhattan Indexing ( RMI ) for the construction of l1 normed VSMs at reduced dimensionality .
CL	D14-1179	1	ab	main	proposal	proposal	none	none	0	0	none	In this paper , we propose a novel neural network model called RNN Encoder- Decoder that consists of two recurrent neural networks ( RNN ) .	
CL	D14-1179	2	ab	secondary	proposal	proposal	none	none	1	-1	elaboration	One RNN encodes a sequence of symbols into a fixed-length vector representation , and the other decodes the representation into another sequence of symbols .	In this paper , we propose a novel neural network model called RNN Encoder- Decoder that consists of two recurrent neural networks ( RNN ) .
CL	D14-1179	3	ab	secondary	proposal_implementation	proposal	none	none	2	-1	elaboration	The encoder and decoder of the proposed model are jointly trained to maximize the conditional probability of a target sequence given a source sequence .	One RNN encodes a sequence of symbols into a fixed-length vector representation , and the other decodes the representation into another sequence of symbols .
CL	D14-1179	4	ab	secondary	conclusion	outcomes	none	none	1	-3	support	The performance of a statistical machine translation system is empirically found to improve by using the conditional probabilities of phrase pairs computed by the RNN Encoder-Decoder as an additional feature in the existing log-linear model .	In this paper , we propose a novel neural network model called RNN Encoder- Decoder that consists of two recurrent neural networks ( RNN ) .
CL	D14-1179	5	ab	secondary	result	outcomes	none	none	4	-1	elaboration	Qualitatively , we show that the proposed model learns a semantically and syntactically meaningful representation of linguistic phrases .	The performance of a statistical machine translation system is empirically found to improve by using the conditional probabilities of phrase pairs computed by the RNN Encoder-Decoder as an additional feature in the existing log-linear model .
CL	D14-1180	1	ab	main	proposal_implementation	proposal	none	none	0	0	none	This paper applies type-based Markov Chain Monte Carlo ( MCMC ) algorithms to the problem of learning Synchronous Context-Free Grammar ( SCFG ) rules from a forest that represents all possible rules consistent with a fixed word alignment .	
CL	D14-1180	2	ab	secondary	motivation_problem	motivation	none	none	1	-1	support	While type-based MCMC has been shown to be effective in a number of NLP applications , our setting , where the tree structure of the sentence is itself a hidden variable , presents a number of challenges to type-based inference .	This paper applies type-based Markov Chain Monte Carlo ( MCMC ) algorithms to the problem of learning Synchronous Context-Free Grammar ( SCFG ) rules from a forest that represents all possible rules consistent with a fixed word alignment .
CL	D14-1180	3	ab	secondary	proposal	proposal	none	none	1	-2	elaboration	We describe methods for defining variable types and efficiently indexing variables in order to overcome these challenges .	This paper applies type-based Markov Chain Monte Carlo ( MCMC ) algorithms to the problem of learning Synchronous Context-Free Grammar ( SCFG ) rules from a forest that represents all possible rules consistent with a fixed word alignment .
CL	D14-1180	4	ab	secondary	result	outcomes	none	none	3	-1	support	These methods lead to improvements in both log likelihood and BLEU score in our experiments .	We describe methods for defining variable types and efficiently indexing variables in order to overcome these challenges .
CL	D14-1181	1	ab	main	proposal	proposal	none	none	0	0	none	We report on a series of experiments with convolutional neural networks ( CNN ) trained on top of pre-trained word vectors for sentence-level classification tasks .	
CL	D14-1181	2	ab	secondary	result	outcomes	none	none	1	-1	support	We show that a simple CNN with little hyperparameter tuning and static vectors achieves excellent results on multiple benchmarks .	We report on a series of experiments with convolutional neural networks ( CNN ) trained on top of pre-trained word vectors for sentence-level classification tasks .
CL	D14-1181	3	ab	secondary	result	outcomes	none	none	2	-1	elaboration	Learning task-specific vectors through fine-tuning offers further gains in performance .	We show that a simple CNN with little hyperparameter tuning and static vectors achieves excellent results on multiple benchmarks .
CL	D14-1181	4	ab	secondary	proposal	proposal	none	none	1	-3	elaboration	We additionally propose a simple modification to the architecture to allow for the use of both task-specific and static vectors .	We report on a series of experiments with convolutional neural networks ( CNN ) trained on top of pre-trained word vectors for sentence-level classification tasks .
CL	D14-1181	5	ab	secondary	result	outcomes	none	none	1	-4	support	The CNN models discussed herein improve upon the state of the art on 4 out of 7 tasks , which include sentiment analysis and question classification .	We report on a series of experiments with convolutional neural networks ( CNN ) trained on top of pre-trained word vectors for sentence-level classification tasks .
CL	D14-1182	1	ab	secondary	motivation_background	motivation	none	none	2	1	info-required	Markov chain Monte Carlo ( MCMC ) approximates the posterior distribution of latent variable models by generating many samples and averaging over them .	In practice , however , it is often more convenient to cut corners , using only a single sample or following a suboptimal averaging strategy .
CL	D14-1182	2	ab	secondary	motivation_hypothesis	motivation	none	none	3	1	support	In practice , however , it is often more convenient to cut corners , using only a single sample or following a suboptimal averaging strategy .	We systematically study different strategies for averaging MCMC samples and show empirically that averaging properly leads to significant improvements in prediction .
CL	D14-1182	3	ab	main	proposal	proposal	conclusion	outcomes	0	0	none	We systematically study different strategies for averaging MCMC samples and show empirically that averaging properly leads to significant improvements in prediction .	
CL	D14-1183	1	ab	secondary	motivation_background	motivation	none	none	2	1	info-required	Phrase reordering is a challenge for statistical machine translation systems .	Posing phrase movements as a prediction problem using contextual features modeled by maximum entropy-based classifier is superior to the commonly used lexicalized reordering model .
CL	D14-1183	2	ab	secondary	motivation_background	motivation	none	none	3	1	info-required	Posing phrase movements as a prediction problem using contextual features modeled by maximum entropy-based classifier is superior to the commonly used lexicalized reordering model .	However , Training this discriminative model using large-scale parallel corpus might be computationally expensive .
CL	D14-1183	3	ab	secondary	motivation_problem	motivation	none	none	4	1	support	However , Training this discriminative model using large-scale parallel corpus might be computationally expensive .	In this paper , we explore recent advancements in solving large-scale classification problems .
CL	D14-1183	4	ab	main	proposal	proposal	none	none	0	0	none	In this paper , we explore recent advancements in solving large-scale classification problems .	
CL	D14-1183	5	ab	secondary	proposal_implementation	proposal	result	outcomes	4	-1	elaboration	Using the dual problem to multinomial logistic regression , we managed to shrink the training data while iterating and produce significant saving in computation and memory while preserving the accuracy .	In this paper , we explore recent advancements in solving large-scale classification problems .
CL	D14-1184	1	ab	main	proposal	proposal	result_means	outcomes	0	0	none	In this paper , we present two improvements to the beam search approach for solving homophonic substitution ciphers presented in Nuhn et al. ( 2013 ) : An improved rest cost estimation together with an optimized strategy for obtaining the order in which the symbols of the cipher are deciphered reduces the beam size needed to successfully decipher the Zodiac-408 cipher from several million down to less than one hundred : The search effort is reduced from several hours of computation time to just a few seconds on a single CPU .	
CL	D14-1184	2	ab	secondary	conclusion	outcomes	information_additional	other	1	-1	support	These improvements allow us to successfully decipher the second part of the famous Beale cipher ( see ( Ward et al. , 1885 ) and e.g. ( King , 1993 ) ) : Having 182 different cipher symbols while having a length of just 762 symbols , the decipherment is way more challenging than the decipherment of the previously deciphered Zodiac-408 cipher ( length 408 , 54 different symbols ) .	In this paper , we present two improvements to the beam search approach for solving homophonic substitution ciphers presented in Nuhn et al. ( 2013 ) : An improved rest cost estimation together with an optimized strategy for obtaining the order in which the symbols of the cipher are deciphered reduces the beam size needed to successfully decipher the Zodiac-408 cipher from several million down to less than one hundred : The search effort is reduced from several hours of computation time to just a few seconds on a single CPU .
CL	D14-1184	3	ab	secondary	information_additional	other	none	none	2	-1	info-optional	To the best of our knowledge , this cipher has not been deciphered automatically before .	These improvements allow us to successfully decipher the second part of the famous Beale cipher ( see ( Ward et al. , 1885 ) and e.g. ( King , 1993 ) ) : Having 182 different cipher symbols while having a length of just 762 symbols , the decipherment is way more challenging than the decipherment of the previously deciphered Zodiac-408 cipher ( length 408 , 54 different symbols ) .
CL	D14-1185	1	ab	secondary	motivation_background	motivation	none	none	2	1	info-required	Manual analysis and decryption of enciphered documents is a tedious and error prone work .	Often even after spending large amounts of time on a particular cipher - no decipherment can be found .
CL	D14-1185	2	ab	secondary	motivation_problem	motivation	none	none	3	1	info-required	Often even after spending large amounts of time on a particular cipher - no decipherment can be found .	Automating the decryption of various types of ciphers makes it possible to sift through the large number of encrypted messages found in libraries and archives , and to focus human effort only on a small but potentially interesting subset of them .
CL	D14-1185	3	ab	secondary	motivation_hypothesis	motivation	none	none	4	1	support	Automating the decryption of various types of ciphers makes it possible to sift through the large number of encrypted messages found in libraries and archives , and to focus human effort only on a small but potentially interesting subset of them .	In this work , we train a classifier that is able to predict which encipherment method has been used to generate a given ciphertext .
CL	D14-1185	4	ab	main	proposal	proposal	none	none	0	0	none	In this work , we train a classifier that is able to predict which encipherment method has been used to generate a given ciphertext .	
CL	D14-1185	5	ab	secondary	result_means	outcomes	none	none	4	-1	support	We are able to distinguish 50 different cipher types ( specified by the American Cryptogram Association ) with an accuracy of 58.5 % .	In this work , we train a classifier that is able to predict which encipherment method has been used to generate a given ciphertext .
CL	D14-1185	6	ab	secondary	observation	outcomes	none	none	5	-1	elaboration	This is a 11.2 % absolute improvement over the best previously published classifier .	We are able to distinguish 50 different cipher types ( specified by the American Cryptogram Association ) with an accuracy of 58.5 % .
CL	D14-1186	1	ab	secondary	motivation_background	motivation	none	none	2	1	info-required	Previous work often used a pipelined framework where Chinese word segmentation is followed by term extraction and keyword extraction .	Such framework suffers from error propagation and is unable to leverage information in later modules for prior components .
CL	D14-1186	2	ab	secondary	motivation_problem	motivation	none	none	3	1	support	Such framework suffers from error propagation and is unable to leverage information in later modules for prior components .	In this paper , we propose a four-level Dirichlet Process based model ( DP-4 ) to jointly learn the word distributions from the corpus , domain and document levels simultaneously .
CL	D14-1186	3	ab	main	proposal	proposal	none	none	0	0	none	In this paper , we propose a four-level Dirichlet Process based model ( DP-4 ) to jointly learn the word distributions from the corpus , domain and document levels simultaneously .	
CL	D14-1186	4	ab	secondary	proposal_implementation	proposal	none	none	3	-1	elaboration	Based on the DP-4 model , a sentence-wise Gibbs sampler is adopted to obtain proper segmentation results .	In this paper , we propose a four-level Dirichlet Process based model ( DP-4 ) to jointly learn the word distributions from the corpus , domain and document levels simultaneously .
CL	D14-1186	5	ab	secondary	proposal_implementation	proposal	none	none	4	-1	elaboration	Meanwhile , terms and keywords are acquired in the sampling process .	Based on the DP-4 model , a sentence-wise Gibbs sampler is adopted to obtain proper segmentation results .
CL	D14-1186	6	ab	secondary	conclusion	outcomes	none	none	3	-3	support	Experimental results have shown the effectiveness of our method .	In this paper , we propose a four-level Dirichlet Process based model ( DP-4 ) to jointly learn the word distributions from the corpus , domain and document levels simultaneously .
CL	D14-1187	1	ab	secondary	motivation_problem	motivation	none	none	2	1	support	When Part-of-Speech annotated data is scarce , e.g. for under-resourced languages , one can turn to cross-lingual transfer and crawled dictionaries to collect partially supervised data .	We cast this problem in the framework of ambiguous learning and show how to learn an accurate history-based model .
CL	D14-1187	2	ab	main	proposal	proposal	none	none	0	0	none	We cast this problem in the framework of ambiguous learning and show how to learn an accurate history-based model .	
CL	D14-1187	3	ab	secondary	result	outcomes	none	none	2	-1	support	Experiments on ten languages show significant improvements over prior state of the art performance .	We cast this problem in the framework of ambiguous learning and show how to learn an accurate history-based model .
CL	D14-1188	1	ab	main	proposal	proposal	none	none	0	0	none	We introduce new features for incorporating semantic predicate-argument structures in machine translation ( MT ) .	
CL	D14-1188	2	ab	secondary	proposal	proposal	none	none	1	-1	elaboration	The methods focus on the completeness of the semantic structures of the translations , as well as the order of the translated semantic roles .	We introduce new features for incorporating semantic predicate-argument structures in machine translation ( MT ) .
CL	D14-1188	3	ab	secondary	proposal_implementation	proposal	observation	outcomes	2	-1	elaboration	We experiment with translation rules which contain the core arguments for the predicates in the source side of a MT system , and observe that using these rules significantly improves the translation quality .	The methods focus on the completeness of the semantic structures of the translations , as well as the order of the translated semantic roles .
CL	D14-1188	4	ab	secondary	proposal	proposal	none	none	1	-3	elaboration	We also present a new semantic feature that resembles a language model .	We introduce new features for incorporating semantic predicate-argument structures in machine translation ( MT ) .
CL	D14-1188	5	ab	secondary	result	outcomes	none	none	4	-1	support	Our results show that the language model feature can also significantly improve MT results .	We also present a new semantic feature that resembles a language model .
CL	D14-1189	1	ab	main	proposal	proposal	none	none	0	0	none	We propose a simple unsupervised approach to detecting non-compositional components in multiword expressions based on Wiktionary .	
CL	D14-1189	2	ab	secondary	proposal_implementation	proposal	none	none	1	-1	elaboration	The approach makes use of the definitions , synonyms and translations in Wiktionary , and is applicable to any type of MWE in any language , assuming the MWE is contained in Wiktionary .	We propose a simple unsupervised approach to detecting non-compositional components in multiword expressions based on Wiktionary .
CL	D14-1189	3	ab	secondary	result	outcomes	none	none	1	-2	support	Our experiments show that the proposed approach achieves higher F-score than state-of-the-art methods .	We propose a simple unsupervised approach to detecting non-compositional components in multiword expressions based on Wiktionary .
CL	D14-1190	1	ab	main	proposal	proposal	none	none	0	0	none	We propose a model for jointly predicting multiple emotions in natural language sentences .	
CL	D14-1190	2	ab	secondary	proposal_implementation	proposal	none	none	1	-1	elaboration	Our model is based on a low-rank coregionalisation approach , which combines a vector-valued Gaussian Process with a rich parameterisation scheme .	We propose a model for jointly predicting multiple emotions in natural language sentences .
CL	D14-1190	3	ab	secondary	result	outcomes	none	none	1	-2	support	We show that our approach is able to learn correlations and anti-correlations between emotions on a news headlines dataset .	We propose a model for jointly predicting multiple emotions in natural language sentences .
CL	D14-1190	4	ab	secondary	result	outcomes	none	none	3	-1	elaboration	The proposed model outperforms both single-task baselines and other multi-task approaches .	We show that our approach is able to learn correlations and anti-correlations between emotions on a news headlines dataset .
CL	D14-1191	1	ab	secondary	motivation_background	motivation	motivation_problem	motivation	2	1	support	Previous work on extracting ideology from text has focused on domains where expression of political views is expected , but it's unclear if current technology can work in domains where displays of ideology are considered inappropriate .	We present a supervised ensemble n-gram model for ideology extraction with topic adjustments and apply it to one such domain : research papers written by academic economists .
CL	D14-1191	2	ab	main	proposal	proposal	none	none	0	0	none	We present a supervised ensemble n-gram model for ideology extraction with topic adjustments and apply it to one such domain : research papers written by academic economists .	
CL	D14-1191	3	ab	secondary	result	outcomes	none	none	2	-1	support	We show economists' political leanings can be correctly predicted , that our predictions generalize to new domains , and that they correlate with public policy-relevant research findings .	We present a supervised ensemble n-gram model for ideology extraction with topic adjustments and apply it to one such domain : research papers written by academic economists .
CL	D14-1191	4	ab	secondary	result	outcomes	none	none	2	-2	support	We also present evidence that unsupervised models can under-perform in domains where ideological expression is discouraged .	We present a supervised ensemble n-gram model for ideology extraction with topic adjustments and apply it to one such domain : research papers written by academic economists .
CL	D14-1192	1	ab	main	proposal	proposal	none	none	0	0	none	We develop a statistical model of saccadic eye movements during reading of isolated sentences .	
CL	D14-1192	2	ab	secondary	proposal_implementation	proposal	none	none	1	-1	elaboration	The model is focused on representing individual differences between readers and supports the inference of the most likely reader for a novel set of eye movement patterns .	We develop a statistical model of saccadic eye movements during reading of isolated sentences .
CL	D14-1192	3	ab	secondary	proposal_implementation	proposal	observation	outcomes	2	-1	elaboration	We empirically study the model for biometric reader identification using eye-tracking data collected from 20 individuals and observe that the model distinguishes between 20 readers with an accuracy of up to 98 % .	The model is focused on representing individual differences between readers and supports the inference of the most likely reader for a novel set of eye movement patterns .
CL	D14-1193	1	ab	secondary	motivation_background	motivation	none	none	2	1	info-required	Multi-label text categorization ( MTC ) is supervised learning , where a document may be assigned with multiple categories ( labels ) simultaneously .	The labels in the MTC are correlated and the correlation results in some hidden components , which represent the "share" variance of correlated labels .
CL	D14-1193	2	ab	secondary	motivation_hypothesis	motivation	none	none	3	1	support	The labels in the MTC are correlated and the correlation results in some hidden components , which represent the "share" variance of correlated labels .	In this paper , we propose a method with hidden components for MTC .
CL	D14-1193	3	ab	main	proposal	proposal	none	none	0	0	none	In this paper , we propose a method with hidden components for MTC .	
CL	D14-1193	4	ab	secondary	proposal_implementation	proposal	none	none	3	-1	elaboration	The proposed method employs PCA to capture the hidden components , and incorporates them into a joint learning framework to improve the performance .	In this paper , we propose a method with hidden components for MTC .
CL	D14-1193	5	ab	secondary	result	outcomes	none	none	3	-2	support	Experiments with real-world data sets and evaluation metrics validate the effectiveness of the proposed method .	In this paper , we propose a method with hidden components for MTC .
CL	D14-1194	1	ab	main	proposal_implementation	proposal	none	none	0	0	none	We describe a convolutional neural network that learns feature representations for short textual posts using hashtags as a supervised signal.	
CL	D14-1194	2	ab	secondary	proposal_implementation	proposal	none	none	1	-1	elaboration	The proposed approach is trained on up to 5.5 billion words predicting 100,000 possible hashtags .	We describe a convolutional neural network that learns feature representations for short textual posts using hashtags as a supervised signal.
CL	D14-1194	3	ab	secondary	result	outcomes	none	none	1	-2	support	As well as strong performance on the hashtag prediction task itself , we show that its learned representation of text ( ignoring the hashtag labels ) is useful for other tasks as well .	We describe a convolutional neural network that learns feature representations for short textual posts using hashtags as a supervised signal.
CL	D14-1194	4	ab	secondary	result	outcomes	none	none	3	-1	elaboration	To that end , we present results on a document recommendation task , where it also outperforms a number of baselines .	As well as strong performance on the hashtag prediction task itself , we show that its learned representation of text ( ignoring the hashtag labels ) is useful for other tasks as well .
CL	D14-1195	1	ab	main	proposal_implementation	proposal	none	none	0	0	none	In this paper , we provide a new method for decoding tree transduction based sentence compression models augmented with language model scores , by jointly decoding two components .	
CL	D14-1195	2	ab	secondary	proposal	proposal	none	none	1	-1	elaboration	In our proposed solution , rich local discriminative features can be easily integrated without increasing computational complexity .	In this paper , we provide a new method for decoding tree transduction based sentence compression models augmented with language model scores , by jointly decoding two components .
CL	D14-1195	3	ab	secondary	proposal_implementation	proposal	none	none	2	-1	elaboration	Utilizing an unobvious fact that the resulted two components can be independently decoded , we conduct efficient joint decoding based on dual decomposition .	In our proposed solution , rich local discriminative features can be easily integrated without increasing computational complexity .
CL	D14-1195	4	ab	secondary	result	outcomes	none	none	1	-3	support	Experimental results show that our method outperforms traditional beam search decoding and achieves the state-of-the-art performance .	In this paper , we provide a new method for decoding tree transduction based sentence compression models augmented with language model scores , by jointly decoding two components .
CL	D14-1196	1	ab	main	proposal_implementation	proposal	motivation_problem	motivation	0	0	none	The current state-of-the-art single-document summarization method generates a summary by solving a Tree Knapsack Problem ( TKP ) , which is the problem of finding the optimal rooted subtree of the dependency-based discourse tree ( DEP-DT ) of a document .	
CL	D14-1196	2	ab	secondary	motivation_background	motivation	none	none	3	1	info-required	We can obtain a gold DEP-DT by transforming a gold Rhetorical Structure Theory-based discourse tree ( RST-DT ) .	However , there is still a large difference between the ROUGE scores of a system with a gold DEP-DT and a system with a DEP-DT obtained from an automatically parsed RST-DT .
CL	D14-1196	3	ab	secondary	motivation_problem	motivation	none	none	4	1	support	However , there is still a large difference between the ROUGE scores of a system with a gold DEP-DT and a system with a DEP-DT obtained from an automatically parsed RST-DT .	To improve the ROUGE score , we propose a novel discourse parser that directly generates the DEP-DT .
CL	D14-1196	4	ab	secondary	proposal	proposal	none	none	1	-3	elaboration	To improve the ROUGE score , we propose a novel discourse parser that directly generates the DEP-DT .	The current state-of-the-art single-document summarization method generates a summary by solving a Tree Knapsack Problem ( TKP ) , which is the problem of finding the optimal rooted subtree of the dependency-based discourse tree ( DEP-DT ) of a document .
CL	D14-1196	5	ab	secondary	result	outcomes	none	none	1	-4	support	The evaluation results showed that the TKP with our parser outperformed that with the state-of-the-art RST-DT parser , and achieved almost equivalent ROUGE scores to the TKP with the gold DEP-DT .	The current state-of-the-art single-document summarization method generates a summary by solving a Tree Knapsack Problem ( TKP ) , which is the problem of finding the optimal rooted subtree of the dependency-based discourse tree ( DEP-DT ) of a document .
CL	D14-1197	1	ab	secondary	result	outcomes	none	none	2	1	support	We show that semantic relationships can be used to improve word alignment , in addition to the lexical and syntactic features that are typically used .	In this paper , we present a method based on a neural network to automatically derive word similarity from monolingual data .
CL	D14-1197	2	ab	main	proposal	proposal	none	none	0	0	none	In this paper , we present a method based on a neural network to automatically derive word similarity from monolingual data .	
CL	D14-1197	3	ab	secondary	proposal	proposal	none	none	2	-1	elaboration	We present an extension to word alignment models that exploits word similarity .	In this paper , we present a method based on a neural network to automatically derive word similarity from monolingual data .
CL	D14-1197	4	ab	secondary	result	outcomes	none	none	1	-3	elaboration	Our experiments , in both large-scale and resource-limited settings , show improvements in word alignment tasks as well as translation tasks .	We show that semantic relationships can be used to improve word alignment , in addition to the lexical and syntactic features that are typically used .
CL	D14-1198	1	ab	main	proposal	proposal	none	none	0	0	none	In this paper , we propose a new framework that unifies the output of three information extraction ( IE ) tasks - entity mentions , relations and events as an information network representation , and extracts all of them using one single joint model based on structured prediction .	
CL	D14-1198	2	ab	secondary	proposal	proposal	none	none	1	-1	elaboration	This novel formulation allows different parts of the information network fully interact with each other .	In this paper , we propose a new framework that unifies the output of three information extraction ( IE ) tasks - entity mentions , relations and events as an information network representation , and extracts all of them using one single joint model based on structured prediction .
CL	D14-1198	3	ab	secondary	information_additional	other	none	none	2	-1	info-optional	For example , many relations can now be considered as the resultant states of events .	This novel formulation allows different parts of the information network fully interact with each other .
CL	D14-1198	4	ab	secondary	result	outcomes	none	none	1	-3	support	Our approach achieves substantial improvements over traditional pipelined approaches , and significantly advances state-of-the-art end-to-end event argument extraction .	In this paper , we propose a new framework that unifies the output of three information extraction ( IE ) tasks - entity mentions , relations and events as an information network representation , and extracts all of them using one single joint model based on structured prediction .
CL	D14-1199	1	ab	secondary	motivation_background	motivation	motivation_problem	motivation	2	1	support	The efficiency of Information Extraction systems is known to be heavily influenced by domain-specific knowledge but the cost of developing such systems is considerably high .	In this article , we consider the problem of event extraction and show that learning word representations from unlabeled domain-specific data and using them for representing event roles enable to outperform previous state-of-the-art event extraction models on the MUC-4 data set .
CL	D14-1199	2	ab	main	proposal	proposal	none	none	0	0	none	In this article , we consider the problem of event extraction and show that learning word representations from unlabeled domain-specific data and using them for representing event roles enable to outperform previous state-of-the-art event extraction models on the MUC-4 data set .	
CL	D14-1200	1	ab	main	proposal	proposal	none	none	0	0	none	This paper proposes a history-based structured learning approach that jointly extracts entities and relations in a sentence .	
CL	D14-1200	2	ab	secondary	proposal	proposal	none	none	1	-1	elaboration	We introduce a novel simple and flexible table representation of entities and relations .	This paper proposes a history-based structured learning approach that jointly extracts entities and relations in a sentence .
CL	D14-1200	3	ab	secondary	proposal	proposal	none	none	2	-1	elaboration	We investigate several feature settings , search orders , and learning methods with inexact search on the table .	We introduce a novel simple and flexible table representation of entities and relations .
CL	D14-1200	4	ab	secondary	result	outcomes	none	none	1	-3	support	The experimental results demonstrate that a joint learning approach significantly outperforms a pipeline approach by incorporating global features and by selecting appropriate learning methods and search orders .	This paper proposes a history-based structured learning approach that jointly extracts entities and relations in a sentence .
CL	D14-1201	1	ab	secondary	motivation_background	motivation	none	none	3	2	info-required	Open Relation Extraction ( ORE ) overcomes the limitations of traditional IE techniques , which train individual extractors for every single relation type .	However , few studies have been reported on ORE for languages beyond English .
CL	D14-1201	2	ab	secondary	information_additional	other	none	none	1	-1	info-optional	Systems such as ReVerb , PATTY , OLLIE , and Exemplar have attracted much attention on English ORE .	Open Relation Extraction ( ORE ) overcomes the limitations of traditional IE techniques , which train individual extractors for every single relation type .
CL	D14-1201	3	ab	secondary	motivation_problem	motivation	none	none	4	1	support	However , few studies have been reported on ORE for languages beyond English .	This paper presents a syntax-based Chinese ( Zh ) ORE system , ZORE , for extracting relations and semantic patterns from Chinese text .
CL	D14-1201	4	ab	main	proposal	proposal	none	none	0	0	none	This paper presents a syntax-based Chinese ( Zh ) ORE system , ZORE , for extracting relations and semantic patterns from Chinese text .	
CL	D14-1201	5	ab	secondary	proposal_implementation	proposal	none	none	4	-1	elaboration	ZORE identifies relation candidates from automatically parsed dependency trees , and then extracts relations with their semantic patterns iteratively through a novel double propagation algorithm .	This paper presents a syntax-based Chinese ( Zh ) ORE system , ZORE , for extracting relations and semantic patterns from Chinese text .
CL	D14-1201	6	ab	secondary	result	outcomes	none	none	4	-2	support	Empirical results on two data sets show the effectiveness of the proposed system .	This paper presents a syntax-based Chinese ( Zh ) ORE system , ZORE , for extracting relations and semantic patterns from Chinese text .
CL	D14-1202	1	ab	secondary	motivation_background	motivation	none	none	2	1	support	Correctly predicting abbreviations given the full forms is important in many natural language processing systems .	In this paper we propose a two-stage method to find the corresponding abbreviation given its full form .
CL	D14-1202	2	ab	main	proposal	proposal	none	none	0	0	none	In this paper we propose a two-stage method to find the corresponding abbreviation given its full form .	
CL	D14-1202	3	ab	secondary	proposal_implementation	proposal	none	none	2	-1	elaboration	We first use the contextual information given a large corpus to get abbreviation candidates for each full form and get a coarse-grained ranking through graph random walk .	In this paper we propose a two-stage method to find the corresponding abbreviation given its full form .
CL	D14-1202	4	ab	secondary	proposal_implementation	proposal	none	none	3	-1	sequence	This coarse-grained rank list fixes the search space inside the top-ranked candidates .	We first use the contextual information given a large corpus to get abbreviation candidates for each full form and get a coarse-grained ranking through graph random walk .
CL	D14-1202	5	ab	secondary	proposal_implementation	proposal	none	none	4	-1	sequence	Then we use a similarity sensitive re-ranking strategy which can utilize the features of the candidates to give a fine-grained re-ranking and select the final result .	This coarse-grained rank list fixes the search space inside the top-ranked candidates .
CL	D14-1202	6	ab	secondary	result	outcomes	none	none	2	-4	support	Our method achieves good results and outperforms the state-of-the-art systems .	In this paper we propose a two-stage method to find the corresponding abbreviation given its full form .
CL	D14-1202	7	ab	secondary	conclusion	outcomes	none	none	2	-5	support	One advantage of our method is that it only needs weak supervision and can get competitive results with fewer training data .	In this paper we propose a two-stage method to find the corresponding abbreviation given its full form .
CL	D14-1202	8	ab	secondary	conclusion	outcomes	none	none	7	-1	elaboration	The candidate generation and coarse-grained ranking is totally unsupervised .	One advantage of our method is that it only needs weak supervision and can get competitive results with fewer training data .
CL	D14-1202	9	ab	secondary	conclusion	outcomes	none	none	8	-1	elaboration	The re-ranking phase can use a very small amount of training data to get a reasonably good result .	The candidate generation and coarse-grained ranking is totally unsupervised .
CL	D14-1203	1	ab	secondary	motivation_background	motivation	none	none	2	1	info-required	Distant supervision has become the leading method for training large-scale relation extractors , with nearly universal adoption in recent TAC knowledge-base population competitions .	However , there are still many questions about the best way to learn such extractors .
CL	D14-1203	2	ab	secondary	motivation_problem	motivation	none	none	3	1	support	However , there are still many questions about the best way to learn such extractors .	In this paper we investigate four orthogonal improvements : integrating named entity linking ( NEL ) and coreference resolution into argument identification for training and extraction , enforcing type constraints of linked arguments , and partitioning the model by relation type signature .
CL	D14-1203	3	ab	main	proposal	proposal	none	none	0	0	none	In this paper we investigate four orthogonal improvements : integrating named entity linking ( NEL ) and coreference resolution into argument identification for training and extraction , enforcing type constraints of linked arguments , and partitioning the model by relation type signature .	
CL	D14-1203	4	ab	secondary	means	method	none	none	5	1	by-means	We evaluate sentential extraction performance on two datasets : the popular set of NY Times articles partially annotated by Hoffmann et al. ( 2011 ) and a new dataset , called GORECO , that is comprehensively annotated for 48 common relations .	We find that using NEL for argument identification boosts performance over the traditional approach ( named entity recognition with string match ) , and there is further improvement from using argument types .
CL	D14-1203	5	ab	secondary	result	outcomes	none	none	3	-2	support	We find that using NEL for argument identification boosts performance over the traditional approach ( named entity recognition with string match ) , and there is further improvement from using argument types .	In this paper we investigate four orthogonal improvements : integrating named entity linking ( NEL ) and coreference resolution into argument identification for training and extraction , enforcing type constraints of linked arguments , and partitioning the model by relation type signature .
CL	D14-1203	6	ab	secondary	observation	outcomes	none	none	5	-1	support	Our best system boosts precision by 44 % and recall by 70 % .	We find that using NEL for argument identification boosts performance over the traditional approach ( named entity recognition with string match ) , and there is further improvement from using argument types .
CL	D14-1204	1	ab	main	proposal	proposal	none	none	0	0	none	We address the problem of automatically inferring the tense of events in Chinese text .	
CL	D14-1204	2	ab	secondary	proposal_implementation	proposal	none	none	1	-1	elaboration	We use a new corpus annotated with Chinese semantic tense information and other implicit Chinese linguistic information using a "distant annotation" method .	We address the problem of automatically inferring the tense of events in Chinese text .
CL	D14-1204	3	ab	secondary	proposal	proposal	none	none	2	-1	elaboration	We propose three improvements over a relatively strong baseline method - a statistical learning method with extensive feature engineering .	We use a new corpus annotated with Chinese semantic tense information and other implicit Chinese linguistic information using a "distant annotation" method .
CL	D14-1204	4	ab	secondary	proposal_implementation	proposal	none	none	3	-1	elaboration	First , we add two sources of implicit linguistic information as features - eventuality type and modality of an event , which are also inferred automatically .	We propose three improvements over a relatively strong baseline method - a statistical learning method with extensive feature engineering .
CL	D14-1204	5	ab	secondary	proposal_implementation	proposal	none	none	4	-1	sequence	Second , we perform joint learning on semantic tense , eventuality type , and modality of an event .	First , we add two sources of implicit linguistic information as features - eventuality type and modality of an event , which are also inferred automatically .
CL	D14-1204	6	ab	secondary	proposal_implementation	proposal	none	none	5	-1	sequence	Third , we train artificial neural network models for this problem and compare its performance with feature-based approaches .	Second , we perform joint learning on semantic tense , eventuality type , and modality of an event .
CL	D14-1204	7	ab	secondary	result	outcomes	none	none	1	-6	support	Experimental results show considerable improvements on Chinese tense inference .	We address the problem of automatically inferring the tense of events in Chinese text .
CL	D14-1204	8	ab	secondary	result	outcomes	none	none	7	-1	elaboration	Our best performance reaches 68.6 % in accuracy , outperforming a strong baseline method .	Experimental results show considerable improvements on Chinese tense inference .
CL	D14-1205	1	ab	secondary	motivation_background	motivation	none	none	2	1	info-required	Populating Knowledge Base ( KB ) with new knowledge facts from reliable text re-sources usually consists of linking name mentions to KB entities and identifying relationship between entity pairs .	However , the task often suffers from errors propagating from upstream entity linkers to downstream relation extractors .
CL	D14-1205	2	ab	secondary	motivation_problem	motivation	none	none	3	1	support	However , the task often suffers from errors propagating from upstream entity linkers to downstream relation extractors .	In this paper , we propose a novel joint inference framework to allow interactions between the two subtasks and find an optimal assignment by addressing the coherence among preliminary local predictions : whether the types of entities meet the expectations of relations explicitly or implicitly , and whether the local predictions are globally compatible .
CL	D14-1205	3	ab	main	proposal_implementation	proposal	none	none	0	0	none	In this paper , we propose a novel joint inference framework to allow interactions between the two subtasks and find an optimal assignment by addressing the coherence among preliminary local predictions : whether the types of entities meet the expectations of relations explicitly or implicitly , and whether the local predictions are globally compatible .	
CL	D14-1205	4	ab	secondary	proposal_implementation	proposal	none	none	3	-1	elaboration	We further measure the confidence of the extracted triples by looking at the details of the complete extraction process .	In this paper , we propose a novel joint inference framework to allow interactions between the two subtasks and find an optimal assignment by addressing the coherence among preliminary local predictions : whether the types of entities meet the expectations of relations explicitly or implicitly , and whether the local predictions are globally compatible .
CL	D14-1205	5	ab	secondary	result	outcomes	none	none	3	-2	support	Experiments show that the proposed framework can significantly reduce the error propagations thus obtain more reliable facts , and outperforms competitive baselines with state-of-the-art relation extraction models .	In this paper , we propose a novel joint inference framework to allow interactions between the two subtasks and find an optimal assignment by addressing the coherence among preliminary local predictions : whether the types of entities meet the expectations of relations explicitly or implicitly , and whether the local predictions are globally compatible .
CL	D14-1206	1	ab	secondary	motivation_background	motivation	none	none	3	2	info-required	Information in visually rich formats such as PDF and HTML is often conveyed by a combination of textual and visual features .	As a result , traditional text-based approaches to information extraction ( IE ) could underperform .
CL	D14-1206	2	ab	secondary	motivation_background	motivation	none	none	1	-1	elaboration	In particular , genres such as marketing flyers and info-graphics often augment textual information by its color , size , positioning , etc. .	Information in visually rich formats such as PDF and HTML is often conveyed by a combination of textual and visual features .
CL	D14-1206	3	ab	secondary	motivation_problem	motivation	none	none	4	1	support	As a result , traditional text-based approaches to information extraction ( IE ) could underperform .	In this study , we present a supervised machine learning approach to IE from online commercial real estate flyers .
CL	D14-1206	4	ab	main	proposal	proposal	none	none	0	0	none	In this study , we present a supervised machine learning approach to IE from online commercial real estate flyers .	
CL	D14-1206	5	ab	secondary	means	method	none	none	6	1	by-means	We evaluated the performance of SVM classifiers on the task of identifying 12 types of named entities using a combination of textual and visual features .	Results show that the addition of visual features such as color , size , and positioning significantly increased classifier performance .
CL	D14-1206	6	ab	secondary	result	outcomes	none	none	4	-2	support	Results show that the addition of visual features such as color , size , and positioning significantly increased classifier performance .	In this study , we present a supervised machine learning approach to IE from online commercial real estate flyers .
CL	D14-1207	1	ab	secondary	motivation_background	motivation	none	none	2	1	info-required	Temporal scope adds a time dimension to facts in Knowledge Bases ( KBs ) .	These time scopes specify the time periods when a given fact was valid in real life .
CL	D14-1207	2	ab	secondary	motivation_background	motivation	none	none	3	1	info-required	These time scopes specify the time periods when a given fact was valid in real life .	Without temporal scope , many facts are under-specified , reducing the usefulness of the data for upper level applications such as Question Answering .
CL	D14-1207	3	ab	secondary	motivation_problem	motivation	none	none	4	1	info-required	Without temporal scope , many facts are under-specified , reducing the usefulness of the data for upper level applications such as Question Answering .	Existing methods for temporal scope inference and extraction still suffer from low accuracy .
CL	D14-1207	4	ab	secondary	motivation_problem	motivation	none	none	5	1	support	Existing methods for temporal scope inference and extraction still suffer from low accuracy .	In this paper , we present a new method that leverages temporal profiles augmented with context— Contextual Temporal Profiles ( CTPs ) of entities .
CL	D14-1207	5	ab	main	proposal	proposal	none	none	0	0	none	In this paper , we present a new method that leverages temporal profiles augmented with context— Contextual Temporal Profiles ( CTPs ) of entities .	
CL	D14-1207	6	ab	secondary	proposal_implementation	proposal	none	none	5	-1	elaboration	Through change patterns in an entity's CTP , we model the entity's state change brought about by real world events that happen to the entity ( e.g , hired , fired , divorced , etc. ) .	In this paper , we present a new method that leverages temporal profiles augmented with context— Contextual Temporal Profiles ( CTPs ) of entities .
CL	D14-1207	7	ab	secondary	conclusion	outcomes	none	none	6	-1	support	This leads to a new formulation of the temporal scoping problem as a state change detection problem .	Through change patterns in an entity's CTP , we model the entity's state change brought about by real world events that happen to the entity ( e.g , hired , fired , divorced , etc. ) .
CL	D14-1207	8	ab	secondary	result	outcomes	none	none	5	-3	support	Our experiments show that this formulation of the problem , and the resulting solution are highly effective for inferring temporal scope of facts .	In this paper , we present a new method that leverages temporal profiles augmented with context— Contextual Temporal Profiles ( CTPs ) of entities .
CL	D14-1208	1	ab	secondary	motivation_background	motivation	none	none	2	1	info-required	Distant supervision , a paradigm of relation extraction where training data is created by aligning facts in a database with a large unannotated corpus , is an attractive approach for training relation extractors .	Various models are proposed in recent literature to align the facts in the database to their mentions in the corpus .
CL	D14-1208	2	ab	secondary	motivation_background	motivation	none	none	3	1	support	Various models are proposed in recent literature to align the facts in the database to their mentions in the corpus .	In this paper , we discuss and critically analyse a popular alignment strategy called the "at least one" heuristic .
CL	D14-1208	3	ab	main	proposal	proposal	none	none	0	0	none	In this paper , we discuss and critically analyse a popular alignment strategy called the "at least one" heuristic .	
CL	D14-1208	4	ab	secondary	proposal	proposal	none	none	3	-1	elaboration	We provide a simple , yet effective relaxation to this strategy .	In this paper , we discuss and critically analyse a popular alignment strategy called the "at least one" heuristic .
CL	D14-1208	5	ab	secondary	proposal_implementation	proposal	none	none	4	-1	elaboration	We formulate the inference procedures in training as integer linear programming ( ILP ) problems and implement the relaxation to the "at least one " heuristic via a soft constraint in this formulation .	We provide a simple , yet effective relaxation to this strategy .
CL	D14-1208	6	ab	secondary	result	outcomes	none	none	3	-3	support	Empirically , we demonstrate that this simple strategy leads to a better performance under certain settings over the existing approaches .	In this paper , we discuss and critically analyse a popular alignment strategy called the "at least one" heuristic .
CL	D14-1209	1	ab	secondary	motivation_problem	motivation	motivation_hypothesis	motivation	2	1	support	Parameter tuning is an important problem in statistical machine translation , but surprisingly , most existing methods such as MERT , MIRA and PRO are agnostic about search , while search errors could severely degrade translation quality .	We propose a search-aware framework to promote promising partial translations , preventing them from be-ing pruned .
CL	D14-1209	2	ab	main	proposal	proposal	none	none	0	0	none	We propose a search-aware framework to promote promising partial translations , preventing them from be-ing pruned .	
CL	D14-1209	3	ab	secondary	proposal	proposal	none	none	2	-1	elaboration	To do so we develop two metrics to evaluate partial derivations .	We propose a search-aware framework to promote promising partial translations , preventing them from be-ing pruned .
CL	D14-1209	4	ab	secondary	observation	outcomes	none	none	2	-2	support	Our technique can be applied to all of the three above-mentioned tuning methods , and extensive experiments on Chinese-to-English and English-to-Chinese translation show up to +2.6 BLEU gains over search-agnostic baselines .	We propose a search-aware framework to promote promising partial translations , preventing them from be-ing pruned .
CL	D14-1210	1	ab	secondary	motivation_hypothesis	motivation	none	none	2	1	support	Data-driven refinement of non-terminal categories has been demonstrated to be a reliable technique for improving monolingual parsing with PCFGs .	In this paper , we extend these techniques to learn latent refinements of single-category synchronous grammars , so as to improve translation performance .
CL	D14-1210	2	ab	main	proposal	proposal	none	none	0	0	none	In this paper , we extend these techniques to learn latent refinements of single-category synchronous grammars , so as to improve translation performance .	
CL	D14-1210	3	ab	secondary	proposal	proposal	none	none	2	-1	elaboration	We compare two estimators for this latent-variable model : one based on EM and the other is a spectral algorithm based on the method of moments .	In this paper , we extend these techniques to learn latent refinements of single-category synchronous grammars , so as to improve translation performance .
CL	D14-1210	4	ab	secondary	means	method	none	none	5	1	by-means	We evaluate their performance on a Chinese-English translation task .	The results indicate that we can achieve significant gains over the baseline with both approaches , but in particular the moments-based estimator is both faster and performs better than EM .
CL	D14-1210	5	ab	secondary	result	outcomes	none	none	2	-3	support	The results indicate that we can achieve significant gains over the baseline with both approaches , but in particular the moments-based estimator is both faster and performs better than EM .	In this paper , we extend these techniques to learn latent refinements of single-category synchronous grammars , so as to improve translation performance .
CL	D14-1211	1	ab	main	proposal	proposal	none	none	0	0	none	We investigate the interaction of power , gender , and language use in the Enron email corpus .	
CL	D14-1211	2	ab	secondary	proposal	proposal	none	none	1	-1	elaboration	We present a freely available extension to the Enron corpus , with the gender of senders of 87 % messages reliably identified .	We investigate the interaction of power , gender , and language use in the Enron email corpus .
CL	D14-1211	3	ab	secondary	proposal	proposal	none	none	2	-1	elaboration	Using this data , we test two specific hypotheses drawn from the sociolinguistic literature pertaining to gender and power : women managers use face-saving communicative strategies , and women use language more explicitly than men to create and maintain social relations .	We present a freely available extension to the Enron corpus , with the gender of senders of 87 % messages reliably identified .
CL	D14-1211	4	ab	secondary	proposal	proposal	none	none	3	-1	elaboration	We introduce the notion of "gender environment" to the computational study of written conversations ; we interpret this notion as the gender makeup of an email thread , and show that some manifestations of power differ significantly between gender environments .	Using this data , we test two specific hypotheses drawn from the sociolinguistic literature pertaining to gender and power : women managers use face-saving communicative strategies , and women use language more explicitly than men to create and maintain social relations .
CL	D14-1211	5	ab	secondary	proposal	proposal	none	none	4	-1	elaboration	Finally , we show the utility of gender information in the problem of automatically predicting the direction of power between pairs of participants in email interactions .	We introduce the notion of "gender environment" to the computational study of written conversations ; we interpret this notion as the gender makeup of an email thread , and show that some manifestations of power differ significantly between gender environments .
CL	D14-1212	1	ab	secondary	motivation_background	motivation	none	none	2	1	info-required	Latent Dirichlet allocation ( LDA ) is a topic model that has been applied to various fields , including user profiling and event summarization on Twitter .	When LDA is applied to tweet collections , it generally treats all aggregated tweets of a user as a single document .
CL	D14-1212	2	ab	secondary	motivation_background	motivation	none	none	3	1	info-required	When LDA is applied to tweet collections , it generally treats all aggregated tweets of a user as a single document .	Twitter-LDA , which assumes a single tweet consists of a single topic , has been proposed and has shown that it is superior in topic semantic coherence .
CL	D14-1212	3	ab	secondary	motivation_background	motivation	none	none	4	1	info-required	Twitter-LDA , which assumes a single tweet consists of a single topic , has been proposed and has shown that it is superior in topic semantic coherence .	However , Twitter-LDA is not capable of online inference .
CL	D14-1212	4	ab	secondary	motivation_problem	motivation	none	none	5	1	support	However , Twitter-LDA is not capable of online inference .	In this study , we extend Twitter-LDA in the following two ways .
CL	D14-1212	5	ab	main	proposal	proposal	none	none	0	0	none	In this study , we extend Twitter-LDA in the following two ways .	
CL	D14-1212	6	ab	secondary	proposal	proposal	none	none	5	-1	elaboration	First , we model the generation process of tweets more accurately by estimating the ratio between topic words and general words for each user .	In this study , we extend Twitter-LDA in the following two ways .
CL	D14-1212	7	ab	secondary	proposal	proposal	none	none	6	-1	elaboration	Second , we enable it to estimate the dynamics of user interests and topic trends online based on the topic tracking model ( TTM ) , which models consumer purchase behaviors .	First , we model the generation process of tweets more accurately by estimating the ratio between topic words and general words for each user .
CL	D14-1213	1	ab	secondary	information_additional	other	none	none	2	1	info-required	Self-disclosure , the act of revealing one-self to others , is an important social behavior that strengthens interpersonal relationships and increases social support .	Although there are many social science studies of self-disclosure , they are based on manual coding of small datasets and questionnaires .
CL	D14-1213	2	ab	secondary	motivation_problem	motivation	none	none	3	1	support	Although there are many social science studies of self-disclosure , they are based on manual coding of small datasets and questionnaires .	We conduct a computational analysis of self-disclosure with a large dataset of naturally-occurring conversations , a semi-supervised machine learning algorithm , and a computational analysis of the effects of self-disclosure on subsequent conversations .
CL	D14-1213	3	ab	main	proposal_implementation	proposal	none	none	0	0	none	We conduct a computational analysis of self-disclosure with a large dataset of naturally-occurring conversations , a semi-supervised machine learning algorithm , and a computational analysis of the effects of self-disclosure on subsequent conversations .	
CL	D14-1213	4	ab	secondary	proposal_implementation	proposal	none	none	3	-1	elaboration	We use a longitudinal dataset of 17 million tweets , all of which occurred in conversations that consist of five or more tweets directly replying to the previous tweet , and from dyads with twenty of more conversations each .	We conduct a computational analysis of self-disclosure with a large dataset of naturally-occurring conversations , a semi-supervised machine learning algorithm , and a computational analysis of the effects of self-disclosure on subsequent conversations .
CL	D14-1213	5	ab	secondary	proposal_implementation	proposal	none	none	4	-1	sequence	We develop self-disclosure topic model ( SDTM ) , a variant of latent Dirichlet allocation ( LDA ) for automatically classifying the level of self-disclosure for each tweet .	We use a longitudinal dataset of 17 million tweets , all of which occurred in conversations that consist of five or more tweets directly replying to the previous tweet , and from dyads with twenty of more conversations each .
CL	D14-1213	6	ab	secondary	proposal_implementation	proposal	none	none	5	-1	sequence	We take the results of SDTM and analyze the effects of self-disclosure on subsequent conversations .	We develop self-disclosure topic model ( SDTM ) , a variant of latent Dirichlet allocation ( LDA ) for automatically classifying the level of self-disclosure for each tweet .
CL	D14-1213	7	ab	secondary	result	outcomes	none	none	5	-2	support	Our model significantly outperforms several comparable methods on classifying the level of self-disclosure , and the analysis of the longitudinal data using SDTM uncovers significant and positive correlation between self-disclosure and conversation frequency and length .	We develop self-disclosure topic model ( SDTM ) , a variant of latent Dirichlet allocation ( LDA ) for automatically classifying the level of self-disclosure for each tweet .
CL	D14-1214	1	ab	secondary	motivation_background	motivation	none	none	2	1	info-required	Social media websites provide a platform for anyone to describe significant events taking place in their lives in realtime .	Currently , the majority of personal news and life events are published in a textual format , motivating information extraction systems that can provide a structured representations of major life events ( weddings , graduation , etc. ) .
CL	D14-1214	2	ab	secondary	motivation_background	motivation	none	none	3	1	support	Currently , the majority of personal news and life events are published in a textual format , motivating information extraction systems that can provide a structured representations of major life events ( weddings , graduation , etc. ) .	This paper demonstrates the feasibility of accurately extracting major life events .
CL	D14-1214	3	ab	main	proposal	proposal	none	none	0	0	none	This paper demonstrates the feasibility of accurately extracting major life events .	
CL	D14-1214	4	ab	secondary	proposal	proposal	none	none	3	-1	elaboration	Our system extracts a fine-grained description of users' life events based on their published tweets .	This paper demonstrates the feasibility of accurately extracting major life events .
CL	D14-1214	5	ab	secondary	conclusion	outcomes	none	none	3	-2	support	We are optimistic that our system can help Twitter users more easily grasp information from users they take interest in following and also facilitate many downstream applications , for example realtime friend recommendation .	This paper demonstrates the feasibility of accurately extracting major life events .
CL	D14-1215	1	ab	secondary	information_additional	other	none	none	2	1	info-required	Comparisons are common linguistic devices used to indicate the likeness of two things .	Often , this likeness is not meant in the literal sense ��for example , ��I slept like a log�� does not imply that logs actually sleep .
CL	D14-1215	2	ab	secondary	motivation_hypothesis	motivation	none	none	3	1	support	Often , this likeness is not meant in the literal sense ��for example , ��I slept like a log�� does not imply that logs actually sleep .	In this paper we propose a computational study of figurative comparisons , or similes .
CL	D14-1215	3	ab	main	proposal	proposal	none	none	0	0	none	In this paper we propose a computational study of figurative comparisons , or similes .	
CL	D14-1215	4	ab	secondary	proposal_implementation	proposal	none	none	3	-1	elaboration	Our starting point is a new large dataset of comparisons extracted from product reviews and annotated for figurativeness .	In this paper we propose a computational study of figurative comparisons , or similes .
CL	D14-1215	5	ab	secondary	proposal_implementation	proposal	none	none	4	-1	sequence	We use this dataset to characterize figurative language in naturally occurring comparisons and reveal linguistic patterns indicative of this phenomenon .	Our starting point is a new large dataset of comparisons extracted from product reviews and annotated for figurativeness .
CL	D14-1215	6	ab	secondary	proposal_implementation	proposal	none	none	5	-1	sequence	We operationalize these insights and apply them to a new task with high relevance to text understanding : distinguishing between figurative and literal comparisons .	We use this dataset to characterize figurative language in naturally occurring comparisons and reveal linguistic patterns indicative of this phenomenon .
CL	D14-1215	7	ab	secondary	proposal_implementation	proposal	conclusion	outcomes	6	-1	sequence	Finally , we apply this framework to explore the social context in which figurative language is produced , showing that similes are more likely to accompany opinions showing extreme sentiment , and that they are uncommon in reviews deemed helpful .	We operationalize these insights and apply them to a new task with high relevance to text understanding : distinguishing between figurative and literal comparisons .
CL	D14-1216	1	ab	main	proposal	proposal	none	none	0	0	none	We describe an algorithm for automatic classification of idiomatic and literal expressions .	
CL	D14-1216	2	ab	secondary	motivation_hypothesis	motivation	none	none	1	-1	support	Our starting point is that words in a given text segment , such as a paragraph , that are high-ranking representatives of a common topic of discussion are less likely to be a part of an idiomatic expression .	We describe an algorithm for automatic classification of idiomatic and literal expressions .
CL	D14-1216	3	ab	secondary	motivation_hypothesis	motivation	proposal	proposal	1	-2	support	Our additional hypothesis is that contexts in which idioms occur , typically , are more affective and therefore , we incorporate a simple analysis of the intensity of the emotions expressed by the contexts .	We describe an algorithm for automatic classification of idiomatic and literal expressions .
CL	D14-1216	4	ab	secondary	proposal	proposal	none	none	1	-3	elaboration	We investigate the bag of words topic representation of one to three paragraphs containing an expression that should be classified as idiomatic or literal ( a target phrase ) .	We describe an algorithm for automatic classification of idiomatic and literal expressions .
CL	D14-1216	5	ab	secondary	proposal_implementation	proposal	none	none	4	-1	elaboration	We extract topics from paragraphs containing idioms and from paragraphs containing literals using an unsupervised clustering method , Latent Dirichlet Allocation ( LDA ) ( Blei et al. , 2003 ) .	We investigate the bag of words topic representation of one to three paragraphs containing an expression that should be classified as idiomatic or literal ( a target phrase ) .
CL	D14-1216	6	ab	secondary	proposal_implementation	proposal	none	none	5	-1	elaboration	Since idiomatic expressions exhibit the property of non-compositionality , we assume that they usually present different semantics than the words used in the local topic .	We extract topics from paragraphs containing idioms and from paragraphs containing literals using an unsupervised clustering method , Latent Dirichlet Allocation ( LDA ) ( Blei et al. , 2003 ) .
CL	D14-1216	7	ab	secondary	proposal_implementation	proposal	none	none	6	-1	elaboration	We treat idioms as semantic outliers , and the identification of a semantic shift as outlier detection .	Since idiomatic expressions exhibit the property of non-compositionality , we assume that they usually present different semantics than the words used in the local topic .
CL	D14-1216	8	ab	secondary	proposal_implementation	proposal	none	none	7	-1	elaboration	Thus , this topic representation allows us to differentiate idioms from literals using local semantic contexts .	We treat idioms as semantic outliers , and the identification of a semantic shift as outlier detection .
CL	D14-1216	9	ab	secondary	result	outcomes	none	none	1	-8	support	Our results are encouraging .	We describe an algorithm for automatic classification of idiomatic and literal expressions .
CL	D14-1217	1	ab	secondary	proposal	proposal	none	none	3	2	elaboration	We address the grounding of natural language to concrete spatial constraints , and inference of implicit pragmatics in 3D environments .	We present a representation for common sense spatial knowledge and an approach to extract it from 3D scene data .
CL	D14-1217	2	ab	secondary	proposal	proposal	none	none	1	-1	elaboration	We apply our approach to the task of text-to-3D scene generation .	We address the grounding of natural language to concrete spatial constraints , and inference of implicit pragmatics in 3D environments .
CL	D14-1217	3	ab	main	proposal	proposal	none	none	0	0	none	We present a representation for common sense spatial knowledge and an approach to extract it from 3D scene data .	
CL	D14-1217	4	ab	secondary	information_additional	other	none	none	2	-2	info-optional	In text-to-3D scene generation , a user provides as input natural language text from which we extract explicit constraints on the objects that should appear in the scene .	We apply our approach to the task of text-to-3D scene generation .
CL	D14-1217	5	ab	secondary	conclusion	outcomes	none	none	3	-2	support	The main innovation of this work is to show how to augment these explicit constraints with learned spatial knowledge to infer missing objects and likely layouts for the objects in the scene .	We present a representation for common sense spatial knowledge and an approach to extract it from 3D scene data .
CL	D14-1217	6	ab	secondary	conclusion	outcomes	none	none	5	-1	elaboration	We demonstrate that spatial knowledge is useful for interpreting natural language and show examples of learned knowledge and generated 3D scenes .	The main innovation of this work is to show how to augment these explicit constraints with learned spatial knowledge to infer missing objects and likely layouts for the objects in the scene .
CL	D14-1218	1	ab	secondary	motivation_background	motivation	none	none	2	1	info-required	Coherence is what makes a multi-sentence text meaningful , both logically and syntactically .	To solve the challenge of ordering a set of sentences into coherent order , existing approaches focus mostly on defining and using sophisticated features to capture the cross-sentence argumentation logic and syntactic relationships .
CL	D14-1218	2	ab	secondary	motivation_background	motivation	none	none	3	1	info-required	To solve the challenge of ordering a set of sentences into coherent order , existing approaches focus mostly on defining and using sophisticated features to capture the cross-sentence argumentation logic and syntactic relationships .	But both argumentation semantics and cross-sentence syntax ( such as coreference and tense rules ) are very hard to formalize .
CL	D14-1218	3	ab	secondary	motivation_problem	motivation	none	none	4	1	support	But both argumentation semantics and cross-sentence syntax ( such as coreference and tense rules ) are very hard to formalize .	In this paper , we introduce a neural network model for the coherence task based on distributed sentence representation .
CL	D14-1218	4	ab	main	proposal	proposal	none	none	0	0	none	In this paper , we introduce a neural network model for the coherence task based on distributed sentence representation .	
CL	D14-1218	5	ab	secondary	proposal_implementation	proposal	none	none	4	-1	elaboration	The proposed approach learns a syntactico-semantic representation for sentences automatically , using either recurrent or recursive neural networks .	In this paper , we introduce a neural network model for the coherence task based on distributed sentence representation .
CL	D14-1218	6	ab	secondary	proposal_implementation	proposal	none	none	5	-1	elaboration	The architecture obviated the need for feature engineering , and learns sentence representations , which are to some extent able to capture the "rules" governing coherent sentence structure .	The proposed approach learns a syntactico-semantic representation for sentences automatically , using either recurrent or recursive neural networks .
CL	D14-1218	7	ab	secondary	result	outcomes	none	none	4	-3	support	The proposed approach outperforms existing baselines and generates the state-of-art performance in standard coherence evaluation tasks .	In this paper , we introduce a neural network model for the coherence task based on distributed sentence representation .
CL	D14-1219	1	ab	main	proposal	proposal	none	none	0	0	none	In this paper , we present a discriminative approach for reranking discourse trees generated by an existing probabilistic discourse parser .	
CL	D14-1219	2	ab	secondary	proposal_implementation	proposal	none	none	3	1	elaboration	The reranker relies on tree kernels ( TKs ) to capture the global dependencies between discourse units in a tree .	In particular , we design new computational structures of discourse trees , which combined with standard TKs , originate novel discourse TKs .
CL	D14-1219	3	ab	secondary	proposal	proposal	none	none	1	-2	elaboration	In particular , we design new computational structures of discourse trees , which combined with standard TKs , originate novel discourse TKs .	In this paper , we present a discriminative approach for reranking discourse trees generated by an existing probabilistic discourse parser .
CL	D14-1219	4	ab	secondary	observation	outcomes	none	none	1	-3	support	The empirical evaluation shows that our reranker can improve the state-of-the-art sentence-level parsing accuracy from 79.77 % to 82.15 % , a relative error reduction of 11.8 % , which in turn pushes the state-of-the-art document-level accuracy from 55.8 % to 57.3 % .	In this paper , we present a discriminative approach for reranking discourse trees generated by an existing probabilistic discourse parser .
CL	D14-1220	1	ab	secondary	motivation_problem	motivation	none	none	2	1	support	Text-level discourse parsing remains a challenge : most approaches employ features that fail to capture the intentional , semantic , and syntactic aspects that govern discourse coherence .	In this paper , we propose a recursive model for discourse parsing that jointly models distributed representations for clauses , sentences , and entire discourses .
CL	D14-1220	2	ab	main	proposal	proposal	none	none	0	0	none	In this paper , we propose a recursive model for discourse parsing that jointly models distributed representations for clauses , sentences , and entire discourses .	
CL	D14-1220	3	ab	secondary	proposal	proposal	none	none	2	-1	elaboration	The learned representations can to some extent learn the semantic and intentional import of words and larger discourse units automatically , .	In this paper , we propose a recursive model for discourse parsing that jointly models distributed representations for clauses , sentences , and entire discourses .
CL	D14-1220	4	ab	secondary	result	outcomes	none	none	2	-2	support	The proposed framework obtains comparable performance regarding standard discours-ing parsing evaluations when compared against current state-of-art systems .	In this paper , we propose a recursive model for discourse parsing that jointly models distributed representations for clauses , sentences , and entire discourses .
CL	D14-1221	1	ab	main	proposal	proposal	none	none	0	0	none	We present a novel method for coreference resolution error analysis which we apply to perform a recall error analysis of four state-of-the-art English coreference resolution systems .	
CL	D14-1221	2	ab	secondary	proposal	proposal	none	none	1	-1	elaboration	Our analysis highlights differences between the systems and identifies that the majority of recall errors for nouns and names are shared by all systems .	We present a novel method for coreference resolution error analysis which we apply to perform a recall error analysis of four state-of-the-art English coreference resolution systems .
CL	D14-1221	3	ab	secondary	proposal	proposal	none	none	2	-1	elaboration	We characterize this set of common challenging errors in terms of a broad range of lexical and semantic properties .	Our analysis highlights differences between the systems and identifies that the majority of recall errors for nouns and names are shared by all systems .
CL	D14-1222	1	ab	secondary	motivation_background	motivation	none	none	2	1	support	Bridging resolution plays an important role in establishing ( local ) entity coherence .	This paper proposes a rule-based approach for the challenging task of unrestricted bridging resolution , where bridging anaphors are not limited to definite NPs and semantic relations between anaphors and their antecedents are not restricted to meronymic relations .
CL	D14-1222	2	ab	main	proposal	proposal	none	none	0	0	none	This paper proposes a rule-based approach for the challenging task of unrestricted bridging resolution , where bridging anaphors are not limited to definite NPs and semantic relations between anaphors and their antecedents are not restricted to meronymic relations .	
CL	D14-1222	3	ab	secondary	proposal_implementation	proposal	none	none	2	-1	elaboration	The system consists of eight rules which target different relations based on linguistic insights .	This paper proposes a rule-based approach for the challenging task of unrestricted bridging resolution , where bridging anaphors are not limited to definite NPs and semantic relations between anaphors and their antecedents are not restricted to meronymic relations .
CL	D14-1222	4	ab	secondary	result	outcomes	none	none	2	-2	support	Our rule-based system significantly outperforms a reimplementation of a previous rule-based system ( Vieira and Poesio , 2000 ) .	This paper proposes a rule-based approach for the challenging task of unrestricted bridging resolution , where bridging anaphors are not limited to definite NPs and semantic relations between anaphors and their antecedents are not restricted to meronymic relations .
CL	D14-1222	5	ab	secondary	result	outcomes	none	none	4	-1	elaboration	Furthermore , it performs better than a learning-based approach which has access to the same knowledge resources as the rule-based system .	Our rule-based system significantly outperforms a reimplementation of a previous rule-based system ( Vieira and Poesio , 2000 ) .
CL	D14-1222	6	ab	secondary	result	outcomes	none	none	5	-1	elaboration	Additionally , incorporating the rules and more features into the learning-based system yields a minor improvement over the rule-based system .	Furthermore , it performs better than a learning-based approach which has access to the same knowledge resources as the rule-based system .
CL	D14-1223	1	ab	secondary	motivation_background	motivation	none	none	2	1	info-required	Unlike traditional over-the-phone spoken dialog systems ( SDSs ) , modern dialog systems tend to have visual rendering on the device screen as an additional modality to communicate the system's response to the user .	Visual display of the system's response not only changes human behavior when interacting with devices , but also creates new research areas in SDSs .
CL	D14-1223	2	ab	secondary	motivation_background	motivation	none	none	3	1	info-required	Visual display of the system's response not only changes human behavior when interacting with devices , but also creates new research areas in SDSs .	On-screen item identification and resolution in utterances is one critical problem to achieve a natural and accurate human-machine communication .
CL	D14-1223	3	ab	secondary	motivation_problem	motivation	none	none	4	1	support	On-screen item identification and resolution in utterances is one critical problem to achieve a natural and accurate human-machine communication .	We pose the problem as a classification task to correctly identify intended on-screen item ( s ) from user utterances .
CL	D14-1223	4	ab	main	proposal	proposal	none	none	0	0	none	We pose the problem as a classification task to correctly identify intended on-screen item ( s ) from user utterances .	
CL	D14-1223	5	ab	secondary	observation	outcomes	none	none	4	-1	support	Using syntactic , semantic as well as context features from the display screen , our model can resolve different types of referring expressions with up to 90 % accuracy .	We pose the problem as a classification task to correctly identify intended on-screen item ( s ) from user utterances .
CL	D14-1223	6	ab	secondary	result	outcomes	none	none	5	-1	elaboration	In the experiments we also show that the proposed model is robust to domain and screen layout changes .	Using syntactic , semantic as well as context features from the display screen , our model can resolve different types of referring expressions with up to 90 % accuracy .
CL	D14-1224	1	ab	main	proposal_implementation	proposal	none	none	0	0	none	In this paper , we propose a Connective-driven Dependency Tree ( CDT ) scheme to represent the discourse rhetorical structure in Chinese language ,  with elementary discourse units as leaf nodes and connectives as non-leaf nodes , largely motivated by the Penn Discourse Treebank and the Rhetorical Structure Theory .	
CL	D14-1224	2	ab	secondary	proposal_implementation	proposal	none	none	1	-1	elaboration	In particular , connectives are employed to directly represent the hierarchy of the tree structure and the rhetorical relation of a discourse , while the nuclei of discourse units are globally determined with reference to the dependency theory .	In this paper , we propose a Connective-driven Dependency Tree ( CDT ) scheme to represent the discourse rhetorical structure in Chinese language ,  with elementary discourse units as leaf nodes and connectives as non-leaf nodes , largely motivated by the Penn Discourse Treebank and the Rhetorical Structure Theory .
CL	D14-1224	3	ab	secondary	proposal_implementation	proposal	none	none	2	-1	elaboration	Guided by the CDT scheme , we manually annotate a Chinese Discourse Treebank ( CDTB ) of 500 documents .	In particular , connectives are employed to directly represent the hierarchy of the tree structure and the rhetorical relation of a discourse , while the nuclei of discourse units are globally determined with reference to the dependency theory .
CL	D14-1224	4	ab	secondary	result	outcomes	none	none	1	-3	support	Preliminary evaluation justifies the appropriateness of the CDT scheme to Chinese discourse analysis and the usefulness of our manually annotated CDTB corpus .	In this paper , we propose a Connective-driven Dependency Tree ( CDT ) scheme to represent the discourse rhetorical structure in Chinese language ,  with elementary discourse units as leaf nodes and connectives as non-leaf nodes , largely motivated by the Penn Discourse Treebank and the Rhetorical Structure Theory .
CL	D14-1225	1	ab	main	proposal	proposal	none	none	0	0	none	We propose a novel search-based approach for greedy coreference resolution , where the mentions are processed in order and added to previous coreference clusters .	
CL	D14-1225	2	ab	secondary	proposal_implementation	proposal	none	none	1	-1	elaboration	Our method is distinguished by the use of two functions to make each coreference decision : a pruning function that prunes bad coreference decisions from further consideration , and a scoring function that then selects the best among the remaining decisions .	We propose a novel search-based approach for greedy coreference resolution , where the mentions are processed in order and added to previous coreference clusters .
CL	D14-1225	3	ab	secondary	proposal	proposal	none	none	2	-1	elaboration	Our framework reduces learning of these functions to rank learning , which helps leverage powerful off-the-shelf rank-learners .	Our method is distinguished by the use of two functions to make each coreference decision : a pruning function that prunes bad coreference decisions from further consideration , and a scoring function that then selects the best among the remaining decisions .
CL	D14-1225	4	ab	secondary	result_means	outcomes	none	none	1	-3	support	We show that our Prune-and-Score approach is superior to using a single scoring function to make both decisions and outperforms several state-of-the-art approaches on multiple benchmark corpora including OntoNotes .	We propose a novel search-based approach for greedy coreference resolution , where the mentions are processed in order and added to previous coreference clusters .
CL	D14-1226	1	ab	secondary	motivation_background	motivation	none	none	2	1	info-required	A typical discussion thread in an online forum spans multiple pages involving participation from multiple users and thus , may contain multiple view-points and solutions .	A user interested in the topic of discussion or having a problem similar to being discussed in the thread may not want to read all the previous posts but only a few selected posts that provide her a concise summary of the ongoing discussion .
CL	D14-1226	2	ab	secondary	motivation_hypothesis	motivation	none	none	3	1	support	A user interested in the topic of discussion or having a problem similar to being discussed in the thread may not want to read all the previous posts but only a few selected posts that provide her a concise summary of the ongoing discussion .	This paper describes an extractive summarization technique that uses textual features and dialog act information of individual messages to select a subset of posts .
CL	D14-1226	3	ab	main	proposal	proposal	none	none	0	0	none	This paper describes an extractive summarization technique that uses textual features and dialog act information of individual messages to select a subset of posts .	
CL	D14-1226	4	ab	secondary	means	method	none	none	3	-1	by-means	Proposed approach is evaluated using two real life forum datasets .	This paper describes an extractive summarization technique that uses textual features and dialog act information of individual messages to select a subset of posts .
