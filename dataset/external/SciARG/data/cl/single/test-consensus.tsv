domain	doc_id	adu_pos	annotator	main_unit	aty	coarse_aty	second_type	coarse_second_type	parent_pos	parent_pos_rel	afu	text	text_parent
CL	D14-1040	1	ca	main	proposal	proposal	none	none	0	0	none	We propose the first probabilistic approach to modeling cross-lingual semantic similarity ( CLSS ) in context which requires only comparable data .	
CL	D14-1040	2	ca	secondary	proposal_implementation	proposal	none	none	1	-1	elaboration	The approach relies on an idea of projecting words and sets of words into a shared latent semantic space spanned by language-pair independent latent semantic concepts ( e.g. , cross-lingual topics obtained by a multilingual topic model ) .	We present new models that modulate the isolated out-of-context word representations with contextual knowledge .
CL	D14-1040	3	ca	secondary	proposal_implementation	proposal	none	none	2	-1	elaboration	These latent cross-lingual concepts are induced from a comparable corpus without any additional lexical resources .	The approach relies on an idea of projecting words and sets of words into a shared latent semantic space spanned by language-pair independent latent semantic concepts ( e.g. , cross-lingual topics obtained by a multilingual topic model ) .
CL	D14-1040	4	ca	secondary	proposal_implementation	proposal	none	none	2	-2	elaboration	Word meaning is represented as a probability distribution over the latent concepts , and a change in meaning is represented as a change in the distribution over these latent concepts .	These latent cross-lingual concepts are induced from a comparable corpus without any additional lexical resources .
CL	D14-1040	5	ca	secondary	proposal_implementation	proposal	none	none	1	-4	elaboration	We present new models that modulate the isolated out-of-context word representations with contextual knowledge .	We propose the first probabilistic approach to modeling cross-lingual semantic similarity ( CLSS ) in context which requires only comparable data .
CL	D14-1040	6	ca	secondary	result	outcomes	none	none	5	-1	support	Results on the task of suggesting word translations in context for 3 language pairs reveal the utility of the proposed contextualized models of cross-lingual semantic similarity .	We present new models that modulate the isolated out-of-context word representations with contextual knowledge .
CL	D14-1041	1	ca	secondary	motivation_problem	motivation	motivation_problem	motivation	2	1	support	The current approaches to Semantic Role Labeling ( SRL ) usually perform role classification for each predicate separately and the interaction among individual predicate's role labeling is ignored if there is more than one predicate in a sentence .	In this paper , we prove that different predicates in a sentence could help each other during SRL .
CL	D14-1041	2	ca	main	proposal	proposal	none	none	0	0	none	In this paper , we prove that different predicates in a sentence could help each other during SRL .	
CL	D14-1041	3	ca	secondary	motivation_background	motivation	none	none	1	-2	info-optional	In multi-predicate role labeling , there are mainly two key points : argument identification and role labeling of the arguments shared by multiple predicates .	The current approaches to Semantic Role Labeling ( SRL ) usually perform role classification for each predicate separately and the interaction among individual predicate's role labeling is ignored if there is more than one predicate in a sentence .
CL	D14-1041	4	ca	secondary	proposal_implementation	proposal	none	none	2	-2	elaboration	To address these issues , in the stage of argument identification , we propose novel predicate-related features which help remove many argument identification errors ; in the stage of argument classification , we adopt a discriminative reranking approach to perform role classification of the shared arguments , in which a large set of global features are proposed .	In this paper , we prove that different predicates in a sentence could help each other during SRL .
CL	D14-1041	5	ca	secondary	means	method	none	none	6	1	by-means	We conducted experiments on two standard benchmarks : Chinese PropBank and English PropBank .	The experimental results show that our approach can significantly improve SRL performance , especially in Chinese PropBank .
CL	D14-1041	6	ca	secondary	result	outcomes	none	none	4	-2	support	The experimental results show that our approach can significantly improve SRL performance , especially in Chinese PropBank .	To address these issues , in the stage of argument identification , we propose novel predicate-related features which help remove many argument identification errors ; in the stage of argument classification , we adopt a discriminative reranking approach to perform role classification of the shared arguments , in which a large set of global features are proposed .
CL	D14-1042	1	ca	secondary	motivation_background	motivation	none	none	2	1	info-required	Word-sense recognition and disambiguation ( WERD ) is the task of identifying word phrases and their senses in natural language text .	Though it is well understood how to disambiguate noun phrases , this task is much less studied for verbs and verbal phrases .
CL	D14-1042	2	ca	secondary	motivation_problem	motivation	none	none	3	1	support	Though it is well understood how to disambiguate noun phrases , this task is much less studied for verbs and verbal phrases .	We present Werdy , a framework for WERD with particular focus on verbs and verbal phrases .
CL	D14-1042	3	ca	main	proposal	proposal	none	none	0	0	none	We present Werdy , a framework for WERD with particular focus on verbs and verbal phrases .	
CL	D14-1042	4	ca	secondary	proposal_implementation	proposal	none	none	3	-1	elaboration	Our framework first identifies multi-word expressions based on the syntactic structure of the sentence ; this allows us to recognize both contiguous and non-contiguous phrases .	We present Werdy , a framework for WERD with particular focus on verbs and verbal phrases .
CL	D14-1042	5	ca	secondary	proposal_implementation	proposal	none	none	4	-1	sequence	We then generate a list of candidate senses for each word or phrase , using novel syntactic and semantic pruning techniques .	Our framework first identifies multi-word expressions based on the syntactic structure of the sentence ; this allows us to recognize both contiguous and non-contiguous phrases .
CL	D14-1042	6	ca	secondary	proposal_implementation	proposal	none	none	5	-1	elaboration	We also construct and leverage a new resource of pairs of senses for verbs and their object arguments .	Our framework first identifies multi-word expressions based on the syntactic structure of the sentence ; this allows us to recognize both contiguous and non-contiguous phrases .
CL	D14-1042	7	ca	secondary	proposal_implementation	proposal	none	none	5	-2	sequence	Finally , we feed the so-obtained candidate senses into standard word-sense disambiguation ( WSD ) methods , and boost their precision and recall .	We then generate a list of candidate senses for each word or phrase , using novel syntactic and semantic pruning techniques .
CL	D14-1042	8	ca	secondary	result	outcomes	none	none	3	-5	support	Our experiments indicate that Werdy significantly increases the performance of existing WSD methods .	We present Werdy , a framework for WERD with particular focus on verbs and verbal phrases .
CL	D14-1043	1	ca	secondary	motivation_background	motivation	none	none	2	1	info-required	Language is given meaning through its correspondence with a world representation .	This correspondence can be at multiple levels of granularity or resolutions .
CL	D14-1043	2	ca	secondary	motivation_background	motivation	none	none	3	1	support	This correspondence can be at multiple levels of granularity or resolutions .	In this paper , we introduce an approach to multi-resolution language grounding in the extremely challenging domain of professional soccer commentaries .
CL	D14-1043	3	ca	main	proposal	proposal	none	none	0	0	none	In this paper , we introduce an approach to multi-resolution language grounding in the extremely challenging domain of professional soccer commentaries .	
CL	D14-1043	4	ca	secondary	proposal_implementation	proposal	none	none	3	-1	elaboration	We define and optimize a factored objective function that allows us to leverage discourse structure and the compositional nature of both language and game events .	In this paper , we introduce an approach to multi-resolution language grounding in the extremely challenging domain of professional soccer commentaries .
CL	D14-1043	5	ca	secondary	result	outcomes	none	none	3	-2	support	We show that finer resolution grounding helps coarser resolution grounding , and vice versa .	In this paper , we introduce an approach to multi-resolution language grounding in the extremely challenging domain of professional soccer commentaries .
CL	D14-1043	6	ca	secondary	observation	outcomes	none	none	5	-1	support	Our method results in an F1 improvement of more than 48 % versus the previous state of the art for fine-resolution grounding .	We show that finer resolution grounding helps coarser resolution grounding , and vice versa .
CL	D14-1044	1	ca	secondary	motivation_background	motivation	none	none	2	1	info-required	Much work in recent years has gone into the construction of large knowledge bases ( KBs ) , such as Freebase , DBPedia , NELL , and YAGO .	Prior work has shown how to make use of a large text corpus to augment random walk inference over KBs .
CL	D14-1044	2	ca	secondary	motivation_problem	motivation	none	none	4	2	support	While these KBs are very large , they are still very incomplete , necessitating the use of inference to fill in gaps .	We present two improvements to the use of such large corpora to augment KB inference .
CL	D14-1044	3	ca	secondary	motivation_background	motivation	none	none	2	-1	support	Prior work has shown how to make use of a large text corpus to augment random walk inference over KBs .	While these KBs are very large , they are still very incomplete , necessitating the use of inference to fill in gaps .
CL	D14-1044	4	ca	main	proposal	proposal	none	none	0	0	none	We present two improvements to the use of such large corpora to augment KB inference .	
CL	D14-1044	5	ca	secondary	proposal_implementation	proposal	conclusion	outcomes	4	-1	elaboration	First , we present a new technique for combining KB relations and surface text into a single graph representation that is much more compact than graphs used in prior work .	We present two improvements to the use of such large corpora to augment KB inference .
CL	D14-1044	6	ca	secondary	proposal_implementation	proposal	conclusion	outcomes	5	-1	elaboration	Second , we describe how to incorporate vector space similarity into random walk inference over KBs , reducing the feature sparsity inherent in using surface text .	First , we present a new technique for combining KB relations and surface text into a single graph representation that is much more compact than graphs used in prior work .
CL	D14-1044	7	ca	secondary	proposal	proposal	conclusion	outcomes	6	-1	elaboration	This allows us to combine distributional similarity with symbolic logical inference in novel and effective ways .	Second , we describe how to incorporate vector space similarity into random walk inference over KBs , reducing the feature sparsity inherent in using surface text .
CL	D14-1044	8	ca	secondary	result_means	outcomes	none	none	4	-4	support	With experiments on many relations from two separate KBs , we show that our methods significantly outperform prior work on KB inference , both in the size of problem our methods can handle and in the quality of predictions made .	We present two improvements to the use of such large corpora to augment KB inference .
CL	D14-1045	1	ca	secondary	motivation_background	motivation	none	none	2	1	info-required	State-of-the-art semantic role labelling systems require large annotated corpora to achieve full performance .	In this paper , we mitigate both of these problems by employing distributional word representations gathered from unlabelled data .
CL	D14-1045	2	ca	secondary	motivation_problem	motivation	none	none	4	2	support	Unfortunately , such corpora are expensive to produce and often do not generalize well across do-mains .	State-of-the-art semantic role labelling systems require large annotated corpora to achieve full performance .
CL	D14-1045	3	ca	secondary	motivation_problem	motivation	none	none	2	-1	elaboration	Even in domain , errors are often made where syntactic information does not provide sufficient cues .	Unfortunately , such corpora are expensive to produce and often do not generalize well across do-mains .
CL	D14-1045	4	ca	main	proposal	proposal	none	none	0	0	none	In this paper , we mitigate both of these problems by employing distributional word representations gathered from unlabelled data .	
CL	D14-1045	5	ca	secondary	result_means	outcomes	none	none	4	-1	support	While straight-forward word representations of predicates and arguments improve performance , we show that further gains are achieved by composing representations that model the interaction between predicate and argument , and capture full argument spans .	In this paper , we mitigate both of these problems by employing distributional word representations gathered from unlabelled data .
CL	D14-1046	1	ca	main	proposal	proposal	none	none	0	0	none	This paper reports on the development of a hybrid and simple method based on a machine learning classifier ( Naive Bayes ) , Word Sense Disambiguation and rules , for the automatic assignment of WordNet Domains to nominal entries of a lexicographic dictionary , the Senso Comune De Mauro Lexicon .	
CL	D14-1046	2	ca	secondary	observation	outcomes	none	none	1	-1	support	The system obtained an F1 score of 0.58 , with a Precision of 0.70 .	This has led to an improvement in the quality of the sense alignments showing the validity of the approach for domain assignment and the importance of domain information for achieving good sense alignments .
CL	D14-1046	3	ca	secondary	proposal_implementation	proposal	none	none	1	-2	elaboration	We further used the automatically assigned domains to filter out word sense alignments between MultiWordNet and Senso Comune .	This paper reports on the development of a hybrid and simple method based on a machine learning classifier ( Naive Bayes ) , Word Sense Disambiguation and rules , for the automatic assignment of WordNet Domains to nominal entries of a lexicographic dictionary , the Senso Comune De Mauro Lexicon .
CL	D14-1046	4	ca	secondary	result	outcomes	none	none	3	-1	support	This has led to an improvement in the quality of the sense alignments showing the validity of the approach for domain assignment and the importance of domain information for achieving good sense alignments .	This paper reports on the development of a hybrid and simple method based on a machine learning classifier ( Naive Bayes ) , Word Sense Disambiguation and rules , for the automatic assignment of WordNet Domains to nominal entries of a lexicographic dictionary , the Senso Comune De Mauro Lexicon .
CL	D14-1047	1	ca	secondary	motivation_background	motivation	none	none	2	1	support	Much attention has been given to the impact of informativeness and similarity measures on distributional thesauri .	We investigate the effects of context filters on thesaurus quality and propose the use of cooccurrence frequency as a simple and inexpensive criterion .
CL	D14-1047	2	ca	main	proposal	proposal	none	none	0	0	none	We investigate the effects of context filters on thesaurus quality and propose the use of cooccurrence frequency as a simple and inexpensive criterion .	
CL	D14-1047	3	ca	secondary	means	method	none	none	4	1	by-means	For evaluation , we measure thesaurus agreement with WordNet and performance in answering TOEFL-like questions .	Results illustrate the sensitivity of distributional thesauri to filters .
CL	D14-1047	4	ca	secondary	result	outcomes	none	none	2	-2	support	Results illustrate the sensitivity of distributional thesauri to filters .	We investigate the effects of context filters on thesaurus quality and propose the use of cooccurrence frequency as a simple and inexpensive criterion .
CL	D14-1048	1	ca	main	proposal	proposal	none	none	0	0	none	We align pairs of English sentences and corresponding Abstract Meaning Representations ( AMR ) , at the token level .	
CL	D14-1048	2	ca	secondary	motivation_hypothesis	motivation	none	none	1	-1	support	Such alignments will be useful for downstream extraction of semantic interpretation and generation rules .	We align pairs of English sentences and corresponding Abstract Meaning Representations ( AMR ) , at the token level .
CL	D14-1048	3	ca	secondary	proposal_implementation	proposal	none	none	1	-2	elaboration	Our method involves linearizing AMR structures and performing symmetrized EM training .	We align pairs of English sentences and corresponding Abstract Meaning Representations ( AMR ) , at the token level .
CL	D14-1048	4	ca	secondary	observation	outcomes	none	none	1	-3	support	We obtain 86.5 % and 83.1 % alignment F score on development and test sets .	We align pairs of English sentences and corresponding Abstract Meaning Representations ( AMR ) , at the token level .
CL	D14-1049	1	ca	main	proposal	proposal	none	none	0	0	none	We introduce a Semantic Role Labeling ( SRL ) parser that finds semantic roles for a predicate together with the syntactic paths linking predicates and arguments .	
CL	D14-1049	2	ca	secondary	proposal_implementation	proposal	conclusion	outcomes	1	-1	elaboration	Our main contribution is to formulate SRL in terms of shortest-path inference , on the assumption that the SRL model is restricted to arc-factored features of the syntactic paths behind semantic roles .	We introduce a Semantic Role Labeling ( SRL ) parser that finds semantic roles for a predicate together with the syntactic paths linking predicates and arguments .
CL	D14-1049	3	ca	secondary	proposal_implementation	proposal	conclusion	outcomes	2	-1	elaboration	Overall , our method for SRL is a novel way to exploit larger variability in the syntactic realizations of predicate-argument relations , moving away from pipeline architectures .	Our main contribution is to formulate SRL in terms of shortest-path inference , on the assumption that the SRL model is restricted to arc-factored features of the syntactic paths behind semantic roles .
CL	D14-1049	4	ca	secondary	result	outcomes	none	none	1	-3	support	Experiments show that our approach improves the robustness of the predictions , producing arc-factored models that perform closely to methods using unrestricted features from the syntax .	We introduce a Semantic Role Labeling ( SRL ) parser that finds semantic roles for a predicate together with the syntactic paths linking predicates and arguments .
CL	D14-1050	1	ca	main	proposal	proposal	motivation_background	motivation	0	0	none	We present an empirical study on the use of semantic information for Concept Segmentation and Labeling ( CSL ) , which is an important step for semantic parsing .	
CL	D14-1050	2	ca	secondary	proposal_implementation	proposal	none	none	1	-1	elaboration	We represent the alternative analyses output by a state-of-the-art CSL parser with tree structures , which we rerank with a classifier trained on two types of semantic tree kernels : one processing structures built with words , concepts and Brown clusters , and another one using semantic similarity among the words composing the structure .	We present an empirical study on the use of semantic information for Concept Segmentation and Labeling ( CSL ) , which is an important step for semantic parsing .
CL	D14-1050	3	ca	secondary	result	outcomes	none	none	1	-2	support	The results on a corpus from the restaurant domain show that our semantic kernels exploiting similarity measures outperform state-of-the-art rerankers .	We present an empirical study on the use of semantic information for Concept Segmentation and Labeling ( CSL ) , which is an important step for semantic parsing .
CL	D14-1051	1	ca	secondary	motivation_background	motivation	none	none	2	1	info-required	Various studies highlighted that topic-based approaches give a powerful spoken content representation of documents .	In this study , we propose an original and promising framework based on a compact representation of a textual document , to solve issues related to topic space granularity .
CL	D14-1051	2	ca	secondary	motivation_problem	motivation	none	none	3	1	support	Nonetheless , these documents may contain more than one main theme , and their automatic transcription inevitably contains errors .	Various studies highlighted that topic-based approaches give a powerful spoken content representation of documents .
CL	D14-1051	3	ca	main	proposal	proposal	none	none	0	0	none	In this study , we propose an original and promising framework based on a compact representation of a textual document , to solve issues related to topic space granularity .	
CL	D14-1051	4	ca	secondary	proposal_implementation	proposal	none	none	3	-1	elaboration	Firstly , various topic spaces are estimated with different numbers of classes from a Latent Dirichlet Allocation .	In this study , we propose an original and promising framework based on a compact representation of a textual document , to solve issues related to topic space granularity .
CL	D14-1051	5	ca	secondary	proposal_implementation	proposal	none	none	4	-1	sequence	Then , this multiple topic space representation is compacted into an elementary segment , called c-vector , originally developed in the context of speaker recognition .	Firstly , various topic spaces are estimated with different numbers of classes from a Latent Dirichlet Allocation .
CL	D14-1051	6	ca	secondary	means	method	none	none	7	1	by-means	Experiments are conducted on the DECODA corpus of conversations .	Our identification system reaches an accuracy of 85 % , with a significant gain of 9 points compared to the baseline ( best single topic space configuration ) .
CL	D14-1051	7	ca	secondary	result	outcomes	none	none	3	-4	support	Results show the effectiveness of the proposed multi-view compact representation paradigm .	In this study , we propose an original and promising framework based on a compact representation of a textual document , to solve issues related to topic space granularity .
CL	D14-1051	8	ca	secondary	observation	outcomes	none	none	7	-1	support	Our identification system reaches an accuracy of 85 % , with a significant gain of 9 points compared to the baseline ( best single topic space configuration ) .	Results show the effectiveness of the proposed multi-view compact representation paradigm .
CL	D14-1052	1	ca	main	proposal	proposal	none	none	0	0	none	This paper introduces a model of multiple-instance learning applied to the prediction of aspect ratings or judgments of specific properties of an item from user-contributed texts such as product reviews .	
CL	D14-1052	2	ca	secondary	proposal_implementation	proposal	none	none	1	-1	elaboration	Each variable-length text is represented by several independent feature vectors ; one word vector per sentence or paragraph .	This paper introduces a model of multiple-instance learning applied to the prediction of aspect ratings or judgments of specific properties of an item from user-contributed texts such as product reviews .
CL	D14-1052	3	ca	secondary	proposal_implementation	proposal	none	none	2	-1	elaboration	For learning from texts with known aspect ratings , the model performs multiple-instance regression ( MIR ) and assigns importance weights to each of the sentences or paragraphs of a text , uncovering their contribution to the aspect ratings .	Each variable-length text is represented by several independent feature vectors ; one word vector per sentence or paragraph .
CL	D14-1052	4	ca	secondary	proposal_implementation	proposal	result	outcomes	3	-1	sequence	Next , the model is used to predict aspect ratings in previously unseen texts , demonstrating interpretability and explanatory power for its predictions .	For learning from texts with known aspect ratings , the model performs multiple-instance regression ( MIR ) and assigns importance weights to each of the sentences or paragraphs of a text , uncovering their contribution to the aspect ratings .
CL	D14-1052	5	ca	secondary	result_means	outcomes	observation	outcomes	1	-4	support	We evaluate the model on seven multi-aspect sentiment analysis data sets , improving over four MIR baselines and two strong bag-of-words linear models , namely SVR and Lasso , by more than 10 % relative in terms of MSE .	This paper introduces a model of multiple-instance learning applied to the prediction of aspect ratings or judgments of specific properties of an item from user-contributed texts such as product reviews .
CL	D14-1053	1	ca	main	proposal	proposal	none	none	0	0	none	We propose a semi-supervised bootstrapping algorithm for analyzing China's foreign relations from the People's Daily .	Our approach addresses sentiment target clustering , subjective lexicons extraction and sentiment prediction in a unified framework .
CL	D14-1053	2	ca	secondary	proposal	proposal	none	none	1	-1	elaboration	Our approach addresses sentiment target clustering , subjective lexicons extraction and sentiment prediction in a unified framework .	
CL	D14-1053	3	ca	secondary	proposal_implementation	proposal	motivation_background	motivation	2	-1	elaboration	Different from existing algorithms in the literature , time information is considered in our algorithm through a hierarchical bayesian model to guide the bootstrapping approach .	We propose a semi-supervised bootstrapping algorithm for analyzing China's foreign relations from the People's Daily .
CL	D14-1053	4	ca	secondary	conclusion	outcomes	none	none	1	-3	support	We are hopeful that our approach can facilitate quantitative political analysis conducted by social scientists and politicians .	Our approach addresses sentiment target clustering , subjective lexicons extraction and sentiment prediction in a unified framework .
CL	D14-1054	1	ca	main	proposal	proposal	none	none	0	0	none	In this paper , we propose a joint segmentation and classification framework for sentiment analysis .	
CL	D14-1054	2	ca	secondary	motivation_problem	motivation	motivation_background	motivation	3	1	support	Existing sentiment classification algorithms typically split a sentence as a word sequence , which does not effectively handle the inconsistent sentiment polarity between a phrase and the words it contains , such as " not bad"  and " a great deal of " .	In this paper , we propose a joint segmentation and classification framework for sentiment analysis .
CL	D14-1054	3	ca	secondary	proposal_implementation	proposal	none	none	1	-2	elaboration	We address this issue by developing a joint segmentation and classification framework ( JSC ) , which simultaneously conducts sentence segmentation and sentence-level sentiment classification .	In this paper , we propose a joint segmentation and classification framework for sentiment analysis .
CL	D14-1054	4	ca	secondary	proposal_implementation	proposal	none	none	3	-1	elaboration	Specifically , we use a log-linear model to score each segmentation candidate , and exploit the phrasal information of top-ranked segmentations as features to build the sentiment classifier .	We address this issue by developing a joint segmentation and classification framework ( JSC ) , which simultaneously conducts sentence segmentation and sentence-level sentiment classification .
CL	D14-1054	5	ca	secondary	proposal_implementation	proposal	none	none	4	-1	elaboration	A marginal log-likelihood objective function is devised for the segmentation model , which is optimized for enhancing the sentiment classification performance .	Specifically , we use a log-linear model to score each segmentation candidate , and exploit the phrasal information of top-ranked segmentations as features to build the sentiment classifier .
CL	D14-1054	6	ca	secondary	proposal_implementation	proposal	none	none	3	-3	elaboration	The joint model is trained only based on the annotated sentiment polarity of sentences , without any segmentation annotations .	A marginal log-likelihood objective function is devised for the segmentation model , which is optimized for enhancing the sentiment classification performance .
CL	D14-1054	7	ca	secondary	result_means	outcomes	none	none	1	-6	support	Experiments on a benchmark Twitter sentiment classification dataset in SemEval 2013 show that , our joint model performs comparably with the state-of-the-art methods .	In this paper , we propose a joint segmentation and classification framework for sentiment analysis .
CL	D14-1055	1	ca	secondary	motivation_background	motivation	none	none	2	1	info-required	Deceptive reviews detection has attracted significant attention from both business and research communities .	This paper proposed a novel angle to the problem by modeling PU ( positive unlabeled ) learning .
CL	D14-1055	2	ca	secondary	motivation_problem	motivation	none	none	3	1	support	However , due to the difficulty of human labeling needed for supervised learning , the problem remains to be highly challenging .	Deceptive reviews detection has attracted significant attention from both business and research communities .
CL	D14-1055	3	ca	main	proposal	proposal	none	none	0	0	none	This paper proposed a novel angle to the problem by modeling PU ( positive unlabeled ) learning .	
CL	D14-1055	4	ca	secondary	proposal	proposal	none	none	3	-1	elaboration	A semi-supervised model , called mixing population and individual property PU learning ( MPIPUL ) , is proposed .	This paper proposed a novel angle to the problem by modeling PU ( positive unlabeled ) learning .
CL	D14-1055	5	ca	secondary	proposal_implementation	proposal	none	none	4	-1	elaboration	Firstly , some reliable negative examples are identified from the unlabeled dataset .	A semi-supervised model , called mixing population and individual property PU learning ( MPIPUL ) , is proposed .
CL	D14-1055	6	ca	secondary	proposal_implementation	proposal	none	none	5	-1	sequence	Secondly , some representative positive examples and negative examples are generated based on LDA ( Latent Dirichlet Allocation ) .	Firstly , some reliable negative examples are identified from the unlabeled dataset .
CL	D14-1055	7	ca	secondary	proposal_implementation	proposal	none	none	6	-1	sequence	Thirdly , for the remaining unlabeled examples ( we call them spy examples ) , which can not be explicitly identified as positive and negative , two similarity weights are assigned , by which the probability of a spy example belonging to the positive class and the negative class are displayed .	Secondly , some representative positive examples and negative examples are generated based on LDA ( Latent Dirichlet Allocation ) .
CL	D14-1055	8	ca	secondary	proposal_implementation	proposal	none	none	7	-1	sequence	Finally , spy examples and their similarity weights are incorporated into SVM ( Support Vector Machine ) to build an accurate classifier .	Thirdly , for the remaining unlabeled examples ( we call them spy examples ) , which can not be explicitly identified as positive and negative , two similarity weights are assigned , by which the probability of a spy example belonging to the positive class and the negative class are displayed .
CL	D14-1055	9	ca	secondary	result_means	outcomes	none	none	3	-6	support	Experiments on gold-standard dataset demonstrate the effectiveness of MPIPUL which outperforms the state-of-the-art baselines .	This paper proposed a novel angle to the problem by modeling PU ( positive unlabeled ) learning .
CL	D14-1056	1	ca	secondary	motivation_background	motivation	none	none	2	1	info-required	Shell nouns , such as fact and problem , occur frequently in all kinds of texts .	These nouns themselves are unspecific , and can only be interpreted together with the shell content .
CL	D14-1056	2	ca	secondary	motivation_problem	motivation	none	none	3	1	support	These nouns themselves are unspecific , and can only be interpreted together with the shell content .	We propose a general approach to automatically identify shell content of shell nouns .
CL	D14-1056	3	ca	main	proposal	proposal	none	none	0	0	none	We propose a general approach to automatically identify shell content of shell nouns .	
CL	D14-1056	4	ca	secondary	proposal_implementation	proposal	none	none	3	-1	elaboration	Our approach exploits lexico-syntactic knowledge derived from the linguistics literature .	We propose a general approach to automatically identify shell content of shell nouns .
CL	D14-1056	5	ca	secondary	observation	outcomes	means	method	3	-2	support	We evaluate the approach on a variety of shell nouns with a variety of syntactic expectations , achieving accuracies in the range of 62 % ( baseline = 33 % ) to 83 % ( baseline = 74 % ) on crowd-annotated data .	We propose a general approach to automatically identify shell content of shell nouns .
CL	D14-1057	1	ca	main	proposal	proposal	means	method	0	0	none	We present a comparison of different selectional preference models and evaluate them on an automatic verb classification task in German .	
CL	D14-1057	2	ca	secondary	result	outcomes	proposal_implementation	proposal	1	-1	support	We find that all the models we compare are effective for verb clustering ; the best-performing model uses syntactic information to induce nouns classes from unlabelled data in an unsupervised manner .	We present a comparison of different selectional preference models and evaluate them on an automatic verb classification task in German .
CL	D14-1057	3	ca	secondary	result	outcomes	none	none	2	-1	elaboration	A very simple model based on lexical preferences is also found to perform well .	We find that all the models we compare are effective for verb clustering ; the best-performing model uses syntactic information to induce nouns classes from unlabelled data in an unsupervised manner .
CL	D14-1058	1	ca	main	proposal	proposal	none	none	0	0	none	This paper presents a novel approach to learning to solve simple arithmetic word problems .	
CL	D14-1058	2	ca	secondary	proposal_implementation	proposal	none	none	1	-1	elaboration	Our system , ARIS , analyzes each of the sentences in the problem state-ment to identify the relevant variables and their values .	This paper presents a novel approach to learning to solve simple arithmetic word problems .
CL	D14-1058	3	ca	secondary	proposal_implementation	proposal	none	none	2	-1	sequence	ARIS then maps this information into an equation that represents the problem , and enables its ( trivial ) solution as shown in Figure 1 .	Our system , ARIS , analyzes each of the sentences in the problem state-ment to identify the relevant variables and their values .
CL	D14-1058	4	ca	secondary	proposal	proposal	none	none	1	-3	elaboration	The paper analyzes the arithmetic-word problems "genre" , identifying seven categories of verbs used in such problems .	This paper presents a novel approach to learning to solve simple arithmetic word problems .
CL	D14-1058	5	ca	secondary	observation	outcomes	none	none	6	1	support	ARIS learns to categorize verbs with 81.2 % accuracy , and is able to solve 77.7 % of the problems in a corpus of standard primary school test questions .	We report the first learning results on this task without reliance on pre-defined templates and make our data publicly available .
CL	D14-1058	6	ca	secondary	result	outcomes	none	none	1	-5	support	We report the first learning results on this task without reliance on pre-defined templates and make our data publicly available .	This paper presents a novel approach to learning to solve simple arithmetic word problems .
CL	D14-1059	1	ca	secondary	motivation_background	motivation	none	none	2	1	support	Common-sense reasoning is important for AI applications , both in NLP and many vision and robotics tasks .	We propose NaturalLI : a Natural Logic inference system for inferring common sense facts - for instance , that cats have tails or tomatoes are round - from a very large database of known facts .
CL	D14-1059	2	ca	main	proposal	proposal	none	none	0	0	none	We propose NaturalLI : a Natural Logic inference system for inferring common sense facts - for instance , that cats have tails or tomatoes are round - from a very large database of known facts .	
CL	D14-1059	3	ca	secondary	proposal	proposal	none	none	2	-1	elaboration	In addition to being able to provide strictly valid derivations , the system is also able to produce derivations which are only likely valid , accompanied by an associated confidence .	We propose NaturalLI : a Natural Logic inference system for inferring common sense facts - for instance , that cats have tails or tomatoes are round - from a very large database of known facts .
CL	D14-1059	4	ca	secondary	result_means	outcomes	observation	outcomes	2	-2	support	We both show that our system is able to capture strict Natural Logic inferences on the FraCaS test suite , and demonstrate its ability to predict common sense facts with 49 % recall and 91 % precision .	We propose NaturalLI : a Natural Logic inference system for inferring common sense facts - for instance , that cats have tails or tomatoes are round - from a very large database of known facts .
CL	D14-1060	1	ca	secondary	motivation_background	motivation	none	none	2	1	support	Term translation is of great importance for statistical machine translation ( SMT ) , especially document-informed SMT .	In this paper , we investigate three issues of term translation in the context of document-informed SMT and propose three corresponding models : ( a ) a term translation disambiguation model which selects desirable translations for terms in the source language with domain information , ( b ) a term translation consistency model that encourages consistent translations for terms with a high strength of translation consistency throughout a document , and ( c ) a term bracketing model that rewards translation hypotheses where bracketable source terms are translated as a whole unit .
CL	D14-1060	2	ca	main	proposal	proposal	none	none	0	0	none	In this paper , we investigate three issues of term translation in the context of document-informed SMT and propose three corresponding models : ( a ) a term translation disambiguation model which selects desirable translations for terms in the source language with domain information , ( b ) a term translation consistency model that encourages consistent translations for terms with a high strength of translation consistency throughout a document , and ( c ) a term bracketing model that rewards translation hypotheses where bracketable source terms are translated as a whole unit .	
CL	D14-1060	3	ca	secondary	proposal_implementation	proposal	means	method	2	-1	elaboration	We integrate the three models into hierarchical phrase-based SMT and evaluate their effectiveness on NIST Chinese-English translation tasks with large-scale training data .	In this paper , we investigate three issues of term translation in the context of document-informed SMT and propose three corresponding models : ( a ) a term translation disambiguation model which selects desirable translations for terms in the source language with domain information , ( b ) a term translation consistency model that encourages consistent translations for terms with a high strength of translation consistency throughout a document , and ( c ) a term bracketing model that rewards translation hypotheses where bracketable source terms are translated as a whole unit .
CL	D14-1060	4	ca	secondary	result	outcomes	none	none	2	-2	support	Experiment results show that all three models can achieve significant improvements over the baseline .	In this paper , we investigate three issues of term translation in the context of document-informed SMT and propose three corresponding models : ( a ) a term translation disambiguation model which selects desirable translations for terms in the source language with domain information , ( b ) a term translation consistency model that encourages consistent translations for terms with a high strength of translation consistency throughout a document , and ( c ) a term bracketing model that rewards translation hypotheses where bracketable source terms are translated as a whole unit .
CL	D14-1060	5	ca	secondary	result	outcomes	proposal_implementation	proposal	4	-1	elaboration	Additionally , we can obtain a further improvement when combining the three models .	Experiment results show that all three models can achieve significant improvements over the baseline .
CL	D14-1061	1	ca	main	proposal	proposal	motivation_background	motivation	0	0	none	Inspired by previous work , where decipherment is used to improve machine translation , we propose a new idea to combine word alignment and decipherment into a single learning process .	
CL	D14-1061	2	ca	secondary	proposal_implementation	proposal	none	none	1	-1	elaboration	We use EM to estimate the model parameters , not only to maximize the probability of parallel corpus , but also the monolingual corpus .	Inspired by previous work , where decipherment is used to improve machine translation , we propose a new idea to combine word alignment and decipherment into a single learning process .
CL	D14-1061	3	ca	secondary	proposal	proposal	motivation_problem	motivation	2	-1	elaboration	We apply our approach to improve Malagasy-English machine translation , where only a small amount of parallel data is available .	We use EM to estimate the model parameters , not only to maximize the probability of parallel corpus , but also the monolingual corpus .
CL	D14-1061	4	ca	secondary	observation	outcomes	none	none	1	-3	support	In our experiments , we observe gains of 0.9 to 2.1 Bleu over a strong baseline .	Inspired by previous work , where decipherment is used to improve machine translation , we propose a new idea to combine word alignment and decipherment into a single learning process .
CL	D14-1062	1	ca	secondary	motivation_problem	motivation	none	none	2	1	support	Phrase-based models directly trained on mix-of-domain corpora can be sub-optimal.	In this paper we equip phrase-based models with a latent domain variable and present a novel method for adapting them to an in-domain task represented by a seed corpus .
CL	D14-1062	2	ca	main	proposal	proposal	none	none	0	0	none	In this paper we equip phrase-based models with a latent domain variable and present a novel method for adapting them to an in-domain task represented by a seed corpus .	
CL	D14-1062	3	ca	secondary	proposal_implementation	proposal	none	none	2	-1	elaboration	We derive an EM algorithm which alternates between inducing domain-focused phrase pair estimates , and weights for mix-domain sentence pairs reflecting their relevance for the in-domain task .	In this paper we equip phrase-based models with a latent domain variable and present a novel method for adapting them to an in-domain task represented by a seed corpus .
CL	D14-1062	4	ca	secondary	proposal_implementation	proposal	none	none	3	-1	elaboration	By embedding our latent domain phrase model in a sentence-level model and training the two in tandem , we are able to adapt all core translation components together - phrase , lexical and reordering .	We derive an EM algorithm which alternates between inducing domain-focused phrase pair estimates , and weights for mix-domain sentence pairs reflecting their relevance for the in-domain task .
CL	D14-1062	5	ca	secondary	result	outcomes	none	none	2	-3	support	We show experiments on weighing sentence pairs for relevance as well as adapting phrase-based models , showing significant performance improvement in both tasks .	In this paper we equip phrase-based models with a latent domain variable and present a novel method for adapting them to an in-domain task represented by a seed corpus .
CL	D14-1063	1	ca	secondary	motivation_background	motivation	none	none	2	1	info-required	In Corpus-Based Machine Translation , the search space of the translation candidates for a given input sentence is often defined by a set of ( cycle-free ) context-free grammar rules .	We propose a natural extension to this representation by using lattice-rules that allow to easily encode an exponential number of variations of each rules .
CL	D14-1063	2	ca	secondary	motivation_background	motivation	none	none	3	1	info-required	This happens naturally in Syntax-Based Machine Translation and Hierarchical Phrase-Based Machine Translation ( where the representation will be the set of the target-side half of the synchronous rules used to parse the input sentence ) .	In Corpus-Based Machine Translation , the search space of the translation candidates for a given input sentence is often defined by a set of ( cycle-free ) context-free grammar rules .
CL	D14-1063	3	ca	secondary	motivation_background	motivation	none	none	4	1	support	But it is also possible to describe Phrase-Based Machine Translation in this framework .	This happens naturally in Syntax-Based Machine Translation and Hierarchical Phrase-Based Machine Translation ( where the representation will be the set of the target-side half of the synchronous rules used to parse the input sentence ) .
CL	D14-1063	4	ca	main	proposal	proposal	none	none	0	0	none	We propose a natural extension to this representation by using lattice-rules that allow to easily encode an exponential number of variations of each rules .	
CL	D14-1063	5	ca	secondary	conclusion	outcomes	none	none	4	-1	support	We also demonstrate how the representation of the search space has an impact on decoding efficiency , and how it is possible to optimize this representation .	We propose a natural extension to this representation by using lattice-rules that allow to easily encode an exponential number of variations of each rules .
CL	D14-1064	1	ca	secondary	motivation_background	motivation	none	none	2	1	info-required	When documents and queries are presented in different languages , the common approach is to translate the query into the document language .	While there are a variety of query translation approaches , recent research suggests that combining multiple methods into a single "structured query" is the most effective .
CL	D14-1064	2	ca	secondary	motivation_background	motivation	none	none	3	1	support	While there are a variety of query translation approaches , recent research suggests that combining multiple methods into a single "structured query" is the most effective .	In this paper , we introduce a novel approach for producing a unique combination recipe for each query , as it has also been shown that the optimal combination weights differ substantially across queries and other task specifics .
CL	D14-1064	3	ca	main	proposal	proposal	motivation_background	motivation	0	0	none	In this paper , we introduce a novel approach for producing a unique combination recipe for each query , as it has also been shown that the optimal combination weights differ substantially across queries and other task specifics .	
CL	D14-1064	4	ca	secondary	conclusion	outcomes	none	none	3	-1	support	Our query-specific combination method generates statistically significant improvements over other combination strategies presented in the literature , such as uniform and task-specific weighting .	An in-depth empirical analysis presents insights about the effect of data size , domain differences , labeling and tuning on the end performance of our approach .
CL	D14-1064	5	ca	secondary	conclusion	outcomes	none	none	4	-1	support	An in-depth empirical analysis presents insights about the effect of data size , domain differences , labeling and tuning on the end performance of our approach .	In this paper , we introduce a novel approach for producing a unique combination recipe for each query , as it has also been shown that the optimal combination weights differ substantially across queries and other task specifics .
CL	D14-1065	1	ca	secondary	motivation_background	motivation	none	none	2	1	info-required	A major challenge in document clustering research arises from the growing amount of text data written in different languages .	Previous approaches depend on language-specific solutions ( e.g. , bilingual dictionaries , sequential machine translation ) to evaluate document similarities , and the required transformations may alter the original document semantics .
CL	D14-1065	2	ca	secondary	motivation_problem	motivation	motivation_problem	motivation	3	1	support	Previous approaches depend on language-specific solutions ( e.g. , bilingual dictionaries , sequential machine translation ) to evaluate document similarities , and the required transformations may alter the original document semantics .	To cope with this issue we propose a new document clustering approach for multilingual corpora that ( i ) exploits a large-scale multilingual knowledge base , ( ii ) takes advantage of the multi-topic nature of the text documents , and ( iii ) employs a tensor-based model to deal with high dimensionality and sparseness .
CL	D14-1065	3	ca	main	proposal	proposal	proposal_implementation	proposal	0	0	none	To cope with this issue we propose a new document clustering approach for multilingual corpora that ( i ) exploits a large-scale multilingual knowledge base , ( ii ) takes advantage of the multi-topic nature of the text documents , and ( iii ) employs a tensor-based model to deal with high dimensionality and sparseness .	
CL	D14-1065	4	ca	secondary	result	outcomes	none	none	3	-1	support	Results have shown the significance of our approach and its better performance w.r.t. classic document clustering approaches , in both a balanced and an unbalanced corpus evaluation .	To cope with this issue we propose a new document clustering approach for multilingual corpora that ( i ) exploits a large-scale multilingual knowledge base , ( ii ) takes advantage of the multi-topic nature of the text documents , and ( iii ) employs a tensor-based model to deal with high dimensionality and sparseness .
CL	D14-1066	1	ca	main	proposal	proposal	none	none	0	0	none	In this paper we examine the lexical substitution task for the medical domain .	
CL	D14-1066	2	ca	secondary	proposal_implementation	proposal	none	none	1	-1	elaboration	We adapt the current best system from the open domain , which trains a single classifier for all instances using delexicalized features .	In this paper we examine the lexical substitution task for the medical domain .
CL	D14-1066	3	ca	secondary	result	outcomes	none	none	1	-2	support	We show significant improvements over a strong baseline coming from a distributional thesaurus ( DT ) .	In this paper we examine the lexical substitution task for the medical domain .
CL	D14-1066	4	ca	secondary	result	outcomes	motivation_background	motivation	1	-3	support	Whereas in the open domain system , features derived from WordNet show only slight improvements , we show that its counterpart for the medical domain ( UMLS ) shows a significant additional benefit when used for feature generation .	We show significant improvements over a strong baseline coming from a distributional thesaurus ( DT ) .
CL	D14-1067	1	ca	main	proposal	proposal	none	none	0	0	none	This paper presents a system which learns to answer questions on a broad range of topics from a knowledge base using few hand-crafted features .	
CL	D14-1067	2	ca	secondary	proposal_implementation	proposal	none	none	1	-1	elaboration	Our model learns low-dimensional embeddings of words and knowledge base constituents ; these representations are used to score natural language questions against candidate answers .	This paper presents a system which learns to answer questions on a broad range of topics from a knowledge base using few hand-crafted features .
CL	D14-1067	3	ca	secondary	result_means	outcomes	none	none	1	-2	support	Training our system using pairs of questions and structured representations of their answers , and pairs of question paraphrases , yields competitive results on a recent benchmark of the literature .	This paper presents a system which learns to answer questions on a broad range of topics from a knowledge base using few hand-crafted features .
CL	D14-1068	1	ca	secondary	motivation_background	motivation	none	none	2	1	support	Keyboard layout errors and homoglyphs in cross-language queries impact our ability to correctly interpret user information needs and offer relevant results .	We present a machine learning approach to correcting these errors , based largely on character-level n-gram features .
CL	D14-1068	2	ca	main	proposal	proposal	none	none	0	0	none	We present a machine learning approach to correcting these errors , based largely on character-level n-gram features .	
CL	D14-1068	3	ca	secondary	result	outcomes	none	none	2	-1	support	We demonstrate superior performance over rule-based methods , as well as a significant reduction in the number of queries that yield null search results .	We present a machine learning approach to correcting these errors , based largely on character-level n-gram features .
CL	D14-1069	1	ca	main	proposal	proposal	none	none	0	0	none	Non-linear mappings of the form P ( ngram ) γ andlog ( 1+τP ( ngram )) log ( 1+τ ) are applied to the n-gram probabilities in five trainable open-source language identifiers .	
CL	D14-1069	2	ca	secondary	observation	outcomes	means	method	1	-1	support	The first mapping reduces classification errors by 4.0 % to 83.9 % over a test set of more than one million 65-character strings in 1366 languages , and by 2.6 % to 76.7 % over a subset of 781 languages .	Non-linear mappings of the form P ( ngram ) γ andlog ( 1+τP ( ngram )) log ( 1+τ ) are applied to the n-gram probabilities in five trainable open-source language identifiers .
CL	D14-1069	3	ca	secondary	observation	outcomes	means	method	2	-1	elaboration	The second mapping improves four of the five identifiers by 10.6 % to 83.8 % on the larger corpus and 14.4 % to 76.7 % on the smaller corpus .	The first mapping reduces classification errors by 4.0 % to 83.9 % over a test set of more than one million 65-character strings in 1366 languages , and by 2.6 % to 76.7 % over a subset of 781 languages .
CL	D14-1069	4	ca	secondary	information_additional	other	none	none	1	-3	info-optional	The subset corpus and the modified programs are made freely available for download at http : //www.cs.cmu.edu/∼ralf/langid.html .	Non-linear mappings of the form P ( ngram ) γ andlog ( 1+τP ( ngram )) log ( 1+τ ) are applied to the n-gram probabilities in five trainable open-source language identifiers .
